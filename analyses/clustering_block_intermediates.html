<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="A summary of my experiments to understand the projection layer and feed-forward layer of a self-attention block.">

<title>transformer-experiments - Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
<meta property="og:title" content="transformer-experiments - Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block">
<meta property="og:description" content="A summary of my experiments to understand the projection layer and feed-forward layer of a self-attention block.">
<meta property="og:site_name" content="transformer-experiments">
<meta name="twitter:title" content="transformer-experiments - Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block">
<meta name="twitter:description" content="A summary of my experiments to understand the projection layer and feed-forward layer of a self-attention block.">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">transformer-experiments</span>
    </a>
  </div>
        <div class="quarto-navbar-tools">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../analyses/introduction.html">analyses</a></li><li class="breadcrumb-item"><a href="../analyses/clustering_block_intermediates.html">Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">transformer-experiments</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">analyses</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/clustering_block_intermediates.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/cosine_sim_intermediates.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Investigation of Cosine Similarity of Block Intermediates</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/similar_strings_deep_dive.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Deep Dive into Similar Strings Progress through the Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/widening_similar_space.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Widening the Space of Similar Values</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/approximation_details.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Approximation Interpretation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/combining_token_subspaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Combining Token Subspaces</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../analyses/embedding_adjustments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Embedding Adjustments</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">blog_posts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../blog_posts/beyond-self-attention.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Beyond Self-Attention: How a Small Language Model Predicts the Next Token</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">common</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../common/databatcher.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">databatcher</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../common/environments.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">environments</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../common/substring-generator.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">substring-generator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../common/svd-helpers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">svd-helpers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../common/text-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">text-analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../common/utils.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">utils</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">datasets</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../datasets/tinyshakespeare.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">tinyshakespeare.ipynb</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
 <span class="menu-text">experiments</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../experiments/alternate-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">alternate-models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../experiments/block-internals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">block-internals</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../experiments/cosine-sims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">cosine-sims</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../experiments/final_ffwd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">final-ffwd</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../experiments/learn-embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">learn-embeddings</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../experiments/logit-lens.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">logit-lens</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../experiments/similar-strings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">similar-strings</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
 <span class="menu-text">models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/transformer-helpers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">transformer-helpers.ipynb</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/transformer-training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">transformer-training</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../models/transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">transformer</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">tokenizers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tokenizers/char-tokenizer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">char-tokenizer.ipynb</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">trained_models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../trained_models/tinyshakespeare-transformer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">tinyshakespeare-transformer</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">training</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../training/dataset-split.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">dataset-split</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../training/training-utils.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">training-utils.ipynb</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#attempt-to-learn-weights-over-a-large-number-of-examples" id="toc-attempt-to-learn-weights-over-a-large-number-of-examples" class="nav-link active" data-scroll-target="#attempt-to-learn-weights-over-a-large-number-of-examples">Attempt to learn weights over a large number of examples</a></li>
  <li><a href="#cosine-similarity-results" id="toc-cosine-similarity-results" class="nav-link" data-scroll-target="#cosine-similarity-results">Cosine Similarity Results</a></li>
  <li><a href="#identify-a-small-sample-of-strings-that-produce-similar-results" id="toc-identify-a-small-sample-of-strings-that-produce-similar-results" class="nav-link" data-scroll-target="#identify-a-small-sample-of-strings-that-produce-similar-results">Identify a small sample of strings that produce similar results</a></li>
  <li><a href="#analysis-of-whether-there-are-similar-strings-of-smaller-length" id="toc-analysis-of-whether-there-are-similar-strings-of-smaller-length" class="nav-link" data-scroll-target="#analysis-of-whether-there-are-similar-strings-of-smaller-length">Analysis of whether there are similar strings of smaller length</a></li>
  <li><a href="#try-out-loading-with-mmap_mode" id="toc-try-out-loading-with-mmap_mode" class="nav-link" data-scroll-target="#try-out-loading-with-mmap_mode">Try out loading with mmap_mode</a>
  <ul class="collapse">
  <li><a href="#perf-tests-for-using-mmap-with-the-slicer" id="toc-perf-tests-for-using-mmap-with-the-slicer" class="nav-link" data-scroll-target="#perf-tests-for-using-mmap-with-the-slicer">Perf tests for using mmap with the slicer</a></li>
  </ul></li>
  <li><a href="#perf-tests-for-finding-closest-embeddings" id="toc-perf-tests-for-finding-closest-embeddings" class="nav-link" data-scroll-target="#perf-tests-for-finding-closest-embeddings">Perf tests for finding closest embeddings</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/spather/transformer-experiments/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../analyses/introduction.html">analyses</a></li><li class="breadcrumb-item"><a href="../analyses/clustering_block_intermediates.html">Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block</h1>
</div>

<div>
  <div class="description">
    A summary of my experiments to understand the projection layer and feed-forward layer of a self-attention block.
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<div id="cell-2" class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a manual seed so output is deterministic (used same value as @karpathy)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> torch.manual_seed(<span class="dv">1337</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-3" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>environment <span class="op">=</span> get_environment()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>ts <span class="op">=</span> TinyShakespeareDataSet(cache_file<span class="op">=</span>environment.code_root <span class="op">/</span> <span class="st">'nbs/artifacts/input.txt'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>m, tokenizer <span class="op">=</span> create_model_and_tokenizer(</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    saved_model_filename<span class="op">=</span>environment.code_root <span class="op">/</span> <span class="st">'nbs/artifacts/shakespeare-20231112.pt'</span>,</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>ts,</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>_, val_data <span class="op">=</span> split_text_dataset(ts.text, tokenizer, train_pct<span class="op">=</span><span class="fl">0.9</span>, device<span class="op">=</span>device)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>encoding_helpers <span class="op">=</span> EncodingHelpers(tokenizer, device)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>accessors <span class="op">=</span> TransformerAccessors(m, device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-4" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"environment is </span><span class="sc">{</span>environment<span class="sc">.</span>name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"device is </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>environment is local_mac
device is cpu</code></pre>
</div>
</div>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>strings10 <span class="op">=</span> all_unique_substrings(ts.text, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-6" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a next token map for each prefix length that we've run experiments for.</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>next_token_map3 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">3</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>next_token_map4 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">4</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>next_token_map5 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">5</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>next_token_map6 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">6</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>next_token_map7 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">7</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>next_token_map8 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">8</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>next_token_map9 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">9</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>next_token_map10 <span class="op">=</span> build_next_token_map(ts.text, prefix_len<span class="op">=</span><span class="dv">10</span>, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-7" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>all_token_lens <span class="op">=</span> [<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>all_token_maps <span class="op">=</span> [</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    next_token_map3,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    next_token_map4,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    next_token_map5,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    next_token_map6,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    next_token_map7,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    next_token_map8,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    next_token_map9,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    next_token_map10</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-8" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine all the token maps into one</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>next_token_map_all <span class="op">=</span> {</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map3,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map4,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map5,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map6,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map7,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map8,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map9,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="op">**</span>next_token_map10</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-9" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sanity check for entries that have no next token. This should only be the case</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># for cases where the last substring in the text is unique.</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> next_token_map_all.items():</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> v.<span class="bu">sum</span>() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="bu">repr</span>(k)<span class="sc">}</span><span class="ss"> has no next tokens"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-10" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sanity check all the lengths are right.</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l, token_map <span class="kw">in</span> <span class="bu">zip</span>(all_token_lens, all_token_maps):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> token_map.keys():</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(k) <span class="op">!=</span> l:</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="bu">repr</span>(k)<span class="sc">}</span><span class="ss"> has length </span><span class="sc">{</span><span class="bu">len</span>(k)<span class="sc">}</span><span class="ss"> but should have length </span><span class="sc">{</span>l<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-11" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">list</span>((environment.data_root <span class="op">/</span> <span class="st">'block_internals_results/large_files/slen10/'</span>).glob(<span class="st">'*'</span>)) <span class="op">==</span> []:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Run `make block_internals_slen10_dataset` in the project root to generate the required dataset"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>exp10 <span class="op">=</span> BatchedBlockInternalsExperiment(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    eh<span class="op">=</span>encoding_helpers,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    accessors<span class="op">=</span>accessors,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    strings<span class="op">=</span>strings10,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>environment.data_root <span class="op">/</span> <span class="st">'block_internals_results/large_files/slen10/'</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-13" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a similar strings experiment on a bunch of sample strings we'll use for analysis</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> environment.code_root <span class="op">/</span> <span class="st">'nbs/artifacts/block_internals_results/similar_strings_sample'</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>output_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>ssexp <span class="op">=</span> SimilarStringsExperiment(output_dir, encoding_helpers)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>sample_strings <span class="op">=</span> [<span class="st">'First Citi'</span>, <span class="st">'Citizen:</span><span class="ch">\n</span><span class="st">B'</span>, <span class="st">'Shyamalan '</span>, <span class="st">'more in jo'</span>]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>n_similars <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>batch_size<span class="op">=</span><span class="bu">len</span>(sample_strings)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> (output_dir <span class="op">/</span> <span class="st">'string_to_batch_map.json'</span>).exists():</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    ssexp.generate_string_to_batch_map(sample_strings, batch_size)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(output_dir.glob(<span class="st">'embs_sim_strings-*.json'</span>)))</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">StopIteration</span>:</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    ssexp.generate_embeddings_files(sample_strings, accessors, exp10, batch_size<span class="op">=</span>batch_size, n_similars<span class="op">=</span>n_similars)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(output_dir.glob(<span class="st">'proj_out_sim_strings-*.json'</span>)))</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">StopIteration</span>:</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    ssexp.generate_proj_out_files(sample_strings, t_i<span class="op">=-</span><span class="dv">1</span>, accessors<span class="op">=</span>accessors, exp<span class="op">=</span>exp10, batch_size<span class="op">=</span>batch_size, n_similars<span class="op">=</span>n_similars)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    _ <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(output_dir.glob(<span class="st">'ffwd_out_sim_strings-*.json'</span>)))</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">StopIteration</span>:</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    ssexp.generate_ffwd_out_files(sample_strings, t_i<span class="op">=-</span><span class="dv">1</span>, accessors<span class="op">=</span>accessors, exp<span class="op">=</span>exp10, batch_size<span class="op">=</span>batch_size, n_similars<span class="op">=</span>n_similars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-14" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> TypeVar(<span class="st">'T'</span>, bound<span class="op">=</span><span class="st">'SimilarStringsFrequencyAndDistanceData'</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="at">@dataclass</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimilarStringsFrequencyAndDistanceData:</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Encapsulates the frequency and distance data associated</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">    with a set of `SimilarStringsResult`s."""</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    strings: Sequence[<span class="bu">str</span>] <span class="co"># N strings</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    string_to_idx: Dict[<span class="bu">str</span>, <span class="bu">int</span>]  <span class="co"># Maps N strings to indices 0..N-1</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    emb_freqs: torch.Tensor  <span class="co"># (N, n_similars, vocab_size)</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    emb_distances: torch.Tensor  <span class="co"># (N, n_similars)</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    proj_freqs: torch.Tensor  <span class="co"># (N, n_layer, n_similars, vocab_size)</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    proj_distances: torch.Tensor  <span class="co"># (N, n_layer, n_similars)</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    ffwd_freqs: torch.Tensor  <span class="co"># (N, n_layer, n_similars, vocab_size)</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    ffwd_distances: torch.Tensor  <span class="co"># (N, n_layer, n_similars)</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">@classmethod</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> from_results(</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        cls: Type[T],</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        ss_results: Dict[<span class="bu">str</span>, SimilarStringsResult],</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        next_token_map: Dict[<span class="bu">str</span>, torch.Tensor],</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        aggregate_over_t_is: Sequence[<span class="bu">int</span>] <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        largest: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> T:</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>        strings: List[<span class="bu">str</span>] <span class="op">=</span> []</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>        string_to_idx: Dict[<span class="bu">str</span>, <span class="bu">int</span>] <span class="op">=</span> {}</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>        all_emb_freqs <span class="op">=</span> []</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        all_emb_distances <span class="op">=</span> []</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>        all_proj_freqs <span class="op">=</span> []</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        all_proj_distances <span class="op">=</span> []</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        all_ffwd_freqs <span class="op">=</span> []</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>        all_ffwd_distances <span class="op">=</span> []</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, (s, result) <span class="kw">in</span> <span class="bu">enumerate</span>(ss_results.items()):</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>            strings.append(s)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>            string_to_idx[s] <span class="op">=</span> i</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>            aggr_proj_out, aggr_ffwd_out <span class="op">=</span> result.aggregate_over_t_is(</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>                aggregate_over_t_is,</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>                largest<span class="op">=</span>largest,</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>            emb_freqs <span class="op">=</span> torch.stack(</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>                [next_token_map[s] <span class="cf">for</span> s <span class="kw">in</span> result.embs.sim_strings]</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>            all_emb_freqs.append(emb_freqs)</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>            emb_distances <span class="op">=</span> result.embs.distances</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>            all_emb_distances.append(emb_distances)</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>            proj_freqs <span class="op">=</span> torch.stack(</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>                [</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>                    torch.stack(</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>                        [</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>                            next_token_map[s]</span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">for</span> s <span class="kw">in</span> aggr_proj_out[block_idx].sim_strings</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>                        ]</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>            all_proj_freqs.append(proj_freqs)</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>            proj_distances <span class="op">=</span> torch.stack(</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>                [aggr_proj_out[block_idx].distances <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)]</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>            all_proj_distances.append(proj_distances)</span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>            ffwd_freqs <span class="op">=</span> torch.stack(</span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>                [</span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>                    torch.stack(</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a>                        [</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>                            next_token_map[s]</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">for</span> s <span class="kw">in</span> aggr_ffwd_out[block_idx].sim_strings</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a>                        ]</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)</span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a>                ]</span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a>            all_ffwd_freqs.append(ffwd_freqs)</span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>            ffwd_distances <span class="op">=</span> torch.stack(</span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>                [aggr_ffwd_out[block_idx].distances <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)]</span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a>            all_ffwd_distances.append(ffwd_distances)</span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> cls(</span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>            strings,</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a>            string_to_idx,</span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>            torch.stack(all_emb_freqs),  <span class="co"># (len(ss_results), n_similars, vocab_size)</span></span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>            torch.stack(all_emb_distances),  <span class="co"># (len(ss_results), n_similars)</span></span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a>            torch.stack(</span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a>                all_proj_freqs</span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a>            ),  <span class="co"># (len(ss_results), n_layer, n_similars, vocab_size)</span></span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a>            torch.stack(all_proj_distances),  <span class="co"># (len(ss_results), n_layer, n_similars)</span></span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a>            torch.stack(</span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a>                all_ffwd_freqs</span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a>            ),  <span class="co"># (len(ss_results), n_layer, n_similars, vocab_size)</span></span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a>            torch.stack(all_ffwd_distances),  <span class="co"># (len(ss_results), n_layer, n_similars)</span></span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-15" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tests for SimilarStringsFrequencyAndDistanceData</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>ss_data <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ssexp.load_results_for_strings(sample_strings),</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>test_eq(ss_data.strings, sample_strings)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>test_eq(<span class="bu">len</span>(ss_data.string_to_idx), <span class="bu">len</span>(sample_strings))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>test_eq(ss_data.emb_freqs.shape, (<span class="bu">len</span>(sample_strings), n_similars, tokenizer.vocab_size))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>test_eq(ss_data.emb_distances.shape, (<span class="bu">len</span>(sample_strings), n_similars))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>test_eq(ss_data.proj_freqs.shape, (<span class="bu">len</span>(sample_strings), n_layer, n_similars, tokenizer.vocab_size))</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>test_eq(ss_data.proj_distances.shape, (<span class="bu">len</span>(sample_strings), n_layer, n_similars))</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>test_eq(ss_data.ffwd_freqs.shape, (<span class="bu">len</span>(sample_strings), n_layer, n_similars, tokenizer.vocab_size))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>test_eq(ss_data.ffwd_distances.shape, (<span class="bu">len</span>(sample_strings), n_layer, n_similars))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-16" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ComputeNextTokenFreqs(Protocol):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>, prompt_idxs: torch.Tensor, ss_data: SimilarStringsFrequencyAndDistanceData</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        ...</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ModelSimulation:</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        ss_data: SimilarStringsFrequencyAndDistanceData,</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        compute_next_token_freqs: ComputeNextTokenFreqs,</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>        encoding_helpers: EncodingHelpers,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    ):</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ss_data <span class="op">=</span> ss_data</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.get_next_token_freqs <span class="op">=</span> compute_next_token_freqs</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoding_helpers <span class="op">=</span> encoding_helpers</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, prompts: Sequence[<span class="bu">str</span>]):</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        prompt_idxs <span class="op">=</span> torch.tensor(</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>            [<span class="va">self</span>.ss_data.string_to_idx[prompt] <span class="cf">for</span> prompt <span class="kw">in</span> prompts], dtype<span class="op">=</span>torch.<span class="bu">long</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>        freqs <span class="op">=</span> <span class="va">self</span>.get_next_token_freqs(prompt_idxs, <span class="va">self</span>.ss_data)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>            top_nonzero_tokens(f, <span class="va">self</span>.encoding_helpers.tokenizer.itos)[:<span class="dv">10</span>]</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> f <span class="kw">in</span> freqs</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>        ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_model_outputs(prompts: Sequence[<span class="bu">str</span>], encoding_helpers: EncodingHelpers):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute the model's predictions:</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> encoding_helpers.tokenize_strings(prompts)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    logits, _ <span class="op">=</span> m(tokens)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> LogitsWrapper(logits, encoding_helpers.tokenizer)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [topk_tokens[<span class="op">-</span><span class="dv">1</span>] <span class="cf">for</span> topk_tokens <span class="kw">in</span> logits.topk_tokens(k<span class="op">=</span><span class="dv">10</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> next_token_freqs_progressive_ffwd_weight(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    prompt_idxs: torch.Tensor, ss_data: SimilarStringsFrequencyAndDistanceData</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    emb_weight <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    proj_weights <span class="op">=</span> torch.tensor(</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>        [<span class="fl">1.0</span> <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layer)], dtype<span class="op">=</span>torch.float32</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    ).unsqueeze(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    ffwd_weights <span class="op">=</span> torch.tensor(</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>        [<span class="dv">1</span> <span class="op">+</span> block_idx <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)], dtype<span class="op">=</span>torch.float32</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    ).unsqueeze(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>        (emb_weight <span class="op">*</span> ss_data.emb_freqs[prompt_idxs, :]).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (proj_weights <span class="op">*</span> ss_data.proj_freqs[prompt_idxs, :, :, :].<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (ffwd_weights <span class="op">*</span> ss_data.ffwd_freqs[prompt_idxs, :, :, :].<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> freqs <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-19" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>simulate <span class="op">=</span> ModelSimulation(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    ss_data<span class="op">=</span>ss_data,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    compute_next_token_freqs<span class="op">=</span>next_token_freqs_progressive_ffwd_weight,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    encoding_helpers<span class="op">=</span>encoding_helpers,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-20" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>strings10[<span class="dv">14423</span>:<span class="dv">14433</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>['more in jo',
 'ore in joy',
 're in joy ',
 'e in joy a',
 ' in joy at',
 'in joy at ',
 'n joy at f',
 ' joy at fi',
 'joy at fir',
 'oy at firs']</code></pre>
</div>
</div>
<div id="cell-21" class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>string_to_idx <span class="op">=</span> {</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    s: i <span class="cf">for</span> i, s <span class="kw">in</span> <span class="bu">enumerate</span>(sample_strings)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>sample_model_outputs <span class="op">=</span> get_model_outputs(sample_strings, encoding_helpers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-22" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>simulate([<span class="st">'First Citi'</span>])[<span class="dv">0</span>], sample_model_outputs[string_to_idx[<span class="st">'First Citi'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('z', 0.9380468726158142),
  ('i', 0.03080154024064541),
  ('e', 0.01610080525279045),
  ('c', 0.004550227429717779),
  ('h', 0.003850192530080676),
  ('p', 0.002100104931741953),
  (':', 0.0014000700321048498),
  ('o', 0.0014000700321048498),
  ('u', 0.0007000350160524249),
  (' ', 0.0007000350160524249)],
 [('z', 0.9996668100357056),
  ('u', 0.00010660554107744247),
  ('I', 7.993520557647571e-05),
  ('U', 2.734881672949996e-05),
  ('K', 2.4257360564661212e-05),
  ('P', 1.5074498151079752e-05),
  ('L', 1.0885321898967959e-05),
  ('n', 8.451069334114436e-06),
  ('O', 8.223939403251279e-06),
  ('f', 7.135453870432684e-06)])</code></pre>
</div>
</div>
<div id="cell-23" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>simulate([<span class="st">'Citizen:</span><span class="ch">\n</span><span class="st">B'</span>])[<span class="dv">0</span>], sample_model_outputs[string_to_idx[<span class="st">'Citizen:</span><span class="ch">\n</span><span class="st">B'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('e', 0.3421829044818878),
  ('u', 0.17404130101203918),
  ('o', 0.13716813921928406),
  ('h', 0.09587020426988602),
  ('y', 0.08554572612047195),
  ('a', 0.07669616490602493),
  ('n', 0.033923305571079254),
  ('i', 0.028023598715662956),
  ('r', 0.011799409985542297),
  ('t', 0.007374631240963936)],
 [('e', 0.47825106978416443),
  ('u', 0.2509588301181793),
  ('y', 0.1266946792602539),
  ('r', 0.05788085237145424),
  ('i', 0.03135434538125992),
  ('o', 0.02440422773361206),
  ('a', 0.017102370038628578),
  ('l', 0.012891546823084354),
  ('s', 8.761954813962802e-05),
  ('R', 7.359156006714329e-05)])</code></pre>
</div>
</div>
<div id="cell-24" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>simulate([<span class="st">'Shyamalan '</span>])[<span class="dv">0</span>], sample_model_outputs[string_to_idx[<span class="st">'Shyamalan '</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('t', 0.15815085172653198),
  ('b', 0.1228710487484932),
  ('o', 0.11313868314027786),
  ('a', 0.10340632498264313),
  ('i', 0.09975668787956238),
  ('d', 0.058394160121679306),
  ('s', 0.05352798104286194),
  ('w', 0.04866180196404457),
  ('m', 0.03041362576186657),
  ('f', 0.027980534359812737)],
 [('t', 0.16370470821857452),
  ('s', 0.10785210877656937),
  ('a', 0.09744462370872498),
  ('b', 0.09677103161811829),
  ('c', 0.08353256434202194),
  ('m', 0.056587863713502884),
  ('d', 0.048968441784381866),
  ('p', 0.04876013845205307),
  ('h', 0.04751131683588028),
  ('w', 0.038983285427093506)])</code></pre>
</div>
</div>
<div id="cell-25" class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>simulate([<span class="st">'more in jo'</span>])[<span class="dv">0</span>], sample_model_outputs[string_to_idx[<span class="st">'more in jo'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('y', 0.6007066965103149),
  ('t', 0.16607773303985596),
  ('i', 0.07773851603269577),
  ('s', 0.06713780760765076),
  ('u', 0.038869258016347885),
  ('m', 0.017667844891548157),
  ('d', 0.010600706562399864),
  ('r', 0.007067137863487005),
  ('k', 0.0035335689317435026),
  ('l', 0.0035335689317435026)],
 [('y', 0.8568735718727112),
  ('i', 0.06098264083266258),
  ('u', 0.04135835915803909),
  ('c', 0.016126777976751328),
  ('t', 0.012861563824117184),
  ('l', 0.0022685928270220757),
  ('o', 0.0021818610839545727),
  ('s', 0.0016513006994500756),
  ('v', 0.001559981144964695),
  ('w', 0.0011889823945239186)])</code></pre>
</div>
</div>
<div id="cell-26" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> analyze_simulate_results2(strings: Sequence[<span class="bu">str</span>], sim_outputs: Sequence, model_outputs: Sequence):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""A version of analyze_simulate_results() that computes results for the</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="co">    full length of the returned results."""</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    topn_matches <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    topn_matches_any_order <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>)]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, s <span class="kw">in</span> <span class="bu">enumerate</span>(strings):</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>        sim_output <span class="op">=</span> sim_outputs[i]</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        model_output <span class="op">=</span> model_outputs[i]</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>        sim_tokens, _ <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>sim_output)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        model_tokens, _ <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>model_output)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> <span class="bu">min</span>(<span class="bu">len</span>(sim_tokens), <span class="bu">len</span>(model_tokens))</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> sim_tokens[j] <span class="op">==</span> model_tokens[j]:</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>                topn_matches[j] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">set</span>(sim_tokens[:j<span class="op">+</span><span class="dv">1</span>]) <span class="op">==</span> <span class="bu">set</span>(model_tokens[:j<span class="op">+</span><span class="dv">1</span>]):</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>                topn_matches_any_order[j] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> topn_matches, topn_matches_any_order</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-27" class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">20000</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>ss_exp20k <span class="op">=</span> SimilarStringsExperiment(</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    exp10.output_dir <span class="op">/</span> <span class="st">'similar_strings'</span>,</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    encoding_helpers</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1337</span>)</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> torch.randperm(<span class="bu">len</span>(exp10.strings))[:n_samples]</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>strings <span class="op">=</span> [exp10.strings[i.item()] <span class="cf">for</span> i <span class="kw">in</span> indices]</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>ss_results20k <span class="op">=</span> ss_exp20k.load_results_for_strings(strings)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>ss_data20k <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ss_results20k,</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-28" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>model_outputs20k <span class="op">=</span> get_model_outputs(strings, encoding_helpers)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-29" class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>sim20k <span class="op">=</span> ModelSimulation(</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    ss_data<span class="op">=</span>ss_data20k,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    compute_next_token_freqs<span class="op">=</span>next_token_freqs_progressive_ffwd_weight,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    encoding_helpers<span class="op">=</span>encoding_helpers,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-30" class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>sim_outputs <span class="op">=</span> sim20k(strings)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-31" class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>topn_matches, topn_matches_any_order <span class="op">=</span> analyze_simulate_results2(strings, sim_outputs, model_outputs20k)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches: </span><span class="sc">{</span>topn_matches[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches (any order): </span><span class="sc">{</span>topn_matches_any_order[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.774
Top 1 matches (any order): 0.774
Top 2 matches: 0.398
Top 2 matches (any order): 0.452
Top 3 matches: 0.211
Top 3 matches (any order): 0.238
Top 4 matches: 0.141
Top 4 matches (any order): 0.143
Top 5 matches: 0.102
Top 5 matches (any order): 0.088
Top 6 matches: 0.081
Top 6 matches (any order): 0.054
Top 7 matches: 0.059
Top 7 matches (any order): 0.028
Top 8 matches: 0.053
Top 8 matches (any order): 0.018
Top 9 matches: 0.046
Top 9 matches (any order): 0.010
Top 10 matches: 0.037
Top 10 matches (any order): 0.005</code></pre>
</div>
</div>
<div id="cell-32" class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>t_is<span class="op">=</span>[<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>ss_results20k_all_t_is <span class="op">=</span> ss_exp20k.load_results_for_strings(strings, load_t_is<span class="op">=</span>t_is)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-33" class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>ss_data20k_aggr <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ss_results20k_all_t_is,</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>t_is,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-34" class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>sim20k_aggr <span class="op">=</span> ModelSimulation(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    ss_data<span class="op">=</span>ss_data20k_aggr,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    compute_next_token_freqs<span class="op">=</span>next_token_freqs_progressive_ffwd_weight,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    encoding_helpers<span class="op">=</span>encoding_helpers,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-35" class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>sim_outputs2 <span class="op">=</span> sim20k_aggr(strings)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-36" class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">20000</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>topn_matches, topn_matches_any_order <span class="op">=</span> analyze_simulate_results2(strings, sim_outputs2, model_outputs20k)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches: </span><span class="sc">{</span>topn_matches[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches (any order): </span><span class="sc">{</span>topn_matches_any_order[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.742
Top 1 matches (any order): 0.742
Top 2 matches: 0.363
Top 2 matches (any order): 0.415
Top 3 matches: 0.197
Top 3 matches (any order): 0.212
Top 4 matches: 0.136
Top 4 matches (any order): 0.130
Top 5 matches: 0.098
Top 5 matches (any order): 0.081
Top 6 matches: 0.080
Top 6 matches (any order): 0.048
Top 7 matches: 0.060
Top 7 matches (any order): 0.027
Top 8 matches: 0.053
Top 8 matches (any order): 0.016
Top 9 matches: 0.044
Top 9 matches (any order): 0.010
Top 10 matches: 0.036
Top 10 matches (any order): 0.004</code></pre>
</div>
</div>
<div id="cell-37" class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>sim20k_aggr([<span class="st">'my most gr'</span>])[<span class="dv">0</span>], model_outputs20k[ss_data20k.string_to_idx[<span class="st">'my most gr'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('a', 0.7179487347602844),
  ('i', 0.09455128014087677),
  ('e', 0.06410256773233414),
  ('h', 0.035256411880254745),
  ('o', 0.028846153989434242),
  ('t', 0.025641025975346565),
  ('u', 0.01923076994717121),
  ('r', 0.008012820966541767),
  ('v', 0.0032051282469183207),
  ('c', 0.0016025641234591603)],
 [('a', 0.4602494537830353),
  ('e', 0.35252559185028076),
  ('o', 0.09188850224018097),
  ('i', 0.09030349552631378),
  ('u', 0.004192721098661423),
  ('y', 0.0007521358784288168),
  ('r', 6.647213740507141e-05),
  ('l', 3.957989065384027e-06),
  ('v', 2.812936827467638e-06),
  ('w', 2.738903503995971e-06)])</code></pre>
</div>
</div>
<div id="cell-38" class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>sim20k([<span class="st">'my most gr'</span>])[<span class="dv">0</span>], model_outputs20k[ss_data20k.string_to_idx[<span class="st">'my most gr'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('a', 0.74631267786026),
  ('i', 0.14454276859760284),
  ('o', 0.05604719743132591),
  ('e', 0.02654867246747017),
  ('n', 0.005899704992771149),
  ('c', 0.005899704992771149),
  ('v', 0.005899704992771149),
  ('d', 0.0029498524963855743),
  ('r', 0.0029498524963855743),
  ('l', 0.0029498524963855743)],
 [('a', 0.4602494537830353),
  ('e', 0.35252559185028076),
  ('o', 0.09188850224018097),
  ('i', 0.09030349552631378),
  ('u', 0.004192721098661423),
  ('y', 0.0007521358784288168),
  ('r', 6.647213740507141e-05),
  ('l', 3.957989065384027e-06),
  ('v', 2.812936827467638e-06),
  ('w', 2.738903503995971e-06)])</code></pre>
</div>
</div>
<div id="cell-39" class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_sim_strings(result: SimilarStringsResult, aggregate_over_t_is: Sequence[<span class="bu">int</span>], largest: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>    aggr_proj_out, aggr_ffwd_out <span class="op">=</span> result.aggregate_over_t_is(aggregate_over_t_is, largest<span class="op">=</span>largest)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    n_similars <span class="op">=</span> <span class="bu">len</span>(aggr_proj_out[<span class="dv">0</span>].sim_strings)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Proj Outputs"</span>)</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_similars):</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">''</span>.join([<span class="ss">f"</span><span class="sc">{</span><span class="bu">repr</span>(aggr_proj_out[block_idx].sim_strings[i])<span class="sc">:&gt;14}</span><span class="ss"> (</span><span class="sc">{</span>aggr_proj_out[block_idx]<span class="sc">.</span>distances[i]<span class="sc">:.2f}</span><span class="ss">)"</span> <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)]))</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>()</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"FFwd Outputs"</span>)</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_similars):</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">''</span>.join([<span class="ss">f"</span><span class="sc">{</span><span class="bu">repr</span>(aggr_ffwd_out[block_idx].sim_strings[i])<span class="sc">:&gt;14}</span><span class="ss"> (</span><span class="sc">{</span>aggr_ffwd_out[block_idx]<span class="sc">.</span>distances[i]<span class="sc">:.2f}</span><span class="ss">)"</span> <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-40" class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>print_sim_strings(ss_results20k_all_t_is[<span class="st">'my most gr'</span>], t_is)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Proj Outputs
    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)
    ur most gr (0.79)    ur most gr (0.95)    is most gr (2.27)     y most gr (3.56)     my most r (4.90)     my most r (2.75)
    is most gr (0.80)    ne most gr (0.96)    ur most gr (2.43)    ur most gr (3.95)     y most gr (5.00)     my most l (3.52)
    ne most gr (0.80)    he most gr (1.05)     y most gr (2.56)     r most gr (4.34)         my gr (5.38)     my most h (3.79)
    ilst my gr (0.82)    is most gr (1.06)    ne most gr (2.63)       most gr (4.51)         my sl (5.54)    my most st (3.91)
    he most gr (0.84)    e, most gr (1.27)    he most gr (2.88)       most gu (4.61)     my most g (5.54)        my mos (3.97)
    unto my gr (0.89)    o, must gr (1.35)     r most gr (2.99)       most gl (4.67)         my gh (5.69)        my mod (4.01)
    e, most gr (0.89)    t, most gr (1.36)    e, most gr (3.16)    ne most gr (4.72)     my most l (5.76)        my mot (4.04)
    t, most gr (0.90)    be past gr (1.37)     s most gr (3.18)     s most gr (4.85)    he most gr (5.85)        my mon (4.08)
    yman to gr (0.92)    yet not gr (1.51)       most gr (3.20)     e most gr (4.86)    my most st (5.86)        my mou (4.14)

FFwd Outputs
    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)
    ne most gr (0.14)    ne most gr (0.43)    ur most gr (0.75)    ur most gr (1.77)    ur most gr (2.76)    t, most gr (3.17)
    ur most gr (0.14)    ur most gr (0.44)    is most gr (0.78)    ne most gr (2.05)    he most gr (2.90)    e, most gr (3.23)
    he most gr (0.14)    he most gr (0.51)    ne most gr (0.83)    is most gr (2.23)    ne most gr (2.94)    ur most gr (3.45)
    e, most gr (0.14)    is most gr (0.57)    he most gr (0.89)    he most gr (2.56)     y most gr (2.98)     , most gr (3.49)
    ilst my gr (0.15)    t, most gr (0.57)    e, most gr (1.23)     y most gr (3.26)     r most gr (3.41)     y most gr (3.72)
    t, most gr (0.15)    e, most gr (0.58)    t, most gr (1.32)     r most gr (3.28)    is most gr (3.60)    ne most gr (3.88)
    is most gr (0.15)    ver yet gr (0.66)    do them gr (2.21)    e, most gr (3.44)     e most gr (3.75)    is most gr (3.90)
    unto my gr (0.15)     cannot gr (0.70)    im that gr (2.24)     s most gr (3.57)       most gr (3.88)    our own gr (3.95)
    o, must gr (0.16)    o, must gr (0.71)    o, must gr (2.25)     e most gr (3.70)    e, most gr (3.89)         or gr (4.04)</code></pre>
</div>
</div>
<p>Compare to just looking at t_i=-1:</p>
<div id="cell-42" class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>print_sim_strings(ss_results20k_all_t_is[<span class="st">'my most gr'</span>], [<span class="op">-</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Proj Outputs
    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)
    ur most gr (0.79)    ur most gr (0.95)    is most gr (2.27)    ur most gr (3.95)    he most gr (5.85)    my most st (3.91)
    is most gr (0.80)    ne most gr (0.96)    ur most gr (2.43)    ne most gr (4.72)    my most st (5.86)    my most sa (4.33)
    ne most gr (0.80)    he most gr (1.05)    ne most gr (2.63)    nd most gu (5.16)    ur most gr (6.43)     my most r (4.56)
    ilst my gr (0.82)    is most gr (1.06)    he most gr (2.88)    nd most gl (5.34)     my most r (6.52)     my most l (5.16)
    he most gr (0.84)    e, most gr (1.27)    e, most gr (3.16)    he most ge (5.49)    my young r (6.56)    my high bl (5.20)
    unto my gr (0.89)    o, must gr (1.35)    t, most gr (3.29)    is most gr (5.53)    my young p (6.58)    m thy moth (5.22)
    e, most gr (0.89)    t, most gr (1.36)    nd most gl (3.57)    ld most gl (5.64)    my young c (6.79)    mt my mast (5.22)
    t, most gr (0.90)    be past gr (1.37)    ld most gl (3.71)    e; most go (5.96)    my part sh (6.84)    my most he (5.34)
    yman to gr (0.92)    yet not gr (1.51)    he most ge (4.52)    e, most gr (6.00)    my young l (6.87)    my merry m (5.45)

FFwd Outputs
    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)
    ne most gr (0.14)    ne most gr (0.43)    ur most gr (0.75)    ur most gr (1.77)    ur most gr (2.76)    t, most gr (3.17)
    ur most gr (0.14)    ur most gr (0.44)    is most gr (0.78)    ne most gr (2.05)    he most gr (2.90)    e, most gr (3.23)
    he most gr (0.14)    he most gr (0.51)    ne most gr (0.83)    is most gr (2.23)    ne most gr (2.94)    ur most gr (3.45)
    e, most gr (0.14)    is most gr (0.57)    he most gr (0.89)    he most gr (2.56)    is most gr (3.60)    ne most gr (3.88)
    ilst my gr (0.15)    t, most gr (0.57)    e, most gr (1.23)    e, most gr (3.44)    e, most gr (3.89)    is most gr (3.90)
    t, most gr (0.15)    e, most gr (0.58)    t, most gr (1.32)    t, most gr (3.77)    t, most gr (4.29)    our own gr (3.95)
    is most gr (0.15)    ver yet gr (0.66)    do them gr (2.21)     common gr (3.88)    dd more gr (5.07)     but my gr (4.61)
    unto my gr (0.15)     cannot gr (0.70)    im that gr (2.24)    is more gr (4.06)     but my gr (5.27)    nto her gr (4.71)
    o, must gr (0.16)    o, must gr (0.71)    o, must gr (2.25)    dd more gr (4.06)    is more gr (5.33)    dd more gr (4.73)</code></pre>
</div>
</div>
<p>How would we do if we just used the next tokens for the prompt?</p>
<div id="cell-44" class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sim_just_next_tokens_from_prompt(prompt: <span class="bu">str</span>, next_token_map: Dict[<span class="bu">str</span>, torch.Tensor], encoding_helpers: EncodingHelpers):</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>    next_tokens <span class="op">=</span> next_token_map[prompt]</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> top_nonzero_tokens(</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>        next_tokens.<span class="bu">float</span>() <span class="op">/</span> next_tokens.<span class="bu">sum</span>(), encoding_helpers.tokenizer.itos</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    )[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-45" class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>sim_jntfp_out <span class="op">=</span> [</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    sim_just_next_tokens_from_prompt(s, next_token_map_all, encoding_helpers)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> s <span class="kw">in</span> tqdm(strings)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3e3417f2f5cc46e799a02dfa3ff5e40f","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
<div id="cell-46" class="cell">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">20000</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>topn_matches, topn_matches_any_order <span class="op">=</span> analyze_simulate_results2(strings, sim_jntfp_out, model_outputs20k)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches: </span><span class="sc">{</span>topn_matches[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches (any order): </span><span class="sc">{</span>topn_matches_any_order[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.606
Top 1 matches (any order): 0.606
Top 2 matches: 0.011
Top 2 matches (any order): 0.012
Top 3 matches: 0.002
Top 3 matches (any order): 0.001
Top 4 matches: 0.001
Top 4 matches (any order): 0.001
Top 5 matches: 0.001
Top 5 matches (any order): 0.000
Top 6 matches: 0.000
Top 6 matches (any order): 0.000
Top 7 matches: 0.000
Top 7 matches (any order): 0.000
Top 8 matches: 0.000
Top 8 matches (any order): 0.000
Top 9 matches: 0.000
Top 9 matches (any order): 0.000
Top 10 matches: 0.000
Top 10 matches (any order): 0.000</code></pre>
</div>
</div>
<p>OK, so 60% on the top 1 token, but it quickly falls off after that.</p>
<div id="cell-48" class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> unique_contributors(result: SimilarStringsResult, aggregate_over_t_is: Sequence[<span class="bu">int</span>]):</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>    aggr_proj_out, aggr_ffwd_out <span class="op">=</span> result.aggregate_over_t_is(aggregate_over_t_is)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    s_to_next_tokens_map <span class="op">=</span> {}</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> s <span class="kw">in</span> result.embs.sim_strings:</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>        s_to_next_tokens_map[s] <span class="op">=</span> next_token_map_all[s]</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer):</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> s <span class="kw">in</span> aggr_proj_out[block_idx].sim_strings:</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>            s_to_next_tokens_map[s] <span class="op">=</span> next_token_map_all[s]</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> s <span class="kw">in</span> aggr_ffwd_out[block_idx].sim_strings:</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>            s_to_next_tokens_map[s] <span class="op">=</span> next_token_map_all[s]</span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _print(item: Tuple[<span class="bu">str</span>, torch.Tensor]):</span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a>        s, next_tokens <span class="op">=</span> item</span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a>        top_tokens <span class="op">=</span> top_nonzero_tokens(next_tokens.<span class="bu">float</span>() <span class="op">/</span> next_tokens.<span class="bu">sum</span>(), encoding_helpers.tokenizer.itos)</span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a>        tokens_str <span class="op">=</span> <span class="st">', '</span>.join([<span class="ss">f"</span><span class="sc">{</span><span class="bu">repr</span>(t)<span class="sc">:&gt;3}</span><span class="ss"> (</span><span class="sc">{</span>p<span class="sc">:.2f}</span><span class="ss">)"</span> <span class="cf">for</span> t, p <span class="kw">in</span> top_tokens])</span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"</span><span class="sc">{</span><span class="bu">repr</span>(s)<span class="sc">:&gt;14}</span><span class="ss">: </span><span class="sc">{</span>tokens_str<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> DataWrapper(s_to_next_tokens_map.items(), _print)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-49" class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>unique_contributors(ss_results20k_all_t_is[<span class="st">'my most gr'</span>], t_is).<span class="bu">print</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  'my most gr': 'a' (1.00)
  'my most sa': 'c' (1.00)
  't, most gr': 'a' (1.00)
  'my most st': 'a' (1.00)
  'e, most gr': 'a' (1.00)
  'ur most gr': 'a' (1.00)
  'is most gr': 'i' (1.00)
  'my most so': 'v' (1.00)
  'my most re': 'd' (1.00)
  'my most he': 'a' (1.00)
  'ne most gr': 'a' (1.00)
  'ilst my gr': 'o' (1.00)
  'he most gr': 'a' (1.00)
  'unto my gr': 'a' (1.00)
  'yman to gr': 'i' (1.00)
  'o, must gr': 'a' (1.00)
  'be past gr': 'i' (1.00)
  'yet not gr': 'e' (1.00)
  'ver yet gr': 'e' (1.00)
  ' cannot gr': 'e' (1.00)
   'y most gr': 'a' (1.00)
   'r most gr': 'a' (1.00)
   's most gr': 'i' (1.00)
    ' most gr': 'a' (0.89), 'i' (0.11)
  'do them gr': 'a' (1.00)
  'im that gr': 'a' (1.00)
     'most gr': 'a' (0.89), 'i' (0.11)
     'most gu': 'i' (1.00)
    ' most gl': 'a' (1.00)
   'e most gr': 'a' (1.00)
   'my most r': 'e' (1.00)
       'my gr': 'a' (0.55), 'i' (0.22), 'e' (0.16), 'o' (0.06)
       'my sl': 'e' (0.40), 'a' (0.40), 'i' (0.20)
   'my most g': 'r' (1.00)
       'my gh': 'o' (1.00)
   'my most l': 'o' (1.00)
   'my most h': 'e' (1.00)
      'my mos': 't' (1.00)
      'my mod': 'e' (1.00)
      'my mot': 'h' (1.00)
      'my mon': 'e' (1.00)
      'my mou': 't' (0.67), 'r' (0.33)
   ', most gr': 'a' (1.00)
  'our own gr': 'a' (1.00)
       'or gr': 'a' (0.56), 'e' (0.19), 'u' (0.12), 'o' (0.06), 'i' (0.06)</code></pre>
</div>
</div>
<div id="cell-50" class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> next_token_freqs_inv_distances(</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>    prompt_idxs: torch.Tensor, ss_tensors: SimilarStringsFrequencyAndDistanceData</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    emb_weight <span class="op">=</span> torch.tensor(<span class="fl">1.0</span>, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    proj_weights <span class="op">=</span> torch.tensor(</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>        [<span class="fl">1.0</span> <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_layer)], dtype<span class="op">=</span>torch.float32</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>    ).unsqueeze(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>    ffwd_weights <span class="op">=</span> torch.tensor(</span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>        [<span class="dv">1</span> <span class="op">+</span> block_idx <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer)], dtype<span class="op">=</span>torch.float32</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>    ).unsqueeze(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>    inv_emb_distances <span class="op">=</span> (<span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> ss_tensors.emb_distances[prompt_idxs, :])).unsqueeze(</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>        dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>    inv_proj_distances <span class="op">=</span> (</span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> ss_data20k_aggr.proj_distances[prompt_idxs, :, :])</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>    ).unsqueeze(dim<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a>    inv_ffwd_distances <span class="op">=</span> (</span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> ss_data20k_aggr.ffwd_distances[prompt_idxs, :, :])</span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>    ).unsqueeze(dim<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (</span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a>        (emb_weight <span class="op">*</span> ss_tensors.emb_freqs[prompt_idxs, :] <span class="op">*</span> inv_emb_distances).<span class="bu">sum</span>(</span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb60-27"><a href="#cb60-27" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb60-28"><a href="#cb60-28" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (</span>
<span id="cb60-29"><a href="#cb60-29" aria-hidden="true" tabindex="-1"></a>            proj_weights</span>
<span id="cb60-30"><a href="#cb60-30" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span> (ss_tensors.proj_freqs[prompt_idxs, :, :, :] <span class="op">*</span> inv_proj_distances).<span class="bu">sum</span>(</span>
<span id="cb60-31"><a href="#cb60-31" aria-hidden="true" tabindex="-1"></a>                dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb60-32"><a href="#cb60-32" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb60-33"><a href="#cb60-33" aria-hidden="true" tabindex="-1"></a>        ).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb60-34"><a href="#cb60-34" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (</span>
<span id="cb60-35"><a href="#cb60-35" aria-hidden="true" tabindex="-1"></a>            ffwd_weights</span>
<span id="cb60-36"><a href="#cb60-36" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span> (ss_tensors.ffwd_freqs[prompt_idxs, :, :, :] <span class="op">*</span> inv_ffwd_distances).<span class="bu">sum</span>(</span>
<span id="cb60-37"><a href="#cb60-37" aria-hidden="true" tabindex="-1"></a>                dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb60-38"><a href="#cb60-38" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb60-39"><a href="#cb60-39" aria-hidden="true" tabindex="-1"></a>        ).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb60-40"><a href="#cb60-40" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb60-41"><a href="#cb60-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> freqs <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-51" class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>sim20k_aggr_alt <span class="op">=</span> ModelSimulation(</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    ss_data<span class="op">=</span>ss_data20k_aggr,</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>    compute_next_token_freqs<span class="op">=</span>next_token_freqs_inv_distances,</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>    encoding_helpers<span class="op">=</span>encoding_helpers,</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-52" class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>sim_outputs_alt <span class="op">=</span> sim20k_aggr_alt(strings)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-53" class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">20000</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>topn_matches, topn_matches_any_order <span class="op">=</span> analyze_simulate_results2(strings, sim_outputs_alt, model_outputs20k)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches: </span><span class="sc">{</span>topn_matches[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches (any order): </span><span class="sc">{</span>topn_matches_any_order[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.699
Top 1 matches (any order): 0.699
Top 2 matches: 0.352
Top 2 matches (any order): 0.404
Top 3 matches: 0.208
Top 3 matches (any order): 0.220
Top 4 matches: 0.141
Top 4 matches (any order): 0.136
Top 5 matches: 0.103
Top 5 matches (any order): 0.089
Top 6 matches: 0.083
Top 6 matches (any order): 0.055
Top 7 matches: 0.065
Top 7 matches (any order): 0.032
Top 8 matches: 0.053
Top 8 matches (any order): 0.020
Top 9 matches: 0.043
Top 9 matches (any order): 0.012
Top 10 matches: 0.036
Top 10 matches (any order): 0.005</code></pre>
</div>
</div>
<p>It does worse at the top but a little better further down.</p>
<p>Try a few other functions:</p>
<div id="cell-56" class="cell">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> next_token_freqs_only_last_ffwd(</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    prompt_idxs: torch.Tensor, ss_data: SimilarStringsFrequencyAndDistanceData</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> ss_data.ffwd_freqs[prompt_idxs, <span class="op">-</span><span class="dv">1</span>, :, :].<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> freqs <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-57" class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> next_token_freqs_only_last_ffwd_with_distances(</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    prompt_idxs: torch.Tensor, ss_data: SimilarStringsFrequencyAndDistanceData</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>    inv_ffwd_distances <span class="op">=</span> (</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> ss_data20k_aggr.ffwd_distances[prompt_idxs, <span class="op">-</span><span class="dv">1</span>, :])</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    ).unsqueeze(dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (inv_ffwd_distances <span class="op">*</span> ss_data.ffwd_freqs[prompt_idxs, <span class="op">-</span><span class="dv">1</span>, :, :]).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> freqs <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-58" class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> try_next_token_freqs_function(</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_fn: ComputeNextTokenFreqs,</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>    ss_data: SimilarStringsFrequencyAndDistanceData,</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>    strings: Sequence[<span class="bu">str</span>],</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>    model_outputs: Sequence[Tuple[<span class="bu">str</span>, <span class="bu">float</span>]],</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>    sim <span class="op">=</span> ModelSimulation(</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>        ss_data<span class="op">=</span>ss_data,</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>        compute_next_token_freqs<span class="op">=</span>next_token_freqs_fn,</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        encoding_helpers<span class="op">=</span>encoding_helpers,</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>    sim_outputs <span class="op">=</span> sim(strings)</span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>    n_samples <span class="op">=</span> <span class="bu">len</span>(strings)</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>    topn_matches, topn_matches_any_order <span class="op">=</span> analyze_simulate_results2(</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>        strings, sim_outputs, model_outputs</span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches: </span><span class="sc">{</span>topn_matches[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(</span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"Top </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> matches (any order): </span><span class="sc">{</span>topn_matches_any_order[i] <span class="op">/</span> n_samples<span class="sc">:.3f}</span><span class="ss">"</span></span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-59" class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_only_last_ffwd, ss_data20k, strings, model_outputs20k</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.744
Top 1 matches (any order): 0.744
Top 2 matches: 0.311
Top 2 matches (any order): 0.362
Top 3 matches: 0.134
Top 3 matches (any order): 0.148
Top 4 matches: 0.071
Top 4 matches (any order): 0.070
Top 5 matches: 0.037
Top 5 matches (any order): 0.030
Top 6 matches: 0.020
Top 6 matches (any order): 0.010
Top 7 matches: 0.011
Top 7 matches (any order): 0.003
Top 8 matches: 0.007
Top 8 matches (any order): 0.001
Top 9 matches: 0.004
Top 9 matches (any order): 0.001
Top 10 matches: 0.002
Top 10 matches (any order): 0.000</code></pre>
</div>
</div>
<p>This is nearly as good as the best baseline results for top1 and top2, but drops off after that.</p>
<div id="cell-61" class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_only_last_ffwd_with_distances, ss_data20k_aggr, strings, model_outputs20k</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.676
Top 1 matches (any order): 0.676
Top 2 matches: 0.253
Top 2 matches (any order): 0.300
Top 3 matches: 0.109
Top 3 matches (any order): 0.117
Top 4 matches: 0.057
Top 4 matches (any order): 0.054
Top 5 matches: 0.032
Top 5 matches (any order): 0.024
Top 6 matches: 0.017
Top 6 matches (any order): 0.009
Top 7 matches: 0.010
Top 7 matches (any order): 0.004
Top 8 matches: 0.006
Top 8 matches (any order): 0.002
Top 9 matches: 0.005
Top 9 matches (any order): 0.001
Top 10 matches: 0.003
Top 10 matches (any order): 0.001</code></pre>
</div>
</div>
<p>For a single example, is it possible to choose weights that give you the same output as the model?</p>
<div id="cell-63" class="cell">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>strings[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>['is dreams,',
 'by present',
 's eyes may',
 'eart of ho',
 ' man, as I',
 'mour in a ',
 'LLA:\nAnd h',
 ' crave no ',
 'o find the',
 'e,\nplease ']</code></pre>
</div>
</div>
<div id="cell-64" class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>prompt_idx <span class="op">=</span> ss_data20k.string_to_idx[prompt]</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>prompt_idxs <span class="op">=</span> torch.tensor([prompt_idx], dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>emb_freqs <span class="op">=</span> ss_data20k.emb_freqs[prompt_idxs, :, :]</span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>proj_freqs <span class="op">=</span> ss_data20k.proj_freqs[prompt_idxs, :, :, :]</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>ffwd_freqs <span class="op">=</span> ss_data20k.ffwd_freqs[prompt_idxs, :, :, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-65" class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> encoding_helpers.tokenize_string(prompt)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>logits, _ <span class="op">=</span> m(tokens)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>model_output <span class="op">=</span> F.softmax(logits[:, <span class="op">-</span><span class="dv">1</span>, :], dim<span class="op">=-</span><span class="dv">1</span>).squeeze(dim<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-66" class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1337</span>) <span class="co"># Ensure stable random values</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize all the learnable params</span></span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>emb_weight_param <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>    torch.randn(<span class="dv">1</span>, dtype<span class="op">=</span>torch.float32), requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>proj_weights_param <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>    torch.randn(n_layer, <span class="dv">1</span>, dtype<span class="op">=</span>torch.float32), requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>ffwd_weights_param <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>    torch.randn(n_layer, <span class="dv">1</span>, dtype<span class="op">=</span>torch.float32), requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-67" class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">3e-3</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>max_iters <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>eval_interval<span class="op">=</span><span class="dv">500</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-68" class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW([emb_weight_param, proj_weights_param, ffwd_weights_param], lr<span class="op">=</span>learning_rate)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>eval_iters <span class="op">=</span> max_iters <span class="op">//</span> <span class="dv">10</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> []</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> tqdm(<span class="bu">range</span>(max_iters)):</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>        (emb_weight_param <span class="op">*</span> emb_freqs).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (proj_weights_param <span class="op">*</span> proj_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (ffwd_weights_param <span class="op">*</span> ffwd_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> freqs.squeeze(dim<span class="op">=</span><span class="dv">0</span>).<span class="bu">float</span>() <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> torch.norm(probs <span class="op">-</span> model_output, p<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a>    losses.append(loss.item())</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> step <span class="op">%</span> eval_iters <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"step </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">, loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb78-22"><a href="#cb78-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-23"><a href="#cb78-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Take a step</span></span>
<span id="cb78-24"><a href="#cb78-24" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb78-25"><a href="#cb78-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-26"><a href="#cb78-26" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb78-27"><a href="#cb78-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-28"><a href="#cb78-28" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> loss.detach()</span>
<span id="cb78-29"><a href="#cb78-29" aria-hidden="true" tabindex="-1"></a>    emb_freqs <span class="op">=</span> emb_freqs.detach()</span>
<span id="cb78-30"><a href="#cb78-30" aria-hidden="true" tabindex="-1"></a>    proj_freqs <span class="op">=</span> proj_freqs.detach()</span>
<span id="cb78-31"><a href="#cb78-31" aria-hidden="true" tabindex="-1"></a>    ffwd_freqs <span class="op">=</span> ffwd_freqs.detach()</span>
<span id="cb78-32"><a href="#cb78-32" aria-hidden="true" tabindex="-1"></a>    model_output <span class="op">=</span> model_output.detach()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e2c4b57ae6f4dc9890ecce93ea64be7","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>step 0, loss: 0.437
step 1000, loss: 0.017
step 2000, loss: 0.005
step 3000, loss: 0.005
step 4000, loss: 0.005
step 5000, loss: 0.005
step 6000, loss: 0.005
step 7000, loss: 0.005
step 8000, loss: 0.005
step 9000, loss: 0.005</code></pre>
</div>
</div>
<div id="cell-69" class="cell">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>        (emb_weight_param <span class="op">*</span> emb_freqs).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (proj_weights_param <span class="op">*</span> proj_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (ffwd_weights_param <span class="op">*</span> ffwd_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> freqs.squeeze(dim<span class="op">=</span><span class="dv">0</span>).<span class="bu">float</span>() <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>    top_nonzero_tokens(probs, encoding_helpers.tokenizer.itos)[:<span class="dv">10</span>],</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a>    top_nonzero_tokens(model_output, encoding_helpers.tokenizer.itos)[:<span class="dv">10</span>]</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('a', 0.4609237313270569),
  ('e', 0.35285136103630066),
  ('o', 0.09236107766628265),
  ('i', 0.09082776308059692),
  ('v', 0.0006160509656183422),
  ('r', 0.0005453210324048996),
  ('l', 0.0005453210324048996),
  ('n', 0.0005146691692061722),
  ('c', 0.0005067135789431632),
  ('d', 0.0003080254828091711)],
 [('a', 0.4602494537830353),
  ('e', 0.35252559185028076),
  ('o', 0.09188850224018097),
  ('i', 0.09030349552631378),
  ('u', 0.004192721098661423),
  ('y', 0.0007521358784288168),
  ('r', 6.647213740507141e-05),
  ('l', 3.957989065384027e-06),
  ('v', 2.812936827467638e-06),
  ('w', 2.738903503995971e-06)])</code></pre>
</div>
</div>
<p>What if we tried these weights for everything?</p>
<div id="cell-71" class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>emb_weight_param.data, proj_weights_param.data, ffwd_weights_param.data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([-1.0925]),
 tensor([[ 0.0070],
         [-0.7119],
         [ 1.1149],
         [ 0.0808],
         [-0.0404],
         [-0.6956]]),
 tensor([[-0.1006],
         [ 0.2627],
         [ 0.0467],
         [ 0.1357],
         [ 0.6802],
         [-1.1193]]))</code></pre>
</div>
</div>
<div id="cell-72" class="cell">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try a run using these weights for everything</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> next_token_freqs_progressive_learned_weights(</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    prompt_idxs: torch.Tensor, ss_data: SimilarStringsFrequencyAndDistanceData</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>    emb_weight <span class="op">=</span> emb_weight_param.data</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>    proj_weights <span class="op">=</span> proj_weights_param.data</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>    ffwd_weights <span class="op">=</span> ffwd_weights_param.data</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (</span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>        (emb_weight <span class="op">*</span> ss_data.emb_freqs[prompt_idxs, :]).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (proj_weights <span class="op">*</span> ss_data.proj_freqs[prompt_idxs, :, :, :].<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (ffwd_weights <span class="op">*</span> ss_data.ffwd_freqs[prompt_idxs, :, :, :].<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(</span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb84-18"><a href="#cb84-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> freqs <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb84-19"><a href="#cb84-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-20"><a href="#cb84-20" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb84-21"><a href="#cb84-21" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_learned_weights, ss_data20k, strings, model_outputs20k</span>
<span id="cb84-22"><a href="#cb84-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.548
Top 1 matches (any order): 0.548
Top 2 matches: 0.181
Top 2 matches (any order): 0.184
Top 3 matches: 0.098
Top 3 matches (any order): 0.050
Top 4 matches: 0.072
Top 4 matches (any order): 0.021
Top 5 matches: 0.060
Top 5 matches (any order): 0.007
Top 6 matches: 0.050
Top 6 matches (any order): 0.004
Top 7 matches: 0.040
Top 7 matches (any order): 0.002
Top 8 matches: 0.036
Top 8 matches (any order): 0.002
Top 9 matches: 0.031
Top 9 matches (any order): 0.001
Top 10 matches: 0.022
Top 10 matches (any order): 0.000</code></pre>
</div>
</div>
<p>Ok, clearly very bad.</p>
<section id="attempt-to-learn-weights-over-a-large-number-of-examples" class="level2">
<h2 class="anchored" data-anchor-id="attempt-to-learn-weights-over-a-large-number-of-examples">Attempt to learn weights over a large number of examples</h2>
<div id="cell-75" class="cell">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_batch(</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>    batch_size: <span class="bu">int</span>,</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>    ss_data: SimilarStringsFrequencyAndDistanceData,</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>    split: <span class="bu">str</span> <span class="op">=</span> <span class="st">'train'</span>,</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    train_pct: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>    n_train <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(ss_data.string_to_idx) <span class="op">*</span> train_pct)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>    low <span class="op">=</span> <span class="dv">0</span> <span class="cf">if</span> split <span class="op">==</span> <span class="st">'train'</span> <span class="cf">else</span> n_train</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a>    high <span class="op">=</span> n_train <span class="cf">if</span> split <span class="op">==</span> <span class="st">'train'</span> <span class="cf">else</span> <span class="bu">len</span>(ss_data.string_to_idx)</span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>    prompt_idxs <span class="op">=</span> torch.randint(</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>        low<span class="op">=</span>low, high<span class="op">=</span>high, size<span class="op">=</span>(batch_size,), dtype<span class="op">=</span>torch.<span class="bu">long</span></span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>    batch_strings <span class="op">=</span> [ss_data.strings[i.item()] <span class="cf">for</span> i <span class="kw">in</span> prompt_idxs]</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>    emb_freqs <span class="op">=</span> ss_data.emb_freqs[prompt_idxs, :, :]</span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>    proj_freqs <span class="op">=</span> ss_data.proj_freqs[prompt_idxs, :, :, :]</span>
<span id="cb86-18"><a href="#cb86-18" aria-hidden="true" tabindex="-1"></a>    ffwd_freqs <span class="op">=</span> ss_data.ffwd_freqs[prompt_idxs, :, :, :]</span>
<span id="cb86-19"><a href="#cb86-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-20"><a href="#cb86-20" aria-hidden="true" tabindex="-1"></a>    tokens <span class="op">=</span> encoding_helpers.tokenize_strings(batch_strings)</span>
<span id="cb86-21"><a href="#cb86-21" aria-hidden="true" tabindex="-1"></a>    logits, _ <span class="op">=</span> m(tokens)</span>
<span id="cb86-22"><a href="#cb86-22" aria-hidden="true" tabindex="-1"></a>    model_output <span class="op">=</span> F.softmax(logits[:, <span class="op">-</span><span class="dv">1</span>, :], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb86-23"><a href="#cb86-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-24"><a href="#cb86-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb86-25"><a href="#cb86-25" aria-hidden="true" tabindex="-1"></a>        emb_freqs.detach(),</span>
<span id="cb86-26"><a href="#cb86-26" aria-hidden="true" tabindex="-1"></a>        proj_freqs.detach(),</span>
<span id="cb86-27"><a href="#cb86-27" aria-hidden="true" tabindex="-1"></a>        ffwd_freqs.detach(),</span>
<span id="cb86-28"><a href="#cb86-28" aria-hidden="true" tabindex="-1"></a>        model_output.detach(),</span>
<span id="cb86-29"><a href="#cb86-29" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-76" class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1337</span>) <span class="co"># Ensure stable random values</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize all the learnable params</span></span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>emb_weight_param <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>    torch.randn(<span class="dv">1</span>, dtype<span class="op">=</span>torch.float32), requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>proj_weights_param <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>    torch.randn(n_layer, <span class="dv">1</span>, dtype<span class="op">=</span>torch.float32), requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>).to(device)</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>ffwd_weights_param <span class="op">=</span> torch.nn.Parameter(</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>    torch.randn(n_layer, <span class="dv">1</span>, dtype<span class="op">=</span>torch.float32), requires_grad<span class="op">=</span><span class="va">True</span></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-77" class="cell">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">3e-4</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>max_iters <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>eval_interval<span class="op">=</span><span class="dv">500</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>eval_iters <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>batch_size<span class="op">=</span><span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-78" class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="at">@torch.no_grad</span>()</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> estimate_loss():</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> {}</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> split <span class="kw">in</span> [<span class="st">'train'</span>, <span class="st">'val'</span>]:</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>        losses <span class="op">=</span> torch.zeros(eval_iters)</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(eval_iters):</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>            emb_freqs, proj_freqs, ffwd_freqs, model_output <span class="op">=</span> get_batch(batch_size, ss_data20k, split<span class="op">=</span><span class="st">'train'</span>, train_pct<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-9"><a href="#cb89-9" aria-hidden="true" tabindex="-1"></a>            freqs <span class="op">=</span> (</span>
<span id="cb89-10"><a href="#cb89-10" aria-hidden="true" tabindex="-1"></a>                (emb_weight_param <span class="op">*</span> emb_freqs).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb89-11"><a href="#cb89-11" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> (proj_weights_param <span class="op">*</span> proj_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb89-12"><a href="#cb89-12" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> (ffwd_weights_param <span class="op">*</span> ffwd_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb89-13"><a href="#cb89-13" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb89-14"><a href="#cb89-14" aria-hidden="true" tabindex="-1"></a>            probs <span class="op">=</span> freqs.<span class="bu">float</span>() <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb89-15"><a href="#cb89-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-16"><a href="#cb89-16" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> torch.norm(probs <span class="op">-</span> model_output, p<span class="op">=</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb89-17"><a href="#cb89-17" aria-hidden="true" tabindex="-1"></a>            losses[k] <span class="op">=</span> loss.item()</span>
<span id="cb89-18"><a href="#cb89-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-19"><a href="#cb89-19" aria-hidden="true" tabindex="-1"></a>        out[split] <span class="op">=</span> losses.mean()</span>
<span id="cb89-20"><a href="#cb89-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-79" class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW([emb_weight_param, proj_weights_param, ffwd_weights_param], lr<span class="op">=</span>learning_rate)</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> tqdm(<span class="bu">range</span>(max_iters)):</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>    emb_freqs, proj_freqs, ffwd_freqs, model_output <span class="op">=</span> get_batch(batch_size, ss_data20k, split<span class="op">=</span><span class="st">'train'</span>, train_pct<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a>        (emb_weight_param <span class="op">*</span> emb_freqs).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (proj_weights_param <span class="op">*</span> proj_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (ffwd_weights_param <span class="op">*</span> ffwd_freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> freqs.<span class="bu">float</span>() <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> torch.norm(probs <span class="op">-</span> model_output, p<span class="op">=</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>).<span class="bu">sum</span>()</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> step <span class="op">%</span> eval_interval <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>        losses <span class="op">=</span> estimate_loss()</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"step </span><span class="sc">{</span>step<span class="sc">}</span><span class="ss">, train loss: </span><span class="sc">{</span>losses[<span class="st">'train'</span>]<span class="sc">:.3f}</span><span class="ss">, val_loss </span><span class="sc">{</span>losses[<span class="st">'val'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Take a step</span></span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-24"><a href="#cb90-24" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"260075cfe1d34ab7b24908f9d480bfbc","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>step 0, train loss: 18.787, val_loss 18.656
step 500, train loss: 18.488, val_loss 18.526
step 1000, train loss: 18.462, val_loss 18.536
step 1500, train loss: 18.320, val_loss 18.076
step 2000, train loss: 18.156, val_loss 18.145
step 2500, train loss: 18.047, val_loss 18.269
step 3000, train loss: 18.095, val_loss 18.123
step 3500, train loss: 18.156, val_loss 18.288
step 4000, train loss: 18.011, val_loss 17.939
step 4500, train loss: 17.811, val_loss 18.024
step 5000, train loss: 18.163, val_loss 18.125
step 5500, train loss: 18.144, val_loss 18.114
step 6000, train loss: 18.147, val_loss 18.117
step 6500, train loss: 17.959, val_loss 18.084
step 7000, train loss: 18.106, val_loss 18.113
step 7500, train loss: 17.988, val_loss 17.954
step 8000, train loss: 18.221, val_loss 18.156
step 8500, train loss: 18.161, val_loss 18.105
step 9000, train loss: 18.026, val_loss 18.064
step 9500, train loss: 18.170, val_loss 18.122</code></pre>
</div>
</div>
<div id="cell-80" class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Try a run using these weights for everything</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> next_token_freqs_progressive_learned_weights(</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>    prompt_idxs: torch.Tensor, ss_data: SimilarStringsFrequencyAndDistanceData</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>    emb_weight <span class="op">=</span> emb_weight_param.data</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>    proj_weights <span class="op">=</span> proj_weights_param.data</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>    ffwd_weights <span class="op">=</span> ffwd_weights_param.data</span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a>    freqs <span class="op">=</span> (</span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a>        (emb_weight <span class="op">*</span> ss_data.emb_freqs[prompt_idxs, :]).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (proj_weights <span class="op">*</span> ss_data.proj_freqs[prompt_idxs, :, :, :].<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(</span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> (ffwd_weights <span class="op">*</span> ss_data.ffwd_freqs[prompt_idxs, :, :, :].<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>)).<span class="bu">sum</span>(</span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a>            dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb92-17"><a href="#cb92-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb92-18"><a href="#cb92-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> freqs <span class="op">/</span> freqs.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb92-19"><a href="#cb92-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-20"><a href="#cb92-20" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb92-21"><a href="#cb92-21" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_learned_weights, ss_data20k, strings, model_outputs20k</span>
<span id="cb92-22"><a href="#cb92-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.772
Top 1 matches (any order): 0.772
Top 2 matches: 0.403
Top 2 matches (any order): 0.458
Top 3 matches: 0.221
Top 3 matches (any order): 0.251
Top 4 matches: 0.149
Top 4 matches (any order): 0.156
Top 5 matches: 0.111
Top 5 matches (any order): 0.102
Top 6 matches: 0.088
Top 6 matches (any order): 0.065
Top 7 matches: 0.066
Top 7 matches (any order): 0.037
Top 8 matches: 0.052
Top 8 matches (any order): 0.021
Top 9 matches: 0.045
Top 9 matches (any order): 0.013
Top 10 matches: 0.033
Top 10 matches (any order): 0.006</code></pre>
</div>
</div>
<p>This is definitely the best result for top 2 we’ve seen and very nearly the best for top1.</p>
<div id="cell-82" class="cell">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a>emb_weight_param.data, proj_weights_param.data, ffwd_weights_param.data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(tensor([-0.0092]),
 tensor([[ 0.0223],
         [-0.1555],
         [ 0.0149],
         [ 0.0122],
         [-0.0932],
         [-0.0848]]),
 tensor([[-0.5732],
         [-0.7713],
         [-0.6631],
         [-0.7545],
         [-1.1689],
         [-2.0063]]))</code></pre>
</div>
</div>
<div id="cell-83" class="cell">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>sim_learned_weights <span class="op">=</span> ModelSimulation(</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>    ss_data<span class="op">=</span>ss_data20k,</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a>    compute_next_token_freqs<span class="op">=</span>next_token_freqs_progressive_learned_weights,</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a>    encoding_helpers<span class="op">=</span>encoding_helpers,</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-84" class="cell">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>sim_learned_weights([<span class="st">'my most gr'</span>])[<span class="dv">0</span>], model_outputs20k[ss_data20k.string_to_idx[<span class="st">'my most gr'</span>]], sim20k([<span class="st">'my most gr'</span>])[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>([('a', 0.7675697803497314),
  ('i', 0.14597564935684204),
  ('o', 0.055422890931367874),
  ('e', 0.027286706492304802),
  ('c', 0.0012530256062746048),
  ('r', 0.0012431245995685458),
  ('l', 0.0012431245995685458),
  ('v', 0.0002444349229335785),
  ('d', 0.00012221746146678925),
  ('3', -0.0)],
 [('a', 0.4602494537830353),
  ('e', 0.35252559185028076),
  ('o', 0.09188850224018097),
  ('i', 0.09030349552631378),
  ('u', 0.004192721098661423),
  ('y', 0.0007521358784288168),
  ('r', 6.647213740507141e-05),
  ('l', 3.957989065384027e-06),
  ('v', 2.812936827467638e-06),
  ('w', 2.738903503995971e-06)],
 [('a', 0.74631267786026),
  ('i', 0.14454276859760284),
  ('o', 0.05604719743132591),
  ('e', 0.02654867246747017),
  ('n', 0.005899704992771149),
  ('c', 0.005899704992771149),
  ('v', 0.005899704992771149),
  ('d', 0.0029498524963855743),
  ('r', 0.0029498524963855743),
  ('l', 0.0029498524963855743)])</code></pre>
</div>
</div>
</section>
<section id="cosine-similarity-results" class="level2">
<h2 class="anchored" data-anchor-id="cosine-similarity-results">Cosine Similarity Results</h2>
<p>The cosine similarity data generation ran overnight. Let’s look at the results.</p>
<div id="cell-87" class="cell">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>ss_cos <span class="op">=</span> SimilarStringsExperiment(</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a>    exp10.output_dir <span class="op">/</span> <span class="st">'similar_strings_cos'</span>,</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>    encoding_helpers,</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>t_is <span class="op">=</span> [<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>ss_cos_results <span class="op">=</span> ss_cos.load_results_for_strings(strings, load_t_is<span class="op">=</span>t_is)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-88" class="cell">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>t_is <span class="op">=</span> [<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>ss_data_cos <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ss_cos_results,</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>t_is,</span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>    largest<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb100-7"><a href="#cb100-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb100-8"><a href="#cb100-8" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb100-9"><a href="#cb100-9" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_ffwd_weight, ss_data_cos, strings, model_outputs20k</span>
<span id="cb100-10"><a href="#cb100-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.750
Top 1 matches (any order): 0.750
Top 2 matches: 0.366
Top 2 matches (any order): 0.415
Top 3 matches: 0.191
Top 3 matches (any order): 0.207
Top 4 matches: 0.134
Top 4 matches (any order): 0.125
Top 5 matches: 0.096
Top 5 matches (any order): 0.077
Top 6 matches: 0.077
Top 6 matches (any order): 0.045
Top 7 matches: 0.060
Top 7 matches (any order): 0.024
Top 8 matches: 0.050
Top 8 matches (any order): 0.014
Top 9 matches: 0.040
Top 9 matches (any order): 0.008
Top 10 matches: 0.033
Top 10 matches (any order): 0.003</code></pre>
</div>
</div>
<p>The results are pretty similar to the best we saw with Eucledian distance. But here’s something interesting: let’s flip the <code>largest</code> param so that it’s not looking for the largest cosine similarity, but the smallest. This will mean we’re looking at less similar samples.</p>
<div id="cell-90" class="cell">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>t_is <span class="op">=</span> [<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>ss_data_cos <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ss_cos_results,</span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>t_is,</span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>    largest<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb102-7"><a href="#cb102-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-91" class="cell">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_ffwd_weight, ss_data_cos, strings, model_outputs20k</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.783
Top 1 matches (any order): 0.783
Top 2 matches: 0.422
Top 2 matches (any order): 0.484
Top 3 matches: 0.233
Top 3 matches (any order): 0.271
Top 4 matches: 0.170
Top 4 matches (any order): 0.181
Top 5 matches: 0.128
Top 5 matches (any order): 0.119
Top 6 matches: 0.101
Top 6 matches (any order): 0.076
Top 7 matches: 0.083
Top 7 matches (any order): 0.041
Top 8 matches: 0.069
Top 8 matches (any order): 0.029
Top 9 matches: 0.059
Top 9 matches (any order): 0.018
Top 10 matches: 0.051
Top 10 matches (any order): 0.011</code></pre>
</div>
</div>
<p>The results actually get BETTER! In fact, these are the best results yet.</p>
<p>(I’m writing this up as if it were an intentional experiment but in fact I found this by accident. At first when I ran the cosine similarity results, I didn’t have a <code>largest</code> parameter to pass into <code>SimilarStringsFrequencyAndDistanceData.from_results()</code>. So it was in fact doing the <code>largest=False</code> version. I got the results above. Then I fixed it to thread <code>largeest</code> through and the results got worse. And that inspired this line of thought.)</p>
<p>This suggests I’ve gotten something fundamentally wrong thus far. I’ve been trying methods to find more and more similar values: looking for more similar values amongst shorter strings, investigating cosine similarity as a potentially better metric. But maybe the model is actually a much wider net i.e.&nbsp;the predictions from a given embedding are an aggregate of similar values from a much wider range.</p>
<p>This explains why efforts to produce more similar values yield worse results e.g.&nbsp;the results from the aggregation of t_is from 3-9 produces more similar values, but worse overall results. Perhaps there just isn’t enough variety in the most similar values to produce final results that resemble the model’s predictions.</p>
<p>Let’s try a few experiments to test this hypothesis.</p>
<p>First, let’s look at the cosine results with <code>largest=True</code> but only considering t_i=9:</p>
<div id="cell-94" class="cell">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>t_is <span class="op">=</span> [<span class="dv">9</span>]</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>ss_cos_results_only9 <span class="op">=</span> ss_cos.load_results_for_strings(strings, load_t_is<span class="op">=</span>t_is)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-95" class="cell">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>ss_data_cos <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ss_cos_results,</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>t_is,</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    largest<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-96" class="cell">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_ffwd_weight, ss_data_cos, strings, model_outputs20k</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.775
Top 1 matches (any order): 0.775
Top 2 matches: 0.397
Top 2 matches (any order): 0.452
Top 3 matches: 0.211
Top 3 matches (any order): 0.237
Top 4 matches: 0.143
Top 4 matches (any order): 0.142
Top 5 matches: 0.103
Top 5 matches (any order): 0.087
Top 6 matches: 0.082
Top 6 matches (any order): 0.055
Top 7 matches: 0.065
Top 7 matches (any order): 0.029
Top 8 matches: 0.054
Top 8 matches (any order): 0.021
Top 9 matches: 0.047
Top 9 matches (any order): 0.010
Top 10 matches: 0.038
Top 10 matches (any order): 0.005</code></pre>
</div>
</div>
<p>This is better than the results from aggregating across t_is 7-9 with <code>largest=True</code>.</p>
<p>What happens if we try <code>largest=False</code> with t_i=9?</p>
<div id="cell-99" class="cell">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>ss_data_cos <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ss_cos_results,</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>t_is,</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>    largest<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_ffwd_weight, ss_data_cos, strings, model_outputs20k</span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.783
Top 1 matches (any order): 0.783
Top 2 matches: 0.422
Top 2 matches (any order): 0.484
Top 3 matches: 0.233
Top 3 matches (any order): 0.271
Top 4 matches: 0.170
Top 4 matches (any order): 0.181
Top 5 matches: 0.128
Top 5 matches (any order): 0.119
Top 6 matches: 0.101
Top 6 matches (any order): 0.076
Top 7 matches: 0.083
Top 7 matches (any order): 0.041
Top 8 matches: 0.069
Top 8 matches (any order): 0.029
Top 9 matches: 0.059
Top 9 matches (any order): 0.018
Top 10 matches: 0.051
Top 10 matches (any order): 0.011</code></pre>
</div>
</div>
<p>This is better than <code>largest=True</code> but worse than when we aggregated ti_s 7-9. Probably because amonst the t_i=7 and t_i=8 values there were some less similar candidates.</p>
<p>Let’s try the Euclidean distance version, but flip <code>largest=True</code>.</p>
<div id="cell-102" class="cell">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>t_is<span class="op">=</span>[<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>ss_data20k_aggr_backwards <span class="op">=</span> SimilarStringsFrequencyAndDistanceData.from_results(</span>
<span id="cb111-3"><a href="#cb111-3" aria-hidden="true" tabindex="-1"></a>    ss_results<span class="op">=</span>ss_results20k_all_t_is,</span>
<span id="cb111-4"><a href="#cb111-4" aria-hidden="true" tabindex="-1"></a>    next_token_map<span class="op">=</span>next_token_map_all,</span>
<span id="cb111-5"><a href="#cb111-5" aria-hidden="true" tabindex="-1"></a>    aggregate_over_t_is<span class="op">=</span>t_is,</span>
<span id="cb111-6"><a href="#cb111-6" aria-hidden="true" tabindex="-1"></a>    largest<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb111-7"><a href="#cb111-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb111-8"><a href="#cb111-8" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb111-9"><a href="#cb111-9" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_ffwd_weight, ss_data20k_aggr_backwards, strings, model_outputs20k</span>
<span id="cb111-10"><a href="#cb111-10" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.783
Top 1 matches (any order): 0.783
Top 2 matches: 0.426
Top 2 matches (any order): 0.487
Top 3 matches: 0.236
Top 3 matches (any order): 0.275
Top 4 matches: 0.171
Top 4 matches (any order): 0.185
Top 5 matches: 0.126
Top 5 matches (any order): 0.120
Top 6 matches: 0.102
Top 6 matches (any order): 0.080
Top 7 matches: 0.082
Top 7 matches (any order): 0.045
Top 8 matches: 0.072
Top 8 matches (any order): 0.032
Top 9 matches: 0.060
Top 9 matches (any order): 0.019
Top 10 matches: 0.052
Top 10 matches (any order): 0.009</code></pre>
</div>
</div>
<p>I tried this several times, and it seems the sweet spot is with t_is=[7, 8, 9]. If you include smaller t_is, the results get progressively worse. Which suggests there is some upper bound to the distance that yields best results. Let’s see if we can hone in on the sweet spot.</p>
<div id="cell-104" class="cell">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>print_sim_strings(ss_results20k_all_t_is[<span class="st">'my most gr'</span>], aggregate_over_t_is<span class="op">=</span>[<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>], largest<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Proj Outputs
    'om is gr' (3.76)    ' dost gi' (4.09)    'st my gr' (6.16)    'must giv' (6.67)    'ost my c' (7.47)  'my merry m' (5.45)
    'at is gr' (3.75)    'uldst gi' (4.09)    ' some gr' (6.10)    ' many ge' (6.64)    'my own d' (7.46)  'my most he' (5.34)
    'on my gu' (3.75)    'heart go' (4.07)    ' more gr' (6.00)    ' many gu' (6.64)    'ms thy c' (7.41)   'm my moth' (5.25)
    ' dost gu' (3.72)    'canst gi' (4.04)    'ommon gr' (5.95)    'most gui' (6.42)    'y most g' (7.41)  'mt my mast' (5.22)
    's not gu' (3.71)    ' last go' (4.03)    ' most gu' (5.83)   ', most gr' (6.13)    'most gen' (7.38)  'm thy moth' (5.22)
    ' most gr' (3.68)    ' most go' (4.03)    ' most go' (5.79)  'e, most gr' (6.00)    's most r' (7.25)    'm thy mo' (5.21)
    'or my gu' (3.68)    ' most gi' (4.00)   ' most\ngl' (5.57)  'e; most go' (5.96)    'e most r' (7.16)    'my misfo' (5.20)
    'nt is gu' (3.67)   '\nMust gi' (3.94)   's more gr' (5.57)   'o most go' (5.81)    ' most gr' (7.08)  'my high bl' (5.20)
    ' must gr' (3.64)    ' must gi' (3.92)   'd most gu' (5.55)  'ld most gl' (5.64)  'my young l' (6.87)   'mes my br' (5.18)
    ' most gu' (3.55)    ' must go' (3.83)   'common gr' (5.48)    'most gla' (5.57)   'r most gr' (6.87)    'mt my ma' (5.17)

FFwd Outputs
   'e stirs: ' (6.66)   'm that gr' (6.03)    't not gr' (4.03)    ' many gr' (5.31)    'om my gr' (6.22)    'rk my gr' (5.52)
   'h still: ' (6.66)   'n that gr' (6.03)    'es to gr' (4.03)    ' more gr' (5.27)    'ge or gr' (6.19)   'ty nor gr' (5.42)
   's hands: ' (6.66)   ' great gr' (6.03)    ' past gr' (4.03)    'ut my gr' (5.26)    'at my gr' (6.12)   'on her gr' (5.41)
   'o it is: ' (6.66)   'ferent gr' (6.02)    'ur to gr' (4.02)    ' good gr' (5.25)    'steel gr' (6.11)   'or old gr' (5.40)
   ' sights: ' (6.66)   'ng but gr' (6.02)    ' must gr' (4.01)    ' made gr' (5.20)    'is my gr' (6.10)    'as my gr' (5.37)
   ', it is: ' (6.65)   's most gr' (6.02)    'd not gr' (3.99)    'r own gr' (5.17)    'in me gr' (5.92)   'o many gr' (5.36)
   'r it is: ' (6.65)   'r most gr' (6.01)    'l not gr' (3.98)    ' some gr' (5.14)   ' to my gr' (5.92)    'ot my gr' (5.33)
   't it is: ' (6.64)   'ervant gr' (6.00)    ' fast gr' (3.97)    '-made gr' (5.06)    'ot my gr' (5.91)    ' many gr' (5.32)
   ' a kiss: ' (6.63)   'mphant gr' (5.99)    ' from gr' (3.97)    'ommon gr' (4.96)    'ut my gr' (5.79)   'hat my gr' (5.29)
   's it is: ' (6.63)   'cannot gr' (5.96)   'her to gr' (3.91)   'o many gr' (4.84)   'd more gr' (5.76)    'ommon gr' (5.27)</code></pre>
</div>
</div>
<div id="cell-105" class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>print_sim_strings(ss_results20k_all_t_is[<span class="st">'my most gr'</span>], aggregate_over_t_is<span class="op">=</span>[<span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>], largest<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Proj Outputs
    '.\nKing ' (4.46)     ' yet gr' (4.76)    'st my gr' (6.16)    'must giv' (6.67)    'ost my c' (7.47)  'my merry m' (5.45)
     'm to gi' (4.46)    '\nLet go' (4.75)     'some gr' (6.14)    ' many ge' (6.64)    'my own d' (7.46)  'my most he' (5.34)
     ', or gi' (4.46)     'most gi' (4.75)    ' some gr' (6.10)    ' many gu' (6.64)     ' most g' (7.41)   'm my moth' (5.25)
     'k to gi' (4.46)     'past gr' (4.73)     'm my gr' (6.06)    'most gui' (6.42)    'ms thy c' (7.41)  'mt my mast' (5.22)
     '; to gr' (4.46)     'Most go' (4.72)    ' more gr' (6.00)     'm my gr' (6.37)    'y most g' (7.41)  'm thy moth' (5.22)
    '\nFor gi' (4.46)     'fast gr' (4.72)    'ommon gr' (5.95)     'more gr' (6.31)    'most gen' (7.38)    'm thy mo' (5.21)
     'm is gr' (4.44)     'must gr' (4.71)    ' most gu' (5.83)     'most gi' (6.31)    'most\ngl' (7.37)    'my misfo' (5.20)
     ', so gi' (4.44)    '\nBut gr' (4.70)     'most go' (5.80)     'must gr' (6.16)     ' most y' (7.36)  'my high bl' (5.20)
     'From gi' (4.41)     'most gr' (4.69)    ' most go' (5.79)   ', most gr' (6.13)    ' most\ng' (7.35)   'mes my br' (5.18)
     'n, jog ' (4.33)     'Must gi' (4.69)     'more gr' (5.78)     't my gr' (6.11)    's most r' (7.25)    'mt my ma' (5.17)

FFwd Outputs
   'e stirs: ' (6.66)   'm that gr' (6.03)     'n to gr' (4.24)    ' many gr' (5.31)     'l my gr' (6.24)     'nown gr' (5.62)
   'h still: ' (6.66)   'n that gr' (6.03)     'w to gr' (4.23)    ' more gr' (5.27)     'mmon gr' (6.24)     'many gr' (5.53)
   's hands: ' (6.66)   ' great gr' (6.03)     't to gr' (4.22)    'ut my gr' (5.26)    'om my gr' (6.22)    'rk my gr' (5.52)
   'o it is: ' (6.66)   'ferent gr' (6.02)     'must gr' (4.22)    ' good gr' (5.25)     'from gr' (6.21)     ' now gr' (5.44)
   ' sights: ' (6.66)   'ng but gr' (6.02)     'mous gr' (4.20)    ' made gr' (5.20)    'ge or gr' (6.19)     ' own gr' (5.43)
   ', it is: ' (6.65)   's most gr' (6.02)     'r to gr' (4.13)    'r own gr' (5.17)    'at my gr' (6.12)     '? or gr' (5.43)
   'r it is: ' (6.65)   'r most gr' (6.01)     'l to gr' (4.12)    ' some gr' (5.14)    'steel gr' (6.11)   'ty nor gr' (5.42)
   't it is: ' (6.64)   'ervant gr' (6.00)     's to gr' (4.05)     'ttle gr' (5.07)     'teel gr' (6.10)     'ndly gr' (5.41)
   ' a kiss: ' (6.63)   'mphant gr' (5.99)     ' not gr' (4.05)     ' not gr' (5.06)    'is my gr' (6.10)   'on her gr' (5.41)
   's it is: ' (6.63)   'cannot gr' (5.96)    't not gr' (4.03)    '-made gr' (5.06)     't or gr' (5.97)   'or old gr' (5.40)</code></pre>
</div>
</div>
<p>This is a pretty crude analysis because we only have what we thought were the top 10 most similar values and we’re flipping the whether we’re looking for smallest vs largest. But these numbers give a ballpark of the distances that are worth considering.</p>
</section>
<section id="identify-a-small-sample-of-strings-that-produce-similar-results" class="level2">
<h2 class="anchored" data-anchor-id="identify-a-small-sample-of-strings-that-produce-similar-results">Identify a small sample of strings that produce similar results</h2>
<div id="cell-108" class="cell">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>sample_size <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>strings_sample <span class="op">=</span> strings[:sample_size]</span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>model_outputs_sample <span class="op">=</span> model_outputs20k[:sample_size]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-109" class="cell">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>try_next_token_freqs_function(</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>    next_token_freqs_progressive_ffwd_weight, ss_data20k_aggr_backwards, strings_sample, model_outputs_sample</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 1 matches: 0.778
Top 1 matches (any order): 0.778
Top 2 matches: 0.416
Top 2 matches (any order): 0.464
Top 3 matches: 0.212
Top 3 matches (any order): 0.266
Top 4 matches: 0.156
Top 4 matches (any order): 0.166
Top 5 matches: 0.126
Top 5 matches (any order): 0.116
Top 6 matches: 0.108
Top 6 matches (any order): 0.068
Top 7 matches: 0.094
Top 7 matches (any order): 0.032
Top 8 matches: 0.072
Top 8 matches (any order): 0.032
Top 9 matches: 0.058
Top 9 matches (any order): 0.020
Top 10 matches: 0.056
Top 10 matches (any order): 0.016</code></pre>
</div>
</div>
<p>OK, these are reasonably similar results.</p>
</section>
<section id="analysis-of-whether-there-are-similar-strings-of-smaller-length" class="level2">
<h2 class="anchored" data-anchor-id="analysis-of-whether-there-are-similar-strings-of-smaller-length">Analysis of whether there are similar strings of smaller length</h2>
<div id="cell-112" class="cell">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>slens <span class="op">=</span> [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">9</span>, <span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-113" class="cell">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>strings_n <span class="op">=</span> {</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>    n: all_unique_substrings(ts.text, n)</span>
<span id="cb121-3"><a href="#cb121-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n <span class="kw">in</span> slens</span>
<span id="cb121-4"><a href="#cb121-4" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-114" class="cell">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>next_token_maps <span class="op">=</span> {</span>
<span id="cb122-2"><a href="#cb122-2" aria-hidden="true" tabindex="-1"></a>    n: build_next_token_map(</span>
<span id="cb122-3"><a href="#cb122-3" aria-hidden="true" tabindex="-1"></a>        ts.text, prefix_len<span class="op">=</span>n, vocab_size<span class="op">=</span>tokenizer.vocab_size, stoi<span class="op">=</span>tokenizer.stoi</span>
<span id="cb122-4"><a href="#cb122-4" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb122-5"><a href="#cb122-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n <span class="kw">in</span> slens</span>
<span id="cb122-6"><a href="#cb122-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-115" class="cell">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> slens:</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">list</span>((environment.data_root <span class="op">/</span> <span class="ss">f'block_internals_results/large_files/slen</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">/'</span>).glob(<span class="st">'*'</span>)) <span class="op">==</span> []:</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Run `make block_internals_slen</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">_dataset` in the project root to generate the required dataset"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-116" class="cell">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>exps <span class="op">=</span> {</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>    n: BatchedBlockInternalsExperiment(</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>        eh<span class="op">=</span>encoding_helpers,</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>        accessors<span class="op">=</span>accessors,</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>        strings<span class="op">=</span>strings_n[n],</span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>        output_dir<span class="op">=</span>environment.data_root <span class="op">/</span> <span class="ss">f'block_internals_results/large_files/slen</span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">/'</span>,</span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb124-8"><a href="#cb124-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb124-9"><a href="#cb124-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> n <span class="kw">in</span> slens</span>
<span id="cb124-10"><a href="#cb124-10" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-117" class="cell">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_similar_strings(</span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>    prompt: <span class="bu">str</span>,</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>    block_idx: <span class="bu">int</span>,</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a>    compare_to_slen: <span class="bu">int</span>,</span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>    prompt_accessors <span class="op">=</span> BlockInternalsAccessors(prompt, encoding_helpers, accessors)</span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-8"><a href="#cb125-8" aria-hidden="true" tabindex="-1"></a>    sim_strings_comp, distances_comp <span class="op">=</span> exps[compare_to_slen].strings_with_topk_closest_proj_outputs(</span>
<span id="cb125-9"><a href="#cb125-9" aria-hidden="true" tabindex="-1"></a>        block_idx<span class="op">=</span>block_idx,</span>
<span id="cb125-10"><a href="#cb125-10" aria-hidden="true" tabindex="-1"></a>        t_i<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb125-11"><a href="#cb125-11" aria-hidden="true" tabindex="-1"></a>        queries<span class="op">=</span>prompt_accessors.proj_output(block_idx<span class="op">=</span>block_idx)[:, <span class="op">-</span><span class="dv">1</span>, :],</span>
<span id="cb125-12"><a href="#cb125-12" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb125-13"><a href="#cb125-13" aria-hidden="true" tabindex="-1"></a>        largest<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb125-14"><a href="#cb125-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb125-15"><a href="#cb125-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-16"><a href="#cb125-16" aria-hidden="true" tabindex="-1"></a>    sim_strings, distances <span class="op">=</span> exps[<span class="bu">len</span>(prompt)].strings_with_topk_closest_proj_outputs(</span>
<span id="cb125-17"><a href="#cb125-17" aria-hidden="true" tabindex="-1"></a>        block_idx<span class="op">=</span>block_idx,</span>
<span id="cb125-18"><a href="#cb125-18" aria-hidden="true" tabindex="-1"></a>        t_i<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb125-19"><a href="#cb125-19" aria-hidden="true" tabindex="-1"></a>        queries<span class="op">=</span>prompt_accessors.proj_output(block_idx<span class="op">=</span>block_idx)[:, <span class="op">-</span><span class="dv">1</span>, :],</span>
<span id="cb125-20"><a href="#cb125-20" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb125-21"><a href="#cb125-21" aria-hidden="true" tabindex="-1"></a>        largest<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb125-22"><a href="#cb125-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb125-23"><a href="#cb125-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-24"><a href="#cb125-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Length </span><span class="sc">{</span>compare_to_slen<span class="sc">}</span><span class="ss"> similars:   Length </span><span class="sc">{</span><span class="bu">len</span>(prompt)<span class="sc">}</span><span class="ss"> similars:"</span>)</span>
<span id="cb125-25"><a href="#cb125-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb125-26"><a href="#cb125-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span><span class="bu">repr</span>(sim_strings_comp[<span class="dv">0</span>][i])<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>distances_comp[i]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss">        </span><span class="sc">{</span><span class="bu">repr</span>(sim_strings[<span class="dv">0</span>][i])<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>distances[i]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After running this a bunch of times, my conclusions from this are:</p>
<ul>
<li>Yes it’s possible to find similar strings with clear patterns in shorter strings</li>
<li>The distances are greater when the strings are shorter</li>
<li>But seeing which shorter strings are similar is illuminating</li>
</ul>
<p>e.g.&nbsp;for block_idx = 1, looking at similar strings of length 5 vs same length as the prompt:</p>
<div id="cell-119" class="cell">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>compare_similar_strings(prompt, block_idx<span class="op">=</span><span class="dv">1</span>, compare_to_slen<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length 5 similars:   Length 10 similars:
'st go' 4.564        'my most gr' 0.000
'ot gl' 4.591        'ur most gr' 0.949
'st ga' 4.595        'ne most gr' 0.958
'ot ga' 4.609        'he most gr' 1.053
'st gl' 4.629        'is most gr' 1.056
'ot gr' 4.638        'e, most gr' 1.268
'st gr' 4.639        'o, must gr' 1.352
'rt go' 4.647        't, most gr' 1.361
'st gi' 4.662        'be past gr' 1.372
'et go' 4.679        'yet not gr' 1.506</code></pre>
</div>
</div>
<p>All the length 5 similar strings have `s t`` in common.</p>
<p>Now look at block 5:</p>
<div id="cell-121" class="cell">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>compare_similar_strings(prompt, block_idx<span class="op">=</span><span class="dv">5</span>, compare_to_slen<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length 5 similars:   Length 10 similars:
'my mo' 4.464        'my most gr' 0.000
'my st' 4.917        'my most st' 3.911
'my br' 4.969        'my most sa' 4.328
'my tr' 4.977        ' my most r' 4.556
'my gr' 5.039        ' my most l' 5.160
'my sw' 5.115        'my high bl' 5.198
'my sc' 5.132        'm thy moth' 5.221
'my wr' 5.140        'mt my mast' 5.225
'my bl' 5.215        'my most he' 5.338
'my tw' 5.267        'my merry m' 5.445</code></pre>
</div>
</div>
<p>Here the common pattern in the length 5 strings is <code>my</code>.</p>
<p>I think this says something. The closest length 5 strings could have been any substring of the full prompt. Seeing what gets picked must be meaningful.</p>
<p>Let’s try with length 3:</p>
<div id="cell-125" class="cell">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>compare_similar_strings(prompt, block_idx<span class="op">=</span><span class="dv">1</span>, compare_to_slen<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length 3 similars:   Length 10 similars:
' gn' 6.114        'my most gr' 0.000
' gy' 6.142        'ur most gr' 0.949
' gl' 6.156        'ne most gr' 0.958
' gr' 6.166        'he most gr' 1.053
' gu' 6.202        'is most gr' 1.056
' gh' 6.218        'e, most gr' 1.268
' go' 6.231        'o, must gr' 1.352
' ga' 6.232        't, most gr' 1.361
' ge' 6.267        'be past gr' 1.372
' gi' 6.397        'yet not gr' 1.506</code></pre>
</div>
</div>
<p>Greater distance but still, a pattern. And block 5:</p>
<div id="cell-127" class="cell">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>compare_similar_strings(prompt, block_idx<span class="op">=</span><span class="dv">5</span>, compare_to_slen<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length 3 similars:   Length 10 similars:
'mys' 6.682        'my most gr' 0.000
'my-' 6.722        'my most st' 3.911
'ms-' 7.015        'my most sa' 4.328
'myr' 7.065        ' my most r' 4.556
'mso' 7.115        ' my most l' 5.160
"my'" 7.123        'my high bl' 5.198
'my?' 7.148        'm thy moth' 5.221
'mfu' 7.158        'mt my mast' 5.225
'moc' 7.168        'my most he' 5.338
"ms'" 7.214        'my merry m' 5.445</code></pre>
</div>
</div>
<p>A different pattern, but still a pattern.</p>
<p>Let’s see if we can do this with just the length 10 data and not have to generate all the block internals data for the other string lengths from scratch.</p>
<p>As a prereq, let’s first see if the intermediate values for substrings within a longer string are the same as the values that would have been produced for those substrings on their own.</p>
<div id="cell-130" class="cell">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show that for the common letters, the intermediates for a substring</span></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="co"># are the same as those in a longer string.</span></span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a>prompt_short <span class="op">=</span> <span class="st">'my mo'</span></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a>prompt_long <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>bia_short <span class="op">=</span> BlockInternalsAccessors(prompt_short, encoding_helpers, accessors)</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>bia_long <span class="op">=</span> BlockInternalsAccessors(prompt_long, encoding_helpers, accessors)</span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> t_i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(prompt_short)):</span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> block_idx <span class="kw">in</span> <span class="bu">range</span>(n_layer):</span>
<span id="cb134-11"><a href="#cb134-11" aria-hidden="true" tabindex="-1"></a>        test_close(</span>
<span id="cb134-12"><a href="#cb134-12" aria-hidden="true" tabindex="-1"></a>            bia_short.proj_output(block_idx<span class="op">=</span>block_idx)[<span class="dv">0</span>, t_i, :],</span>
<span id="cb134-13"><a href="#cb134-13" aria-hidden="true" tabindex="-1"></a>            bia_long.proj_output(block_idx<span class="op">=</span>block_idx)[<span class="dv">0</span>, t_i, :],</span>
<span id="cb134-14"><a href="#cb134-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb134-15"><a href="#cb134-15" aria-hidden="true" tabindex="-1"></a>        test_close(</span>
<span id="cb134-16"><a href="#cb134-16" aria-hidden="true" tabindex="-1"></a>            bia_short.ffwd_output(block_idx<span class="op">=</span>block_idx)[<span class="dv">0</span>, t_i, :],</span>
<span id="cb134-17"><a href="#cb134-17" aria-hidden="true" tabindex="-1"></a>            bia_long.ffwd_output(block_idx<span class="op">=</span>block_idx)[<span class="dv">0</span>, t_i, :],</span>
<span id="cb134-18"><a href="#cb134-18" aria-hidden="true" tabindex="-1"></a>        )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It passes, so this shows we can use the values at the other t_i’s from the slen10 dataset. Let’s try it.</p>
<div id="cell-132" class="cell">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>full_slen<span class="op">=</span><span class="dv">10</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>target_exp <span class="op">=</span> exps[full_slen]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-133" class="cell">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_similar_strings2(</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>    prompt: <span class="bu">str</span>,</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a>    block_idx: <span class="bu">int</span>,</span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>    compare_to_slen: <span class="bu">int</span>,</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb136-6"><a href="#cb136-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Same as compare_similar_strings() above but just uses a single experiment."""</span></span>
<span id="cb136-7"><a href="#cb136-7" aria-hidden="true" tabindex="-1"></a>    prompt_accessors <span class="op">=</span> BlockInternalsAccessors(prompt, encoding_helpers, accessors)</span>
<span id="cb136-8"><a href="#cb136-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-9"><a href="#cb136-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># indexing `compare_to_slen - 1` below because slicers2 is indexed</span></span>
<span id="cb136-10"><a href="#cb136-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># by t_i, not string length</span></span>
<span id="cb136-11"><a href="#cb136-11" aria-hidden="true" tabindex="-1"></a>    sim_strings_comp, distances_comp <span class="op">=</span> target_exp.strings_with_topk_closest_proj_outputs(</span>
<span id="cb136-12"><a href="#cb136-12" aria-hidden="true" tabindex="-1"></a>        block_idx<span class="op">=</span>block_idx,</span>
<span id="cb136-13"><a href="#cb136-13" aria-hidden="true" tabindex="-1"></a>        t_i<span class="op">=</span>compare_to_slen <span class="op">-</span> <span class="dv">1</span>,</span>
<span id="cb136-14"><a href="#cb136-14" aria-hidden="true" tabindex="-1"></a>        queries<span class="op">=</span>prompt_accessors.proj_output(block_idx<span class="op">=</span>block_idx)[:, <span class="op">-</span><span class="dv">1</span>, :],</span>
<span id="cb136-15"><a href="#cb136-15" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb136-16"><a href="#cb136-16" aria-hidden="true" tabindex="-1"></a>        largest<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb136-17"><a href="#cb136-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb136-18"><a href="#cb136-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-19"><a href="#cb136-19" aria-hidden="true" tabindex="-1"></a>    sim_strings, distances <span class="op">=</span> exps[<span class="bu">len</span>(prompt)].strings_with_topk_closest_proj_outputs(</span>
<span id="cb136-20"><a href="#cb136-20" aria-hidden="true" tabindex="-1"></a>        block_idx<span class="op">=</span>block_idx,</span>
<span id="cb136-21"><a href="#cb136-21" aria-hidden="true" tabindex="-1"></a>        t_i<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb136-22"><a href="#cb136-22" aria-hidden="true" tabindex="-1"></a>        queries<span class="op">=</span>prompt_accessors.proj_output(block_idx<span class="op">=</span>block_idx)[:, <span class="op">-</span><span class="dv">1</span>, :],</span>
<span id="cb136-23"><a href="#cb136-23" aria-hidden="true" tabindex="-1"></a>        k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb136-24"><a href="#cb136-24" aria-hidden="true" tabindex="-1"></a>        largest<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb136-25"><a href="#cb136-25" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb136-26"><a href="#cb136-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-27"><a href="#cb136-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Length </span><span class="sc">{</span>compare_to_slen<span class="sc">}</span><span class="ss"> similars:   Length </span><span class="sc">{</span><span class="bu">len</span>(prompt)<span class="sc">}</span><span class="ss"> similars:"</span>)</span>
<span id="cb136-28"><a href="#cb136-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb136-29"><a href="#cb136-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'</span><span class="sc">{</span><span class="bu">repr</span>(sim_strings_comp[<span class="dv">0</span>][i][:compare_to_slen])<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>distances_comp[i]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss">        </span><span class="sc">{</span><span class="bu">repr</span>(sim_strings[<span class="dv">0</span>][i])<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>distances[i]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-134" class="cell">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>compare_similar_strings2(prompt, block_idx<span class="op">=</span><span class="dv">5</span>, compare_to_slen<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length 5 similars:   Length 10 similars:
'my mo' 4.464        'my most gr' 0.000
'my st' 4.917        'my most st' 3.911
'my br' 4.969        'my most sa' 4.328
'my tr' 4.977        ' my most r' 4.556
'my gr' 5.039        ' my most l' 5.160
'my sw' 5.115        'my high bl' 5.198
'my sc' 5.132        'm thy moth' 5.221
'my wr' 5.140        'mt my mast' 5.225
'my bl' 5.215        'my most he' 5.338
'my tw' 5.267        'my merry m' 5.445</code></pre>
</div>
</div>
<p>Notice that this is the same as the output above when we compared to a length 5 experiment’s outputs!</p>
<p>And now we can do it for other lengths without having to run experiments for all of them.</p>
<div id="cell-137" class="cell">
<div class="sourceCode cell-code" id="cb139"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>compare_similar_strings2(prompt, block_idx<span class="op">=</span><span class="dv">5</span>, compare_to_slen<span class="op">=</span><span class="dv">9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Length 9 similars:   Length 10 similars:
'my most r' 2.754        'my most gr' 0.000
'my most l' 3.517        'my most st' 3.911
'my most h' 3.795        'my most sa' 4.328
'm my mout' 4.802        ' my most r' 4.556
'm thy mot' 4.808        ' my most l' 5.160
'm, my mot' 4.832        'my high bl' 5.198
'y most gr' 4.976        'm thy moth' 5.221
'my most g' 5.051        'mt my mast' 5.225
'mes my br' 5.177        'my most he' 5.338
'm my moth' 5.252        'my merry m' 5.445</code></pre>
</div>
</div>
</section>
<section id="try-out-loading-with-mmap_mode" class="level2">
<h2 class="anchored" data-anchor-id="try-out-loading-with-mmap_mode">Try out loading with mmap_mode</h2>
<blockquote class="blockquote">
<p>Code in this section doesn’t run anymore because the Slicer doesn’t exist and some other internal changes have been made based on the experiments here, but I’m leaving this in for the historical record.</p>
</blockquote>
<p>Set up a query:</p>
<div id="cell-141" class="cell">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">'my most gr'</span></span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>prompt_accessors <span class="op">=</span> BlockInternalsAccessors(prompt, encoding_helpers, accessors)</span>
<span id="cb141-3"><a href="#cb141-3" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> prompt_accessors.proj_output(block_idx<span class="op">=</span><span class="dv">0</span>)[:, <span class="op">-</span><span class="dv">1</span>, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Time loading a full batch from slen10 the regular way and subtracting the query:</p>
<div id="cell-143" class="cell">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> torch.load(exps[<span class="dv">10</span>].output_dir <span class="op">/</span> <span class="st">'proj_output-000-00.pt'</span>)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>batch <span class="op">-</span> query</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>28.4 ms ± 348 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
<p>Now load with <code>mmap=True</code> and try again:</p>
<div id="cell-145" class="cell">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>].output_dir <span class="op">/</span> <span class="st">'proj_output-000-00.pt'</span>), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>batch <span class="op">-</span> query</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>11.8 ms ± 56.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)</code></pre>
</div>
</div>
<p>Ooh, it’s way faster. Let’s see if we can load multiple batches, cat them and do the subtraction:</p>
<div id="cell-147" class="cell">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>batch1 <span class="op">=</span> torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>].output_dir <span class="op">/</span> <span class="st">'proj_output-000-00.pt'</span>), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>batch2 <span class="op">=</span> torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>].output_dir <span class="op">/</span> <span class="st">'proj_output-001-00.pt'</span>), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>batch3 <span class="op">=</span> torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>].output_dir <span class="op">/</span> <span class="st">'proj_output-002-00.pt'</span>), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb146-4"><a href="#cb146-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-5"><a href="#cb146-5" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">=</span> torch.cat([batch1, batch2, batch3])</span>
<span id="cb146-6"><a href="#cb146-6" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">-</span> query</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>52.1 ms ± 637 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
<p>Wow. OK, this is a big deal. We did 3 batches in 51ms vs 28.ms for just one batch in the regular way. And I suspect this scales non-linearly. Let’s try it with all the batches:</p>
<div id="cell-149" class="cell">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">=</span> torch.cat([</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>    torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>]._proj_output_filename(batch_idx<span class="op">=</span>batch_idx, block_idx<span class="op">=</span><span class="dv">0</span>)), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exps[<span class="dv">10</span>].n_batches)</span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">-</span> query</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>8.88 s ± 294 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>So 8.88s for 86 batches. Memory usage peaked at 25GB during the run but went up and down and settled back down to where it was before the run started.</p>
<p>But that’s 103ms per batch which seems slower than just loading each batch one at a time. But the computation is simpler (no need for <code>topk_across_batches()</code> etc).</p>
<p>Let’s try running through all the batches the old way (no mmap) and time it.</p>
<div id="cell-152" class="cell">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exps[<span class="dv">10</span>].n_batches):</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>    batch <span class="op">=</span> torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>]._proj_output_filename(batch_idx<span class="op">=</span>batch_idx, block_idx<span class="op">=</span><span class="dv">0</span>))) <span class="co"># no mmap</span></span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>    batch <span class="op">-</span> query</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.32 s ± 157 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>So this is actually faster. But let’s try to do more of the complete operation and do multiple queries:</p>
<div id="cell-154" class="cell">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define prompts and extract the query values</span></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>prompts <span class="op">=</span> [<span class="st">'First Citi'</span>, <span class="st">'Citizen:</span><span class="ch">\n</span><span class="st">B'</span>, <span class="st">'Shyamalan '</span>, <span class="st">'more in jo'</span>]</span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a>prompts_exp <span class="op">=</span> BlockInternalsExperiment(encoding_helpers, accessors, prompts)</span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-5"><a href="#cb152-5" aria-hidden="true" tabindex="-1"></a>t_i <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb152-6"><a href="#cb152-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-7"><a href="#cb152-7" aria-hidden="true" tabindex="-1"></a>queries <span class="op">=</span> prompts_exp.proj_output(block_idx<span class="op">=</span><span class="dv">0</span>)[:, t_i, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Time doing the equivalent of strings_with_topk_closest_ffwd_outputs() on the mmaped data:</p>
<div id="cell-156" class="cell">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">=</span> torch.cat([</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>    torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>]._proj_output_filename(batch_idx<span class="op">=</span>batch_idx, block_idx<span class="op">=</span><span class="dv">0</span>)), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exps[<span class="dv">10</span>].n_batches)</span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a>n_queries, _ <span class="op">=</span> queries.shape</span>
<span id="cb153-7"><a href="#cb153-7" aria-hidden="true" tabindex="-1"></a>B, T, _ <span class="op">=</span> big_batch.shape</span>
<span id="cb153-8"><a href="#cb153-8" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> torch.norm(</span>
<span id="cb153-9"><a href="#cb153-9" aria-hidden="true" tabindex="-1"></a>    big_batch[:, t_i, :].reshape(B, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, n_queries, <span class="op">-</span><span class="dv">1</span>) <span class="op">-</span> queries,</span>
<span id="cb153-10"><a href="#cb153-10" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb153-11"><a href="#cb153-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb153-12"><a href="#cb153-12" aria-hidden="true" tabindex="-1"></a>topk <span class="op">=</span> torch.topk(distances, k<span class="op">=</span><span class="dv">10</span>, dim<span class="op">=</span><span class="dv">0</span>, largest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb153-13"><a href="#cb153-13" aria-hidden="true" tabindex="-1"></a>exps[<span class="dv">10</span>].strings_from_indices(topk.indices), topk.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>6.51 s ± 395 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>OK, that is slow. But I suspect there is some overhead in loading the data the first time. What if we load the data once and then process the queries on the loaded data:</p>
<div id="cell-158" class="cell">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">=</span> torch.cat([</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>    torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>]._proj_output_filename(batch_idx<span class="op">=</span>batch_idx, block_idx<span class="op">=</span><span class="dv">0</span>)), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exps[<span class="dv">10</span>].n_batches)</span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-159" class="cell">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>n_queries, _ <span class="op">=</span> queries.shape</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>B, T, _ <span class="op">=</span> big_batch.shape</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> torch.norm(</span>
<span id="cb156-4"><a href="#cb156-4" aria-hidden="true" tabindex="-1"></a>    big_batch[:, t_i, :].reshape(B, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, n_queries, <span class="op">-</span><span class="dv">1</span>) <span class="op">-</span> queries,</span>
<span id="cb156-5"><a href="#cb156-5" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb156-6"><a href="#cb156-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb156-7"><a href="#cb156-7" aria-hidden="true" tabindex="-1"></a>topk <span class="op">=</span> torch.topk(distances, k<span class="op">=</span><span class="dv">10</span>, dim<span class="op">=</span><span class="dv">0</span>, largest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb156-8"><a href="#cb156-8" aria-hidden="true" tabindex="-1"></a>exps[<span class="dv">10</span>].strings_from_indices(topk.indices), topk.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>303 ms ± 8.63 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>Compare that to doing it with a slicer.</p>
<div id="cell-161" class="cell">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>slicers[<span class="dv">10</span>].strings_with_topk_closest_proj_outputs(block_idx<span class="op">=</span><span class="dv">0</span>, queries<span class="op">=</span>queries, k<span class="op">=</span><span class="dv">10</span>, largest<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>471 ms ± 3.27 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>We don’t have the required methods on the exp class anymore, but if we want to test how long this would have taken without the slicer i.e.&nbsp;on the same data that the mmap version is using but without using mmap, we can resurrect the relevant code:</p>
<div id="cell-163" class="cell">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Copy of the code from block_internals, just so we can run it below</span></span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> batch_distances(batch: torch.Tensor, queries: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Returns the distance between each item in the batch and the queries."""</span></span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> batch.dim() <span class="op">==</span> <span class="dv">2</span>, <span class="ss">f"batch.dim() should be 2, was </span><span class="sc">{</span>batch<span class="sc">.</span>dim()<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb160-5"><a href="#cb160-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> queries.dim() <span class="op">==</span> <span class="dv">2</span>, <span class="ss">f"query.dim() should be 2, was </span><span class="sc">{</span>queries<span class="sc">.</span>dim()<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb160-6"><a href="#cb160-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> (</span>
<span id="cb160-7"><a href="#cb160-7" aria-hidden="true" tabindex="-1"></a>        batch.shape[<span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> queries.shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb160-8"><a href="#cb160-8" aria-hidden="true" tabindex="-1"></a>    ), <span class="ss">f"last dimension of batch was </span><span class="sc">{</span>batch<span class="sc">.</span>shape[<span class="op">-</span><span class="dv">1</span>]<span class="sc">}</span><span class="ss">, which does not match last dimension of queries </span><span class="sc">{</span>queries<span class="sc">.</span>shape[<span class="op">-</span><span class="dv">1</span>]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb160-9"><a href="#cb160-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-10"><a href="#cb160-10" aria-hidden="true" tabindex="-1"></a>    B, _ <span class="op">=</span> batch.shape</span>
<span id="cb160-11"><a href="#cb160-11" aria-hidden="true" tabindex="-1"></a>    n_queries, _ <span class="op">=</span> queries.shape</span>
<span id="cb160-12"><a href="#cb160-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-13"><a href="#cb160-13" aria-hidden="true" tabindex="-1"></a>    distances <span class="op">=</span> torch.norm(</span>
<span id="cb160-14"><a href="#cb160-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape the batch to a singleton dimension, then expand that dimension</span></span>
<span id="cb160-15"><a href="#cb160-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># by the number of queries. We can then subtract all the queries in one</span></span>
<span id="cb160-16"><a href="#cb160-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># go.</span></span>
<span id="cb160-17"><a href="#cb160-17" aria-hidden="true" tabindex="-1"></a>        batch.reshape(B, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, n_queries, <span class="op">-</span><span class="dv">1</span>) <span class="op">-</span> queries,</span>
<span id="cb160-18"><a href="#cb160-18" aria-hidden="true" tabindex="-1"></a>        dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb160-19"><a href="#cb160-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb160-20"><a href="#cb160-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> distances</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-164" class="cell">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a>n_queries, _ <span class="op">=</span> queries.shape</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>values, indices <span class="op">=</span> topk_across_batches(</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a>    n_batches<span class="op">=</span>exps[<span class="dv">10</span>].n_batches,</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a>    largest<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb161-6"><a href="#cb161-6" aria-hidden="true" tabindex="-1"></a>    load_batch<span class="op">=</span><span class="kw">lambda</span> i: torch.load(exps[<span class="dv">10</span>]._proj_output_filename(i, block_idx<span class="op">=</span><span class="dv">0</span>))[:, t_i, :],</span>
<span id="cb161-7"><a href="#cb161-7" aria-hidden="true" tabindex="-1"></a>    process_batch<span class="op">=</span><span class="kw">lambda</span> batch: batch_distances(batch, queries<span class="op">=</span>queries),</span>
<span id="cb161-8"><a href="#cb161-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb161-9"><a href="#cb161-9" aria-hidden="true" tabindex="-1"></a>exps[<span class="dv">10</span>].strings_from_indices(indices), values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.18 s ± 29.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>The mmap way is a faster than the slicer (303ms vs 471ms) and doesn’t require materializing the slices. And it’s waaaay faster than doing it without the slicer and without mmap (303ms vs 2.18s).</p>
<p>In summary: It seems there is a one-time cost to loading all the batches via:</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">=</span> torch.cat([</span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>    torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>]._proj_output_filename(batch_idx<span class="op">=</span>batch_idx, block_idx<span class="op">=</span><span class="dv">0</span>)), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exps[<span class="dv">10</span>].n_batches)</span>
<span id="cb163-4"><a href="#cb163-4" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>But this doesn’t take up too much memory (fresh Jupyter kernel running just the stuff in this and the previous section has about 13 GB of memory per Activity Monitor). So we can load this once and run a lot of queries very fast.</p>
<p>Let’s check that the results are correct:</p>
<div id="cell-166" class="cell">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Do for real so we can compare the results</span></span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>big_batch <span class="op">=</span> torch.cat([</span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a>    torch.load(<span class="bu">str</span>(exps[<span class="dv">10</span>]._proj_output_filename(batch_idx<span class="op">=</span>batch_idx, block_idx<span class="op">=</span><span class="dv">0</span>)), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exps[<span class="dv">10</span>].n_batches)</span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>n_queries, _ <span class="op">=</span> queries.shape</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>B, T, _ <span class="op">=</span> big_batch.shape</span>
<span id="cb164-9"><a href="#cb164-9" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> torch.norm(</span>
<span id="cb164-10"><a href="#cb164-10" aria-hidden="true" tabindex="-1"></a>    big_batch[:, t_i, :].reshape(B, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, n_queries, <span class="op">-</span><span class="dv">1</span>) <span class="op">-</span> queries,</span>
<span id="cb164-11"><a href="#cb164-11" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb164-12"><a href="#cb164-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb164-13"><a href="#cb164-13" aria-hidden="true" tabindex="-1"></a>topk <span class="op">=</span> torch.topk(distances, k<span class="op">=</span><span class="dv">10</span>, dim<span class="op">=</span><span class="dv">0</span>, largest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb164-14"><a href="#cb164-14" aria-hidden="true" tabindex="-1"></a>exps[<span class="dv">10</span>].strings_from_indices(topk.indices), topk.values</span>
<span id="cb164-15"><a href="#cb164-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-16"><a href="#cb164-16" aria-hidden="true" tabindex="-1"></a>sim_strings, distances <span class="op">=</span> slicers[<span class="dv">10</span>].strings_with_topk_closest_proj_outputs(block_idx<span class="op">=</span><span class="dv">0</span>, queries<span class="op">=</span>queries, k<span class="op">=</span><span class="dv">10</span>, largest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb164-17"><a href="#cb164-17" aria-hidden="true" tabindex="-1"></a>test_eq(exps[<span class="dv">10</span>].strings_from_indices(topk.indices), sim_strings)</span>
<span id="cb164-18"><a href="#cb164-18" aria-hidden="true" tabindex="-1"></a>test_close(topk.values, distances)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These test pass, so the output is the same!</p>
<section id="perf-tests-for-using-mmap-with-the-slicer" class="level3">
<h3 class="anchored" data-anchor-id="perf-tests-for-using-mmap-with-the-slicer">Perf tests for using mmap with the slicer</h3>
<p>The analysis above showed that using mmap on the raw batch data is faster than using the slicer. But yesterday I found that just setting mmap=True on the load_batch function when finding closest embeddings made a huge difference. Let’s try the same thing for the slicer and see if it makes a difference.</p>
<div id="cell-170" class="cell">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>t_i <span class="op">=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>queries <span class="op">=</span> prompts_exp.proj_output(block_idx<span class="op">=</span><span class="dv">0</span>)[:, t_i, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Though we have a measurement for using the slicer above, let’s just replicate it for completeness. Ran this line before making any changes:</p>
<div id="cell-172" class="cell">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>slicers[<span class="dv">10</span>].strings_with_topk_closest_proj_outputs(block_idx<span class="op">=</span><span class="dv">0</span>, queries<span class="op">=</span>queries, k<span class="op">=</span><span class="dv">10</span>, largest<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>482 ms ± 14.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>OK, that’s in line with the measurement above. Now let’s try it after changing the implementation to use <code>mmap=True</code>:</p>
<div id="cell-174" class="cell">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>slicers[<span class="dv">10</span>].strings_with_topk_closest_proj_outputs(block_idx<span class="op">=</span><span class="dv">0</span>, queries<span class="op">=</span>queries, k<span class="op">=</span><span class="dv">10</span>, largest<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>361 ms ± 8.18 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>OK, so it got faster, but it’s still not as fast as using the raw batch data with <code>mmap=True</code>. So we’ll go with that.</p>
</section>
</section>
<section id="perf-tests-for-finding-closest-embeddings" class="level2">
<h2 class="anchored" data-anchor-id="perf-tests-for-finding-closest-embeddings">Perf tests for finding closest embeddings</h2>
<div id="cell-177" class="cell">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>exp10 <span class="op">=</span> BatchedBlockInternalsExperiment(</span>
<span id="cb170-2"><a href="#cb170-2" aria-hidden="true" tabindex="-1"></a>    eh<span class="op">=</span>encoding_helpers,</span>
<span id="cb170-3"><a href="#cb170-3" aria-hidden="true" tabindex="-1"></a>    accessors<span class="op">=</span>accessors,</span>
<span id="cb170-4"><a href="#cb170-4" aria-hidden="true" tabindex="-1"></a>    strings<span class="op">=</span>strings_n[<span class="dv">10</span>],</span>
<span id="cb170-5"><a href="#cb170-5" aria-hidden="true" tabindex="-1"></a>    output_dir<span class="op">=</span>environment.data_root <span class="op">/</span> <span class="st">'block_internals_results/large_files/slen10/'</span>,</span>
<span id="cb170-6"><a href="#cb170-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">10000</span>,</span>
<span id="cb170-7"><a href="#cb170-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Measurement before any changes</p>
<div id="cell-179" class="cell">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>exp10.strings_with_topk_closest_embeddings(queries<span class="op">=</span>prompts_exp.embeddings, k<span class="op">=</span><span class="dv">10</span>, largest<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4.49 s ± 9.11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>Simulate loading all the batch data at once and then finding the topk closest strings for all the queries:</p>
<div id="cell-181" class="cell">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>embeddings_data <span class="op">=</span> torch.cat([</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>    torch.load(<span class="bu">str</span>(exp10._embeddings_filename(batch_idx<span class="op">=</span>batch_idx)), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb173-3"><a href="#cb173-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exp10.n_batches)</span>
<span id="cb173-4"><a href="#cb173-4" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-182" class="cell">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalent of topk_closest_embeddings - slow</span></span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a>B, _, _ <span class="op">=</span> embeddings_data.shape</span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a>n_queries, _, _ <span class="op">=</span> prompts_exp.embeddings.shape</span>
<span id="cb174-5"><a href="#cb174-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb174-6"><a href="#cb174-6" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> batch_distances(</span>
<span id="cb174-7"><a href="#cb174-7" aria-hidden="true" tabindex="-1"></a>    embeddings_data.reshape(B, <span class="op">-</span><span class="dv">1</span>),</span>
<span id="cb174-8"><a href="#cb174-8" aria-hidden="true" tabindex="-1"></a>    prompts_exp.embeddings.reshape(n_queries, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb174-9"><a href="#cb174-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb174-10"><a href="#cb174-10" aria-hidden="true" tabindex="-1"></a>topk <span class="op">=</span> torch.topk(distances, dim<span class="op">=</span><span class="dv">0</span>, k<span class="op">=</span>k, largest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb174-11"><a href="#cb174-11" aria-hidden="true" tabindex="-1"></a>exp10.strings_from_indices(topk.indices), topk.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The above was really slow and took a ton of memory.</p>
<p>Verify that the equivalent thing on the proj_out data is still fast:</p>
<div id="cell-185" class="cell">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>proj_out_data <span class="op">=</span> torch.cat([</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>    torch.load(<span class="bu">str</span>(exp10._proj_output_filename(batch_idx<span class="op">=</span>batch_idx, block_idx<span class="op">=</span><span class="dv">0</span>)), mmap<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb175-3"><a href="#cb175-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx <span class="kw">in</span> <span class="bu">range</span>(exp10.n_batches)</span>
<span id="cb175-4"><a href="#cb175-4" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-186" class="cell">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>n_queries, _ <span class="op">=</span> queries.shape</span>
<span id="cb176-2"><a href="#cb176-2" aria-hidden="true" tabindex="-1"></a>B, T, _ <span class="op">=</span> proj_out_data.shape</span>
<span id="cb176-3"><a href="#cb176-3" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> torch.norm(</span>
<span id="cb176-4"><a href="#cb176-4" aria-hidden="true" tabindex="-1"></a>    proj_out_data[:, t_i, :].reshape(B, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, n_queries, <span class="op">-</span><span class="dv">1</span>) <span class="op">-</span> queries,</span>
<span id="cb176-5"><a href="#cb176-5" aria-hidden="true" tabindex="-1"></a>    dim<span class="op">=</span><span class="dv">2</span></span>
<span id="cb176-6"><a href="#cb176-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb176-7"><a href="#cb176-7" aria-hidden="true" tabindex="-1"></a>topk <span class="op">=</span> torch.topk(distances, k<span class="op">=</span><span class="dv">10</span>, dim<span class="op">=</span><span class="dv">0</span>, largest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb176-8"><a href="#cb176-8" aria-hidden="true" tabindex="-1"></a>exp10.strings_from_indices(topk.indices), topk.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Yes it is.</p>
<p>Suspecting the issue is the reshape needed. Show that we can calculate the norm we want without the reshape.</p>
<p>What the reshape does is stack the embeddings across the T dimension. We have embeddings</p>
<p><span class="math display">\[
e_1, e_2, \ldots, e_T \in \mathbb{R}^{n\_embed}
\]</span></p>
<p>By stacking them, we get one big embedding:</p>
<p><span class="math display">\[
e_{1:T} \in \mathbb{R}^{T * n\_embed}
\]</span></p>
<p>We do the same with the queries:</p>
<p><span class="math display">\[
q_1, q_2, \ldots, q_T \in \mathbb{R}^{n\_embed} \rightarrow
q_{1:T} \in \mathbb{R}^{T * n\_embed}
\]</span></p>
<p>We then want to compute</p>
<p><span class="math display">\[
\Vert e_{1:T} - q_{1:T} \Vert_2 = \sqrt{\sum_{i=1}^{T * n\_embed} (e_{1:T} - q_{1:T})_i^2}
\]</span></p>
<p>Can we get to this if we only have <span class="math inline">\(e_1, e_2, \ldots, e_T\)</span> and <span class="math inline">\(q_1, q_2, \ldots, q_T\)</span>? Yes, we can.</p>
<p><span class="math display">\[
\begin{align}
\Vert e_{1:T} - q_{1:T} \Vert_2 &amp;= \sqrt{\sum_{i=1}^{T * n\_embed} (e_{1:T} - q_{1:T})_i^2} \\
\Vert e_{1:T} - q_{1:T} \Vert_2^2 &amp;= \sum_{i=1}^{T * n\_embed} (e_{1:T} - q_{1:T})_i^2 \\
&amp;=\sum_{i=1}^{n\_embed}(e_{1:T} - q_{1:T})_i^2 + \sum_{i=n\_embed+1}^{2*n\_embed}(e_{1:T} - q_{1:T})_i^2 + \ldots + \sum_{i=(T-1)*n\_embed+1}^{T*n\_embed}(e_{1:T} - q_{1:T})_i^2 \\
&amp;=\sum_{i=1}^{n\_embed}(e_{1} - q_{1})_i^2 + \sum_{i=1}^{n\_embed}(e_{2} - q_{2})_i^2 + \ldots + \sum_{i=1}^{n\_embed}(e_{T} - q_{T})_i^2 \\
&amp;=\Vert e_1 - q_1 \Vert_2^2 + \Vert e_2 - q_2 \Vert_2^2 + \ldots + \Vert e_T - q_T \Vert_2^2 \\
&amp;=\sum_{i=1}^{T}\Vert e_i - q_i \Vert_2^2
\end{align}
\]</span></p>
<p>So</p>
<p><span class="math display">\[
\begin{align}
\Vert e_{1:T} - q_{1:T} \Vert_2 &amp;= \sqrt{\sum_{i=1}^{T}\Vert e_i - q_i \Vert_2^2}
\end{align}
\]</span></p>
<p>Let’s check it in code.</p>
<div id="cell-189" class="cell">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show that we can effectively compute the norm without reshaping</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn((<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">384</span>))</span>
<span id="cb177-3"><a href="#cb177-3" aria-hidden="true" tabindex="-1"></a>B, T, _ <span class="op">=</span> x.shape</span>
<span id="cb177-4"><a href="#cb177-4" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> torch.randn(<span class="dv">5</span>, <span class="dv">384</span>)</span>
<span id="cb177-5"><a href="#cb177-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb177-6"><a href="#cb177-6" aria-hidden="true" tabindex="-1"></a>norm1 <span class="op">=</span> torch.norm(x.reshape(B, <span class="op">-</span><span class="dv">1</span>) <span class="op">-</span> q.reshape(<span class="op">-</span><span class="dv">1</span>), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb177-7"><a href="#cb177-7" aria-hidden="true" tabindex="-1"></a>norm2 <span class="op">=</span> (torch.norm(x <span class="op">-</span> q, dim<span class="op">=-</span><span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span>).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>).sqrt()</span>
<span id="cb177-8"><a href="#cb177-8" aria-hidden="true" tabindex="-1"></a>test_close(norm1, norm2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let’s do it with the embeddings</p>
<div id="cell-191" class="cell">
<div class="sourceCode cell-code" id="cb178"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Version without reshaping</span></span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a>B, _, _ <span class="op">=</span> embeddings_data.shape</span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-4"><a href="#cb178-4" aria-hidden="true" tabindex="-1"></a>n_queries, _, _ <span class="op">=</span> prompts_exp.embeddings.shape</span>
<span id="cb178-5"><a href="#cb178-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-6"><a href="#cb178-6" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> (</span>
<span id="cb178-7"><a href="#cb178-7" aria-hidden="true" tabindex="-1"></a>    torch.norm(embeddings_data.unsqueeze(dim<span class="op">=</span><span class="dv">1</span>).expand(<span class="op">-</span><span class="dv">1</span>, n_queries, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>) <span class="op">-</span> prompts_exp.embeddings, dim<span class="op">=-</span><span class="dv">1</span>) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb178-8"><a href="#cb178-8" aria-hidden="true" tabindex="-1"></a>).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>).sqrt()</span>
<span id="cb178-9"><a href="#cb178-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-10"><a href="#cb178-10" aria-hidden="true" tabindex="-1"></a>topk <span class="op">=</span> torch.topk(distances, dim<span class="op">=</span><span class="dv">0</span>, k<span class="op">=</span><span class="dv">10</span>, largest<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb178-11"><a href="#cb178-11" aria-hidden="true" tabindex="-1"></a>exp10.strings_from_indices(topk.indices), topk.values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>: </code></pre>
</div>
</div>
<p>The above used so much memory that it crashed the kernel. So this is a no go. I think the fundamental problem is we’re computing over a lot more data: all elements of the T dimension vs just one with the proj_outputs/ffwd_outputs. So let’s go back to the original way of doing it in batches, but let’s see if it helps to load “super batches” by combining several of the batches on disk into one batch in memory.</p>
<div id="cell-193" class="cell">
<div class="sourceCode cell-code" id="cb180"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters for creating super batches</span></span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>k<span class="op">=</span><span class="dv">10</span></span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>largest<span class="op">=</span><span class="va">False</span></span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a>combine_n_batches <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb180-6"><a href="#cb180-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-7"><a href="#cb180-7" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> exp10.batch_size <span class="op">*</span> combine_n_batches</span>
<span id="cb180-8"><a href="#cb180-8" aria-hidden="true" tabindex="-1"></a>n_batches <span class="op">=</span> math.ceil(<span class="bu">len</span>(exp10.strings) <span class="op">/</span> batch_size)</span>
<span id="cb180-9"><a href="#cb180-9" aria-hidden="true" tabindex="-1"></a>queries <span class="op">=</span> prompts_exp.embeddings</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-194" class="cell">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _load_batch(batch_idx: <span class="bu">int</span>):</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> batch_idx <span class="op">*</span> combine_n_batches</span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> <span class="bu">min</span>((batch_idx <span class="op">+</span> <span class="dv">1</span>) <span class="op">*</span> combine_n_batches, exp10.n_batches)</span>
<span id="cb181-4"><a href="#cb181-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-5"><a href="#cb181-5" aria-hidden="true" tabindex="-1"></a>    batch <span class="op">=</span> torch.cat([</span>
<span id="cb181-6"><a href="#cb181-6" aria-hidden="true" tabindex="-1"></a>        torch.load(</span>
<span id="cb181-7"><a href="#cb181-7" aria-hidden="true" tabindex="-1"></a>            <span class="bu">str</span>(exp10._embeddings_filename(batch_idx<span class="op">=</span>i)),</span>
<span id="cb181-8"><a href="#cb181-8" aria-hidden="true" tabindex="-1"></a>            mmap<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb181-9"><a href="#cb181-9" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb181-10"><a href="#cb181-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(start, end)</span>
<span id="cb181-11"><a href="#cb181-11" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb181-12"><a href="#cb181-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> batch</span>
<span id="cb181-13"><a href="#cb181-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-14"><a href="#cb181-14" aria-hidden="true" tabindex="-1"></a>n_queries, _, _ <span class="op">=</span> queries.shape</span>
<span id="cb181-15"><a href="#cb181-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-16"><a href="#cb181-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _process_batch(batch: torch.Tensor) <span class="op">-&gt;</span> torch.Tensor:</span>
<span id="cb181-17"><a href="#cb181-17" aria-hidden="true" tabindex="-1"></a>    B, _, _ <span class="op">=</span> batch.shape</span>
<span id="cb181-18"><a href="#cb181-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Batch and queries and both shape (B, s_len, n_embed).</span></span>
<span id="cb181-19"><a href="#cb181-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For the purposes of finding the closest values, we</span></span>
<span id="cb181-20"><a href="#cb181-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># reshape both the batch and queries to eliminate the</span></span>
<span id="cb181-21"><a href="#cb181-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># s_len dimension, effectively concatenating all the</span></span>
<span id="cb181-22"><a href="#cb181-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># embedding tensors across positions.</span></span>
<span id="cb181-23"><a href="#cb181-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> batch_distances(batch.reshape(B, <span class="op">-</span><span class="dv">1</span>), queries.reshape(n_queries, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb181-24"><a href="#cb181-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-25"><a href="#cb181-25" aria-hidden="true" tabindex="-1"></a>values, indices <span class="op">=</span> topk_across_batches(</span>
<span id="cb181-26"><a href="#cb181-26" aria-hidden="true" tabindex="-1"></a>    n_batches<span class="op">=</span>n_batches,</span>
<span id="cb181-27"><a href="#cb181-27" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span>k,</span>
<span id="cb181-28"><a href="#cb181-28" aria-hidden="true" tabindex="-1"></a>    largest<span class="op">=</span>largest,</span>
<span id="cb181-29"><a href="#cb181-29" aria-hidden="true" tabindex="-1"></a>    load_batch<span class="op">=</span>_load_batch,</span>
<span id="cb181-30"><a href="#cb181-30" aria-hidden="true" tabindex="-1"></a>    process_batch<span class="op">=</span>_process_batch,</span>
<span id="cb181-31"><a href="#cb181-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb181-32"><a href="#cb181-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-33"><a href="#cb181-33" aria-hidden="true" tabindex="-1"></a>exp10.strings_from_indices(indices), values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4.19 s ± 35.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>This helps only a tiny amount. And it seems to get faster the fewer number of batches we combine. So let’s just do it with one batch at a time. I added code to load the one batch in the existing implementation with mmap=True and timed it:</p>
<div id="cell-196" class="cell">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a>exp10.strings_with_topk_closest_embeddings(queries<span class="op">=</span>prompts_exp.embeddings, k<span class="op">=</span><span class="dv">10</span>, largest<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.34 s ± 46.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>This is the best result so far so we’ll go with this.</p>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"state":{},"version_major":2,"version_minor":0}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/spather/transformer-experiments/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>