{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "> An introduction to the TinyShakespeare transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a manual seed so output is deterministic (used same value as @karpathy)\n",
    "_ = torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import TransformerLanguageModel\n",
    "from transformer_experiments.models.transformer_helpers import EncodingHelpers\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ts = TinyShakespeareDataSet(cache_file='../artifacts/input.txt')\n",
    "m, tokenizer = create_model_and_tokenizer(\n",
    "    saved_model_filename='../artifacts/shakespeare-20231112.pt',\n",
    "    dataset=ts,\n",
    "    device=device,\n",
    ")\n",
    "encoding_helpers = EncodingHelpers(tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788929"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at the model size\n",
    "trainable_params = [p for p in m.parameters() if p.requires_grad]\n",
    "nparams = sum([np.prod(p.size()) for p in trainable_params])\n",
    "nparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate text\n",
    "\n",
    "def generate(m: TransformerLanguageModel, initial_text: str, max_new_tokens=100):\n",
    "    input = encoding_helpers.tokenize_string(initial_text)\n",
    "    return tokenizer.decode(m.generate(input, max_new_tokens=max_new_tokens)[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellow doth my lord and myself?\n",
      "\n",
      "LUCIO:\n",
      "Leave me.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Save you neither.\n",
      "\n",
      "Provost:\n",
      "But I am t\n"
     ]
    }
   ],
   "source": [
    "print(generate(m, 'Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "And that which I, infects thy seat false forth,\n",
      "That Berkeley hath not open? through thyself to be monarch,\n",
      "And clubs venomourous misfortune's end:\n",
      "The grace of Buckingham, like a feast.\n",
      "\n",
      "GLOUCESTER:\n",
      "Edward murderer, for thanks: my glory,\n",
      "Sweet life and all my son's death, and Clifford's love,\n",
      "Hath he touch'd the high ado a toad child,\n",
      "And see his precious farthen a royal stay:\n",
      "Now she is only poor house; but in evil,\n",
      "'What she spares, we'll quick Henry leave last\n",
      "By Henry the Duke of Norfolk in leaves.'\n",
      "But, come, O fortune, to our schoolmaster son\n",
      "For soul men, were spented to them, or unconquest?\n",
      "\n",
      "CLARENCE:\n",
      "Sweet lord, die upon the book of hell.\n",
      "\n",
      "WARWICK:\n",
      "My soul I must deserve what deny hours\n",
      "With my followers and turn kings, and to the queen,\n",
      "Who now deliver'd him and I siege my knees;\n",
      "Idly no reconcilence may perfect him to the regal.\n",
      "3 KING HENRY VI\n",
      "\n",
      "YORK:\n",
      "Well, Exeter, England, how would he that set us on!\n",
      "\n",
      "YORK:\n",
      "Yea, have so far off; I was loathed for thee?\n",
      "\n",
      "EXETER:\n",
      "A thriving\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Generate some longer text\n",
    "print(generate(m, '\\n', max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There once was a man from Nantuckets,\n",
      "And rich'd it with so ppresent for you\n",
      "To commit it.\n",
      "\n",
      "AUFIDIUS:\n",
      "I pray thee, I have not a soul\n",
      "Now that our country, nor being grieved, nor no;\n",
      "But one of our body's death and with what.\n",
      "\n",
      "CORIOLANU\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(generate(m, 'There once was a man from Nantucket', max_new_tokens=200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
