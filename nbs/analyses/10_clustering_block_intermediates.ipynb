{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the Projection and Feed-Forward Layers in a Self-Attention Block\n",
    "\n",
    "> A summary of my experiments to understand the projection layer and feed-forward layer of a self-attention block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Iterable, Sequence, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from fastcore.test import *\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a manual seed so output is deterministic (used same value as @karpathy)\n",
    "_ = torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from transformer_experiments.common.substring_generator import all_unique_substrings\n",
    "from transformer_experiments.common.text_analysis import (\n",
    "    build_next_token_map,\n",
    "    SubstringFrequencyAnalysis,\n",
    "    top_nonzero_tokens\n",
    ")\n",
    "from transformer_experiments.common.utils import (\n",
    "    aggregate_by_string_key,\n",
    "    DataWrapper,\n",
    "    topk_across_batches,\n",
    ")\n",
    "from transformer_experiments.dataset_split import split_text_dataset\n",
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import (\n",
    "    n_layer,\n",
    "    TransformerLanguageModel\n",
    ")\n",
    "from transformer_experiments.models.transformer_helpers import (\n",
    "    unsqueeze_emb,\n",
    "    EncodingHelpers,\n",
    "    LogitsWrapper,\n",
    "    TransformerAccessors\n",
    ")\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer\n",
    ")\n",
    "from transformer_experiments.experiments.block_internals import (\n",
    "    BlockInternalsAccessors,\n",
    "    BlockInternalsExperiment,\n",
    "    BatchedBlockInternalsExperiment,\n",
    "    BatchedBlockInternalsExperimentSlicer,\n",
    "    BlockInternalsAnalysis,\n",
    ")\n",
    "from transformer_experiments.experiments.similar_strings import (\n",
    "    SimilarStringsData,\n",
    "    SimilarStringsExperiment,\n",
    "    SimilarStringsResult\n",
    ")\n",
    "from transformer_experiments.experiments.logit_lens import LogitLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ts = TinyShakespeareDataSet(cache_file='../artifacts/input.txt')\n",
    "m, tokenizer = create_model_and_tokenizer(\n",
    "    saved_model_filename='../artifacts/shakespeare.pt',\n",
    "    dataset=ts,\n",
    "    device=device,\n",
    ")\n",
    "_, val_data = split_text_dataset(ts.text, tokenizer, train_pct=0.9)\n",
    "encoding_helpers = EncodingHelpers(tokenizer, device)\n",
    "accessors = TransformerAccessors(m, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings10 = all_unique_substrings(ts.text, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_map10 = build_next_token_map(\n",
    "    ts.text, prefix_len=10, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list(Path('../artifacts/block_internals_results/large_files/slen10/').glob('*')) == []:\n",
    "    print(\"Run `make block_internals_slen10_dataset` in the project root to generate the required dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp10 = BatchedBlockInternalsExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings10,\n",
    "    output_dir=Path('../artifacts/block_internals_results/large_files/slen10/'),\n",
    "    batch_size=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a similar strings experiment on a bunch of sample strings we'll use for analysis\n",
    "output_dir = Path('../artifacts/block_internals_results/similar_strings_sample')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ssexp = SimilarStringsExperiment(output_dir, encoding_helpers)\n",
    "strings = ['First Citi', 'Citizen:\\nB', 'Shyamalan ', 'more in jo']\n",
    "batch_size=len(strings)\n",
    "if not (output_dir / 'string_to_batch_map.json').exists():\n",
    "    ssexp.generate_string_to_batch_map(strings, batch_size)\n",
    "\n",
    "try:\n",
    "    _ = next(iter(output_dir.glob('embs_sim_strings-*.json')))\n",
    "except StopIteration:\n",
    "    ssexp.generate_embeddings_files(strings, accessors, exp10, batch_size=batch_size, n_similars=10)\n",
    "\n",
    "try:\n",
    "    _ = next(iter(output_dir.glob('proj_out_sim_strings-*.json')))\n",
    "except StopIteration:\n",
    "    ssexp.generate_proj_out_files(strings, t_i=-1, accessors=accessors, exp=exp10, batch_size=batch_size, n_similars=10)\n",
    "\n",
    "try:\n",
    "    _ = next(iter(output_dir.glob('ffwd_out_sim_strings-*.json')))\n",
    "except StopIteration:\n",
    "    ssexp.generate_ffwd_out_files(strings, t_i=-1, accessors=accessors, exp=exp10, batch_size=batch_size, n_similars=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationFromSimilarStringsExperimentResults:\n",
    "    def __init__(\n",
    "        self,\n",
    "        ss_results: Dict[str, SimilarStringsResult],\n",
    "        next_token_map: Dict[str, torch.Tensor],\n",
    "        encoding_helpers: EncodingHelpers,\n",
    "        aggregate_over_t_is: Sequence[int] = [-1],\n",
    "    ):\n",
    "        self.ss_results = ss_results\n",
    "        self.next_token_map = next_token_map\n",
    "        self.encoding_helpers = encoding_helpers\n",
    "        self.aggregate_over_t_is = aggregate_over_t_is\n",
    "        (\n",
    "            self.string_to_idx,\n",
    "            self.emb_freqs,\n",
    "            self.proj_freqs,\n",
    "            self.ffwd_freqs,\n",
    "        ) = self._freqs_for_results()\n",
    "\n",
    "    def simulate(self, prompt: str):\n",
    "        if prompt not in self.ss_results:\n",
    "            raise ValueError(\n",
    "                f\"Prompt {repr(prompt)} was not in the SimilarStringsExperiment results\"\n",
    "            )\n",
    "\n",
    "        prompt_idx = self.string_to_idx[prompt]\n",
    "\n",
    "        emb_weight = torch.tensor(1.0, dtype=torch.float32)\n",
    "        proj_weights = torch.tensor(\n",
    "            [1.0 for _ in range(n_layer)], dtype=torch.float32\n",
    "        ).unsqueeze(dim=1)\n",
    "        ffwd_weights = torch.tensor(\n",
    "            [1 + block_idx for block_idx in range(n_layer)], dtype=torch.float32\n",
    "        ).unsqueeze(dim=1)\n",
    "\n",
    "        # this is what simulate does:\n",
    "        freqs = (\n",
    "            emb_weight * self.emb_freqs[prompt_idx, :]\n",
    "            + (proj_weights * self.proj_freqs[:, prompt_idx, :]).sum(dim=0)\n",
    "            + (ffwd_weights * self.ffwd_freqs[:, prompt_idx, :]).sum(dim=0)\n",
    "        )\n",
    "        sim_from_weights = top_nonzero_tokens(\n",
    "            freqs.float() / freqs.sum(), self.encoding_helpers.tokenizer.itos\n",
    "        )[:10]\n",
    "\n",
    "        # Compute the model's predictions:\n",
    "        tokens = self.encoding_helpers.tokenize_string(prompt)\n",
    "        logits, _ = m(tokens)\n",
    "\n",
    "        logits = LogitsWrapper(logits, self.encoding_helpers.tokenizer)\n",
    "        return sim_from_weights, logits.topk_tokens(k=10)[0][-1]\n",
    "\n",
    "    def _freqs_for_results(self):\n",
    "        string_to_idx: Dict[str, int] = {}\n",
    "        emb_freqs = []\n",
    "        proj_freqs = [[] for _ in range(n_layer)]\n",
    "        ffwd_freqs = [[] for _ in range(n_layer)]\n",
    "\n",
    "        itos = self.encoding_helpers.tokenizer.itos\n",
    "\n",
    "        for i, (s, result) in enumerate(self.ss_results.items()):\n",
    "            string_to_idx[s] = i\n",
    "            emb_freqs.append(\n",
    "                SubstringFrequencyAnalysis(\n",
    "                    result.embs.sim_strings, self.next_token_map, itos\n",
    "                ).cumulative_freqs\n",
    "            )\n",
    "            aggr_proj_out, aggr_ffwd_out = result.aggregate_over_t_is(self.aggregate_over_t_is)\n",
    "\n",
    "            for block_idx in range(n_layer):\n",
    "                proj_freqs[block_idx].append(\n",
    "                    SubstringFrequencyAnalysis(\n",
    "                        aggr_proj_out[block_idx].sim_strings,\n",
    "                        self.next_token_map,\n",
    "                        itos,\n",
    "                    ).cumulative_freqs\n",
    "                )\n",
    "                ffwd_freqs[block_idx].append(\n",
    "                    SubstringFrequencyAnalysis(\n",
    "                        aggr_ffwd_out[block_idx].sim_strings,\n",
    "                        self.next_token_map,\n",
    "                        itos,\n",
    "                    ).cumulative_freqs\n",
    "                )\n",
    "        return (\n",
    "            string_to_idx,\n",
    "            torch.stack(emb_freqs),  # (len(ss_results), vocab_size)\n",
    "            torch.stack(\n",
    "                [torch.stack(freqs) for freqs in proj_freqs]\n",
    "            ),  # (n_layer, len(ss_results), vocab_size)\n",
    "            torch.stack(\n",
    "                [torch.stack(freqs) for freqs in ffwd_freqs]\n",
    "            ),  # (n_layer, len(ss_results), vocab_size)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_results = ssexp.load_results_for_strings(strings)\n",
    "\n",
    "ss_sim = SimulationFromSimilarStringsExperimentResults(ss_results, next_token_map10, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['more in jo',\n",
       " 'ore in joy',\n",
       " 're in joy ',\n",
       " 'e in joy a',\n",
       " ' in joy at',\n",
       " 'in joy at ',\n",
       " 'n joy at f',\n",
       " ' joy at fi',\n",
       " 'joy at fir',\n",
       " 'oy at firs']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings10[14423:14433]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('z', 0.9380468726158142),\n",
       "  ('i', 0.03080154024064541),\n",
       "  ('e', 0.01610080525279045),\n",
       "  ('c', 0.004550227429717779),\n",
       "  ('h', 0.003850192530080676),\n",
       "  ('p', 0.002100104931741953),\n",
       "  (':', 0.0014000700321048498),\n",
       "  ('o', 0.0014000700321048498),\n",
       "  ('u', 0.0007000350160524249),\n",
       "  (' ', 0.0007000350160524249)],\n",
       " [('z', 0.9996668100357056),\n",
       "  ('u', 0.00010660554107744247),\n",
       "  ('I', 7.993520557647571e-05),\n",
       "  ('U', 2.734881672949996e-05),\n",
       "  ('K', 2.4257360564661212e-05),\n",
       "  ('P', 1.5074498151079752e-05),\n",
       "  ('L', 1.0885321898967959e-05),\n",
       "  ('n', 8.451069334114436e-06),\n",
       "  ('O', 8.223939403251279e-06),\n",
       "  ('f', 7.135453870432684e-06)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_sim.simulate('First Citi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('e', 0.3421829044818878),\n",
       "  ('u', 0.17404130101203918),\n",
       "  ('o', 0.13716813921928406),\n",
       "  ('h', 0.09587020426988602),\n",
       "  ('y', 0.08554572612047195),\n",
       "  ('a', 0.07669616490602493),\n",
       "  ('n', 0.033923305571079254),\n",
       "  ('i', 0.028023598715662956),\n",
       "  ('r', 0.011799409985542297),\n",
       "  ('t', 0.007374631240963936)],\n",
       " [('e', 0.47825106978416443),\n",
       "  ('u', 0.2509588301181793),\n",
       "  ('y', 0.1266946792602539),\n",
       "  ('r', 0.05788085237145424),\n",
       "  ('i', 0.03135434538125992),\n",
       "  ('o', 0.02440422773361206),\n",
       "  ('a', 0.017102370038628578),\n",
       "  ('l', 0.012891546823084354),\n",
       "  ('s', 8.761954813962802e-05),\n",
       "  ('R', 7.359156006714329e-05)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_sim.simulate('Citizen:\\nB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('t', 0.15815085172653198),\n",
       "  ('b', 0.1228710487484932),\n",
       "  ('o', 0.11313868314027786),\n",
       "  ('a', 0.10340632498264313),\n",
       "  ('i', 0.09975668787956238),\n",
       "  ('d', 0.058394160121679306),\n",
       "  ('s', 0.05352798104286194),\n",
       "  ('w', 0.04866180196404457),\n",
       "  ('m', 0.03041362576186657),\n",
       "  ('f', 0.027980534359812737)],\n",
       " [('t', 0.16370470821857452),\n",
       "  ('s', 0.10785210877656937),\n",
       "  ('a', 0.09744462370872498),\n",
       "  ('b', 0.09677103161811829),\n",
       "  ('c', 0.08353256434202194),\n",
       "  ('m', 0.056587863713502884),\n",
       "  ('d', 0.048968441784381866),\n",
       "  ('p', 0.04876013845205307),\n",
       "  ('h', 0.04751131683588028),\n",
       "  ('w', 0.038983285427093506)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_sim.simulate('Shyamalan ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('y', 0.6007066965103149),\n",
       "  ('t', 0.16607773303985596),\n",
       "  ('i', 0.07773851603269577),\n",
       "  ('s', 0.06713780760765076),\n",
       "  ('u', 0.038869258016347885),\n",
       "  ('m', 0.017667844891548157),\n",
       "  ('d', 0.010600706562399864),\n",
       "  ('r', 0.007067137863487005),\n",
       "  ('k', 0.0035335689317435026),\n",
       "  ('l', 0.0035335689317435026)],\n",
       " [('y', 0.8568735718727112),\n",
       "  ('i', 0.06098264083266258),\n",
       "  ('u', 0.04135835915803909),\n",
       "  ('c', 0.016126777976751328),\n",
       "  ('t', 0.012861563824117184),\n",
       "  ('l', 0.0022685928270220757),\n",
       "  ('o', 0.0021818610839545727),\n",
       "  ('s', 0.0016513006994500756),\n",
       "  ('v', 0.001559981144964695),\n",
       "  ('w', 0.0011889823945239186)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_sim.simulate('more in jo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_simulate_results2(strings: Sequence[str], sim_outputs: Sequence, model_outputs: Sequence):\n",
    "    \"\"\"A version of analyze_simulate_results() that computes results for the\n",
    "    full length of the returned results.\"\"\"\n",
    "\n",
    "    topn_matches = [0 for _ in range(10)]\n",
    "    topn_matches_any_order = [0 for _ in range(10)]\n",
    "    for i, s in enumerate(strings):\n",
    "        sim_output = sim_outputs[i]\n",
    "        model_output = model_outputs[i]\n",
    "        sim_tokens, _ = zip(*sim_output)\n",
    "        model_tokens, _ = zip(*model_output)\n",
    "\n",
    "        n = min(len(sim_tokens), len(model_tokens))\n",
    "        for j in range(n):\n",
    "            if sim_tokens[j] == model_tokens[j]:\n",
    "                topn_matches[j] += 1\n",
    "            if set(sim_tokens[:j+1]) == set(model_tokens[:j+1]):\n",
    "                topn_matches_any_order[j] += 1\n",
    "\n",
    "    return topn_matches, topn_matches_any_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20000\n",
    "ss_exp20k = SimilarStringsExperiment(\n",
    "    exp10.output_dir / 'similar_strings',\n",
    "    encoding_helpers\n",
    ")\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "indices = torch.randperm(len(exp10.strings))[:n_samples]\n",
    "strings = [exp10.strings[i.item()] for i in indices]\n",
    "\n",
    "ss_results20k = ss_exp20k.load_results_for_strings(strings)\n",
    "\n",
    "ss_sim20k = SimulationFromSimilarStringsExperimentResults(ss_results20k, next_token_map10, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a next token map for each prefix length that we've run experiments for.\n",
    "next_token_map3 = build_next_token_map(ts.text, prefix_len=3, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)\n",
    "next_token_map4 = build_next_token_map(ts.text, prefix_len=4, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)\n",
    "next_token_map5 = build_next_token_map(ts.text, prefix_len=5, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)\n",
    "next_token_map6 = build_next_token_map(ts.text, prefix_len=6, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)\n",
    "next_token_map7 = build_next_token_map(ts.text, prefix_len=7, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)\n",
    "next_token_map8 = build_next_token_map(ts.text, prefix_len=8, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)\n",
    "next_token_map9 = build_next_token_map(ts.text, prefix_len=9, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)\n",
    "next_token_map10 = build_next_token_map(ts.text, prefix_len=10, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_token_lens = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "all_token_maps = [\n",
    "    next_token_map3,\n",
    "    next_token_map4,\n",
    "    next_token_map5,\n",
    "    next_token_map6,\n",
    "    next_token_map7,\n",
    "    next_token_map8,\n",
    "    next_token_map9,\n",
    "    next_token_map10\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the token maps into one\n",
    "next_token_map_all = {\n",
    "    **next_token_map3,\n",
    "    **next_token_map4,\n",
    "    **next_token_map5,\n",
    "    **next_token_map6,\n",
    "    **next_token_map7,\n",
    "    **next_token_map8,\n",
    "    **next_token_map9,\n",
    "    **next_token_map10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'waking.\\n' has no next tokens\n",
      "' waking.\\n' has no next tokens\n",
      "'t waking.\\n' has no next tokens\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for entries that have no next token. This should only be the case\n",
    "# for cases where the last substring in the text is unique.\n",
    "for k, v in next_token_map_all.items():\n",
    "    if v.sum() == 0:\n",
    "        print(f\"{repr(k)} has no next tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check all the lengths are right.\n",
    "for l, token_map in zip(all_token_lens, all_token_maps):\n",
    "    for k in token_map.keys():\n",
    "        if len(k) != l:\n",
    "            print(f\"{repr(k)} has length {len(k)} but should have length {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_is=[3, 4, 5, 6, 7, 8, 9]\n",
    "ss_results20k_all_t_is = ss_exp20k.load_results_for_strings(strings, load_t_is=t_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_sim20k_aggr = SimulationFromSimilarStringsExperimentResults(\n",
    "    ss_results20k_all_t_is, next_token_map_all, encoding_helpers, aggregate_over_t_is=t_is\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39974e5ee11548dfbb8277b4edb31c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_outputs, model_outputs = zip(*[\n",
    "    ss_sim20k.simulate(s)\n",
    "    for s in tqdm(strings)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.774\n",
      "Top 1 matches (any order): 0.774\n",
      "Top 2 matches: 0.398\n",
      "Top 2 matches (any order): 0.452\n",
      "Top 3 matches: 0.211\n",
      "Top 3 matches (any order): 0.238\n",
      "Top 4 matches: 0.141\n",
      "Top 4 matches (any order): 0.143\n",
      "Top 5 matches: 0.102\n",
      "Top 5 matches (any order): 0.088\n",
      "Top 6 matches: 0.081\n",
      "Top 6 matches (any order): 0.054\n",
      "Top 7 matches: 0.059\n",
      "Top 7 matches (any order): 0.028\n",
      "Top 8 matches: 0.053\n",
      "Top 8 matches (any order): 0.018\n",
      "Top 9 matches: 0.046\n",
      "Top 9 matches (any order): 0.010\n",
      "Top 10 matches: 0.037\n",
      "Top 10 matches (any order): 0.005\n"
     ]
    }
   ],
   "source": [
    "topn_matches, topn_matches_any_order = analyze_simulate_results2(strings, sim_outputs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / n_samples:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_samples:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a190e1c6c045bb884a3cc187cdf429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_outputs2, model_outputs2 = zip(*[\n",
    "    ss_sim20k_aggr.simulate(s)\n",
    "    for s in tqdm(strings)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.742\n",
      "Top 1 matches (any order): 0.742\n",
      "Top 2 matches: 0.363\n",
      "Top 2 matches (any order): 0.415\n",
      "Top 3 matches: 0.197\n",
      "Top 3 matches (any order): 0.212\n",
      "Top 4 matches: 0.136\n",
      "Top 4 matches (any order): 0.130\n",
      "Top 5 matches: 0.098\n",
      "Top 5 matches (any order): 0.081\n",
      "Top 6 matches: 0.080\n",
      "Top 6 matches (any order): 0.048\n",
      "Top 7 matches: 0.060\n",
      "Top 7 matches (any order): 0.027\n",
      "Top 8 matches: 0.053\n",
      "Top 8 matches (any order): 0.016\n",
      "Top 9 matches: 0.044\n",
      "Top 9 matches (any order): 0.010\n",
      "Top 10 matches: 0.036\n",
      "Top 10 matches (any order): 0.004\n"
     ]
    }
   ],
   "source": [
    "n_samples = 20000\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results2(strings, sim_outputs2, model_outputs2)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / n_samples:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_samples:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('a', 0.8568075299263),\n",
       "  ('i', 0.09624413400888443),\n",
       "  ('e', 0.018779342994093895),\n",
       "  ('o', 0.014084506779909134),\n",
       "  ('r', 0.004694835748523474),\n",
       "  ('v', 0.004694835748523474),\n",
       "  ('c', 0.002347417874261737),\n",
       "  ('d', 0.002347417874261737)],\n",
       " [('a', 0.4602494537830353),\n",
       "  ('e', 0.35252559185028076),\n",
       "  ('o', 0.09188850224018097),\n",
       "  ('i', 0.09030349552631378),\n",
       "  ('u', 0.004192721098661423),\n",
       "  ('y', 0.0007521358784288168),\n",
       "  ('r', 6.647213740507141e-05),\n",
       "  ('l', 3.957989065384027e-06),\n",
       "  ('v', 2.812936827467638e-06),\n",
       "  ('w', 2.738903503995971e-06)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_sim20k_aggr.simulate('my most gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('a', 0.74631267786026),\n",
       "  ('i', 0.14454276859760284),\n",
       "  ('o', 0.05604719743132591),\n",
       "  ('e', 0.02654867246747017),\n",
       "  ('n', 0.005899704992771149),\n",
       "  ('c', 0.005899704992771149),\n",
       "  ('v', 0.005899704992771149),\n",
       "  ('d', 0.0029498524963855743),\n",
       "  ('r', 0.0029498524963855743),\n",
       "  ('l', 0.0029498524963855743)],\n",
       " [('a', 0.4602494537830353),\n",
       "  ('e', 0.35252559185028076),\n",
       "  ('o', 0.09188850224018097),\n",
       "  ('i', 0.09030349552631378),\n",
       "  ('u', 0.004192721098661423),\n",
       "  ('y', 0.0007521358784288168),\n",
       "  ('r', 6.647213740507141e-05),\n",
       "  ('l', 3.957989065384027e-06),\n",
       "  ('v', 2.812936827467638e-06),\n",
       "  ('w', 2.738903503995971e-06)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_sim20k.simulate('my most gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sim_strings(result: SimilarStringsResult, aggregate_over_t_is: Sequence[int]):\n",
    "    aggr_proj_out, aggr_ffwd_out = result.aggregate_over_t_is(aggregate_over_t_is)\n",
    "    n_similars = len(aggr_proj_out[0].sim_strings)\n",
    "    print(\"Proj Outputs\")\n",
    "    for i in range(n_similars):\n",
    "        print(''.join([f\"{aggr_proj_out[block_idx].sim_strings[i]:>14} ({aggr_proj_out[block_idx].distances[i]:.2f})\" for block_idx in range(n_layer)]))\n",
    "\n",
    "    print()\n",
    "    print(\"FFwd Outputs\")\n",
    "    for i in range(n_similars):\n",
    "        print(''.join([f\"{aggr_ffwd_out[block_idx].sim_strings[i]:>14} ({aggr_ffwd_out[block_idx].distances[i]:.2f})\" for block_idx in range(n_layer)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proj Outputs\n",
      "    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)\n",
      "    ur most gr (0.79)    ur most gr (0.95)    is most gr (2.27)     y most gr (3.56)     my most r (4.90)     my most r (2.75)\n",
      "    is most gr (0.80)    ne most gr (0.96)    ur most gr (2.43)    ur most gr (3.95)     y most gr (5.00)     my most l (3.52)\n",
      "    ne most gr (0.80)    he most gr (1.05)     y most gr (2.56)     r most gr (4.34)         my gr (5.38)     my most h (3.79)\n",
      "    ilst my gr (0.82)    is most gr (1.06)    ne most gr (2.63)       most gr (4.51)         my sl (5.54)    my most st (3.91)\n",
      "    he most gr (0.84)    e, most gr (1.27)    he most gr (2.88)       most gu (4.61)     my most g (5.54)        my mos (3.97)\n",
      "    unto my gr (0.89)    o, must gr (1.35)     r most gr (2.99)       most gl (4.67)         my gh (5.69)        my mod (4.01)\n",
      "    e, most gr (0.89)    t, most gr (1.36)    e, most gr (3.16)    ne most gr (4.72)     my most l (5.76)        my mot (4.04)\n",
      "    t, most gr (0.90)    be past gr (1.37)     s most gr (3.18)     s most gr (4.85)    he most gr (5.85)        my mon (4.08)\n",
      "    yman to gr (0.92)    yet not gr (1.51)       most gr (3.20)     e most gr (4.86)    my most st (5.86)        my mou (4.14)\n",
      "\n",
      "FFwd Outputs\n",
      "    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)\n",
      "    ne most gr (0.14)    ne most gr (0.43)    ur most gr (0.75)    ur most gr (1.77)    ur most gr (2.76)    t, most gr (3.17)\n",
      "    ur most gr (0.14)    ur most gr (0.44)    is most gr (0.78)    ne most gr (2.05)    he most gr (2.90)    e, most gr (3.23)\n",
      "    he most gr (0.14)    he most gr (0.51)    ne most gr (0.83)    is most gr (2.23)    ne most gr (2.94)    ur most gr (3.45)\n",
      "    e, most gr (0.14)    is most gr (0.57)    he most gr (0.89)    he most gr (2.56)     y most gr (2.98)     , most gr (3.49)\n",
      "    ilst my gr (0.15)    t, most gr (0.57)    e, most gr (1.23)     y most gr (3.26)     r most gr (3.41)     y most gr (3.72)\n",
      "    t, most gr (0.15)    e, most gr (0.58)    t, most gr (1.32)     r most gr (3.28)    is most gr (3.60)    ne most gr (3.88)\n",
      "    is most gr (0.15)    ver yet gr (0.66)    do them gr (2.21)    e, most gr (3.44)     e most gr (3.75)    is most gr (3.90)\n",
      "    unto my gr (0.15)     cannot gr (0.70)    im that gr (2.24)     s most gr (3.57)       most gr (3.88)    our own gr (3.95)\n",
      "    o, must gr (0.16)    o, must gr (0.71)    o, must gr (2.25)     e most gr (3.70)    e, most gr (3.89)         or gr (4.04)\n"
     ]
    }
   ],
   "source": [
    "print_sim_strings(ss_results20k_all_t_is['my most gr'], t_is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to just looking at t_i=-1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proj Outputs\n",
      "    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)\n",
      "    ur most gr (0.79)    ur most gr (0.95)    is most gr (2.27)    ur most gr (3.95)    he most gr (5.85)    my most st (3.91)\n",
      "    is most gr (0.80)    ne most gr (0.96)    ur most gr (2.43)    ne most gr (4.72)    my most st (5.86)    my most sa (4.33)\n",
      "    ne most gr (0.80)    he most gr (1.05)    ne most gr (2.63)    nd most gu (5.16)    ur most gr (6.43)     my most r (4.56)\n",
      "    ilst my gr (0.82)    is most gr (1.06)    he most gr (2.88)    nd most gl (5.34)     my most r (6.52)     my most l (5.16)\n",
      "    he most gr (0.84)    e, most gr (1.27)    e, most gr (3.16)    he most ge (5.49)    my young r (6.56)    my high bl (5.20)\n",
      "    unto my gr (0.89)    o, must gr (1.35)    t, most gr (3.29)    is most gr (5.53)    my young p (6.58)    m thy moth (5.22)\n",
      "    e, most gr (0.89)    t, most gr (1.36)    nd most gl (3.57)    ld most gl (5.64)    my young c (6.79)    mt my mast (5.22)\n",
      "    t, most gr (0.90)    be past gr (1.37)    ld most gl (3.71)    e; most go (5.96)    my part sh (6.84)    my most he (5.34)\n",
      "    yman to gr (0.92)    yet not gr (1.51)    he most ge (4.52)    e, most gr (6.00)    my young l (6.87)    my merry m (5.45)\n",
      "\n",
      "FFwd Outputs\n",
      "    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)\n",
      "    ne most gr (0.14)    ne most gr (0.43)    ur most gr (0.75)    ur most gr (1.77)    ur most gr (2.76)    t, most gr (3.17)\n",
      "    ur most gr (0.14)    ur most gr (0.44)    is most gr (0.78)    ne most gr (2.05)    he most gr (2.90)    e, most gr (3.23)\n",
      "    he most gr (0.14)    he most gr (0.51)    ne most gr (0.83)    is most gr (2.23)    ne most gr (2.94)    ur most gr (3.45)\n",
      "    e, most gr (0.14)    is most gr (0.57)    he most gr (0.89)    he most gr (2.56)    is most gr (3.60)    ne most gr (3.88)\n",
      "    ilst my gr (0.15)    t, most gr (0.57)    e, most gr (1.23)    e, most gr (3.44)    e, most gr (3.89)    is most gr (3.90)\n",
      "    t, most gr (0.15)    e, most gr (0.58)    t, most gr (1.32)    t, most gr (3.77)    t, most gr (4.29)    our own gr (3.95)\n",
      "    is most gr (0.15)    ver yet gr (0.66)    do them gr (2.21)     common gr (3.88)    dd more gr (5.07)     but my gr (4.61)\n",
      "    unto my gr (0.15)     cannot gr (0.70)    im that gr (2.24)    is more gr (4.06)     but my gr (5.27)    nto her gr (4.71)\n",
      "    o, must gr (0.16)    o, must gr (0.71)    o, must gr (2.25)    dd more gr (4.06)    is more gr (5.33)    dd more gr (4.73)\n"
     ]
    }
   ],
   "source": [
    "print_sim_strings(ss_results20k_all_t_is['my most gr'], [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to try a lot of experiments so need to be able to simulate a lot of strings fast. Let's see if we can pick a random sample and get representative results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "results_strings = list(ss_results20k_all_t_is.keys())\n",
    "torch.manual_seed(1337)\n",
    "indices = torch.randperm(len(results_strings))[:n_samples]\n",
    "sample_strings = [results_strings[i.item()] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_sample(sample_strings: Sequence[str], ss_sim: SimulationFromSimilarStringsExperimentResults):\n",
    "    n_samples = len(sample_strings)\n",
    "    sim_outputs, model_outputs = zip(*[\n",
    "        ss_sim.simulate(s)\n",
    "        for s in tqdm(sample_strings)\n",
    "    ])\n",
    "    topn_matches, topn_matches_any_order = analyze_simulate_results2(sample_strings, sim_outputs, model_outputs)\n",
    "    for i in range(10):\n",
    "        print(f\"Top {i+1} matches: {topn_matches[i] / n_samples:.3f}\")\n",
    "        print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_samples:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6bd1222e23450ba148de5632124e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.754\n",
      "Top 1 matches (any order): 0.754\n",
      "Top 2 matches: 0.368\n",
      "Top 2 matches (any order): 0.426\n",
      "Top 3 matches: 0.186\n",
      "Top 3 matches (any order): 0.204\n",
      "Top 4 matches: 0.152\n",
      "Top 4 matches (any order): 0.114\n",
      "Top 5 matches: 0.094\n",
      "Top 5 matches (any order): 0.082\n",
      "Top 6 matches: 0.100\n",
      "Top 6 matches (any order): 0.052\n",
      "Top 7 matches: 0.052\n",
      "Top 7 matches (any order): 0.030\n",
      "Top 8 matches: 0.040\n",
      "Top 8 matches (any order): 0.016\n",
      "Top 9 matches: 0.034\n",
      "Top 9 matches (any order): 0.010\n",
      "Top 10 matches: 0.038\n",
      "Top 10 matches (any order): 0.004\n"
     ]
    }
   ],
   "source": [
    "eval_on_sample(sample_strings, ss_sim20k_aggr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, kinda representative and runs in ~6 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proj Outputs\n",
      "    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)\n",
      "    ur most gr (0.79)    ur most gr (0.95)    is most gr (2.27)     y most gr (3.56)     my most r (4.90)     my most r (2.75)\n",
      "    is most gr (0.80)    ne most gr (0.96)    ur most gr (2.43)    ur most gr (3.95)     y most gr (5.00)     my most l (3.52)\n",
      "    ne most gr (0.80)    he most gr (1.05)     y most gr (2.56)     r most gr (4.34)         my gr (5.38)     my most h (3.79)\n",
      "    ilst my gr (0.82)    is most gr (1.06)    ne most gr (2.63)       most gr (4.51)         my sl (5.54)    my most st (3.91)\n",
      "    he most gr (0.84)    e, most gr (1.27)    he most gr (2.88)       most gu (4.61)     my most g (5.54)        my mos (3.97)\n",
      "    unto my gr (0.89)    o, must gr (1.35)     r most gr (2.99)       most gl (4.67)         my gh (5.69)        my mod (4.01)\n",
      "    e, most gr (0.89)    t, most gr (1.36)    e, most gr (3.16)    ne most gr (4.72)     my most l (5.76)        my mot (4.04)\n",
      "    t, most gr (0.90)    be past gr (1.37)     s most gr (3.18)     s most gr (4.85)    he most gr (5.85)        my mon (4.08)\n",
      "    yman to gr (0.92)    yet not gr (1.51)       most gr (3.20)     e most gr (4.86)    my most st (5.86)        my mou (4.14)\n",
      "\n",
      "FFwd Outputs\n",
      "    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)    my most gr (0.00)\n",
      "    ne most gr (0.14)    ne most gr (0.43)    ur most gr (0.75)    ur most gr (1.77)    ur most gr (2.76)    t, most gr (3.17)\n",
      "    ur most gr (0.14)    ur most gr (0.44)    is most gr (0.78)    ne most gr (2.05)    he most gr (2.90)    e, most gr (3.23)\n",
      "    he most gr (0.14)    he most gr (0.51)    ne most gr (0.83)    is most gr (2.23)    ne most gr (2.94)    ur most gr (3.45)\n",
      "    e, most gr (0.14)    is most gr (0.57)    he most gr (0.89)    he most gr (2.56)     y most gr (2.98)     , most gr (3.49)\n",
      "    ilst my gr (0.15)    t, most gr (0.57)    e, most gr (1.23)     y most gr (3.26)     r most gr (3.41)     y most gr (3.72)\n",
      "    t, most gr (0.15)    e, most gr (0.58)    t, most gr (1.32)     r most gr (3.28)    is most gr (3.60)    ne most gr (3.88)\n",
      "    is most gr (0.15)    ver yet gr (0.66)    do them gr (2.21)    e, most gr (3.44)     e most gr (3.75)    is most gr (3.90)\n",
      "    unto my gr (0.15)     cannot gr (0.70)    im that gr (2.24)     s most gr (3.57)       most gr (3.88)    our own gr (3.95)\n",
      "    o, must gr (0.16)    o, must gr (0.71)    o, must gr (2.25)     e most gr (3.70)    e, most gr (3.89)         or gr (4.04)\n"
     ]
    }
   ],
   "source": [
    "print_sim_strings(ss_results20k_all_t_is['my most gr'], t_is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we do if we just used the next tokens for the prompt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_just_next_tokens_from_prompt(prompt: str, next_token_map: Dict[str, torch.Tensor], encoding_helpers: EncodingHelpers):\n",
    "    next_tokens = next_token_map[prompt]\n",
    "    return top_nonzero_tokens(\n",
    "        next_tokens.float() / next_tokens.sum(), encoding_helpers.tokenizer.itos\n",
    "    )[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e997d00e024ee28dd6f5c339a78248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sim_jntfp_out = [\n",
    "    sim_just_next_tokens_from_prompt(s, next_token_map_all, encoding_helpers)\n",
    "    for s in tqdm(strings)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.606\n",
      "Top 1 matches (any order): 0.606\n",
      "Top 2 matches: 0.011\n",
      "Top 2 matches (any order): 0.012\n",
      "Top 3 matches: 0.002\n",
      "Top 3 matches (any order): 0.001\n",
      "Top 4 matches: 0.001\n",
      "Top 4 matches (any order): 0.001\n",
      "Top 5 matches: 0.001\n",
      "Top 5 matches (any order): 0.000\n",
      "Top 6 matches: 0.000\n",
      "Top 6 matches (any order): 0.000\n",
      "Top 7 matches: 0.000\n",
      "Top 7 matches (any order): 0.000\n",
      "Top 8 matches: 0.000\n",
      "Top 8 matches (any order): 0.000\n",
      "Top 9 matches: 0.000\n",
      "Top 9 matches (any order): 0.000\n",
      "Top 10 matches: 0.000\n",
      "Top 10 matches (any order): 0.000\n"
     ]
    }
   ],
   "source": [
    "n_samples = 20000\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results2(strings, sim_jntfp_out, model_outputs2)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / n_samples:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_samples:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so 60% on the top 1 token, but it quickly falls off after that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_contributors(result: SimilarStringsResult, aggregate_over_t_is: Sequence[int]):\n",
    "    aggr_proj_out, aggr_ffwd_out = result.aggregate_over_t_is(aggregate_over_t_is)\n",
    "\n",
    "    s_to_next_tokens_map = {}\n",
    "\n",
    "    for s in result.embs.sim_strings:\n",
    "        s_to_next_tokens_map[s] = next_token_map_all[s]\n",
    "\n",
    "    for block_idx in range(n_layer):\n",
    "        for s in aggr_proj_out[block_idx].sim_strings:\n",
    "            s_to_next_tokens_map[s] = next_token_map_all[s]\n",
    "        for s in aggr_ffwd_out[block_idx].sim_strings:\n",
    "            s_to_next_tokens_map[s] = next_token_map_all[s]\n",
    "\n",
    "    def _print(item: Tuple[str, torch.Tensor]):\n",
    "        s, next_tokens = item\n",
    "        top_tokens = top_nonzero_tokens(next_tokens.float() / next_tokens.sum(), encoding_helpers.tokenizer.itos)\n",
    "        tokens_str = ', '.join([f\"{repr(t):>3} ({p:.2f})\" for t, p in top_tokens])\n",
    "        return f\"{repr(s):>14}: {tokens_str}\"\n",
    "\n",
    "    return DataWrapper(s_to_next_tokens_map.items(), _print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'my most gr': 'a' (1.00)\n",
      "  'my most sa': 'c' (1.00)\n",
      "  't, most gr': 'a' (1.00)\n",
      "  'my most st': 'a' (1.00)\n",
      "  'e, most gr': 'a' (1.00)\n",
      "  'ur most gr': 'a' (1.00)\n",
      "  'is most gr': 'i' (1.00)\n",
      "  'my most so': 'v' (1.00)\n",
      "  'my most re': 'd' (1.00)\n",
      "  'my most he': 'a' (1.00)\n",
      "  'ne most gr': 'a' (1.00)\n",
      "  'ilst my gr': 'o' (1.00)\n",
      "  'he most gr': 'a' (1.00)\n",
      "  'unto my gr': 'a' (1.00)\n",
      "  'yman to gr': 'i' (1.00)\n",
      "  'o, must gr': 'a' (1.00)\n",
      "  'be past gr': 'i' (1.00)\n",
      "  'yet not gr': 'e' (1.00)\n",
      "  'ver yet gr': 'e' (1.00)\n",
      "  ' cannot gr': 'e' (1.00)\n",
      "   'y most gr': 'a' (1.00)\n",
      "   'r most gr': 'a' (1.00)\n",
      "   's most gr': 'i' (1.00)\n",
      "    ' most gr': 'a' (0.89), 'i' (0.11)\n",
      "  'do them gr': 'a' (1.00)\n",
      "  'im that gr': 'a' (1.00)\n",
      "     'most gr': 'a' (0.89), 'i' (0.11)\n",
      "     'most gu': 'i' (1.00)\n",
      "    ' most gl': 'a' (1.00)\n",
      "   'e most gr': 'a' (1.00)\n",
      "   'my most r': 'e' (1.00)\n",
      "       'my gr': 'a' (0.55), 'i' (0.22), 'e' (0.16), 'o' (0.06)\n",
      "       'my sl': 'e' (0.40), 'a' (0.40), 'i' (0.20)\n",
      "   'my most g': 'r' (1.00)\n",
      "       'my gh': 'o' (1.00)\n",
      "   'my most l': 'o' (1.00)\n",
      "   'my most h': 'e' (1.00)\n",
      "      'my mos': 't' (1.00)\n",
      "      'my mod': 'e' (1.00)\n",
      "      'my mot': 'h' (1.00)\n",
      "      'my mon': 'e' (1.00)\n",
      "      'my mou': 't' (0.67), 'r' (0.33)\n",
      "   ', most gr': 'a' (1.00)\n",
      "  'our own gr': 'a' (1.00)\n",
      "       'or gr': 'a' (0.56), 'e' (0.19), 'u' (0.12), 'o' (0.06), 'i' (0.06)\n"
     ]
    }
   ],
   "source": [
    "unique_contributors(ss_results20k_all_t_is['my most gr'], t_is).print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything below was run when I'd only generated strings for 2000 samples\n",
    "Needs to be re-run now that we have 20,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultDataFile:\n",
    "    def __init__(self, filename: str):\n",
    "        self.filename = filename\n",
    "        self.data = json.loads(Path(filename).read_text())\n",
    "        self.prompts = self.data['prompts']\n",
    "        self.prompt_to_idx = {p: i for i, p in enumerate(self.prompts)}\n",
    "\n",
    "    def emb_similar_strings(self, prompt: str) -> Sequence[str]:\n",
    "        return self.data['emb_similar_strings'][self.prompt_to_idx[prompt]]\n",
    "\n",
    "    def proj_similar_strings(self, prompt: str, block_idx: int) -> Sequence[str]:\n",
    "        return self.data['blocks'][block_idx]['proj_similar_strings'][self.prompt_to_idx[prompt]]\n",
    "\n",
    "    def ffwd_similar_strings(self, prompt: str, block_idx: int) -> Sequence[str]:\n",
    "        return self.data['blocks'][block_idx]['ffwd_similar_strings'][self.prompt_to_idx[prompt]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['by present',\n",
       "  'My present',\n",
       "  'be present',\n",
       "  'dy present',\n",
       "  'my present',\n",
       "  'ry present',\n",
       "  'y, present',\n",
       "  't, present',\n",
       "  'on present',\n",
       "  'in present'],\n",
       " ['by present',\n",
       "  'my present',\n",
       "  'dy present',\n",
       "  'be present',\n",
       "  'ry present',\n",
       "  'My present',\n",
       "  'y; present',\n",
       "  'is present',\n",
       "  'im present',\n",
       "  'do present'],\n",
       " ['by present',\n",
       "  'my present',\n",
       "  'dy present',\n",
       "  'ry present',\n",
       "  'in present',\n",
       "  'se present',\n",
       "  'he present',\n",
       "  'is present',\n",
       "  'My present',\n",
       "  'be present'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = ResultDataFile(output_dir / 'results_000.json')\n",
    "prompt = r.prompts[1]\n",
    "r.emb_similar_strings(prompt), r.proj_similar_strings(prompt, 0), r.ffwd_similar_strings(prompt, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(filenames: Sequence[str]):\n",
    "    prompts = []\n",
    "    emb_freqs = []\n",
    "    proj_freqs = [[] for _ in range(n_layer)]\n",
    "    ffwd_freqs = [[] for _ in range(n_layer)]\n",
    "\n",
    "    for filename in filenames:\n",
    "        r = ResultDataFile(filename)\n",
    "        prompts.extend(r.prompts)\n",
    "        emb_freqs.extend(\n",
    "            [\n",
    "                SubstringFrequencyAnalysis(\n",
    "                    r.emb_similar_strings(p), next_token_map10, tokenizer.itos\n",
    "                ).cumulative_freqs\n",
    "                for p in r.prompts\n",
    "            ]\n",
    "        )\n",
    "        for block_idx in range(n_layer):\n",
    "            proj_freqs[block_idx].extend(\n",
    "                [\n",
    "                    SubstringFrequencyAnalysis(\n",
    "                        r.proj_similar_strings(p, block_idx),\n",
    "                        next_token_map10,\n",
    "                        tokenizer.itos,\n",
    "                    ).cumulative_freqs\n",
    "                    for p in r.prompts\n",
    "                ]\n",
    "            )\n",
    "            ffwd_freqs[block_idx].extend(\n",
    "                [\n",
    "                    SubstringFrequencyAnalysis(\n",
    "                        r.ffwd_similar_strings(p, block_idx),\n",
    "                        next_token_map10,\n",
    "                        tokenizer.itos,\n",
    "                    ).cumulative_freqs\n",
    "                    for p in r.prompts\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return (\n",
    "        prompts,\n",
    "        torch.stack(emb_freqs), # (n_prompts, vocab_size)\n",
    "        torch.stack([torch.stack(freqs) for freqs in proj_freqs]), # (n_layer, n_prompts, vocab_size)\n",
    "        torch.stack([torch.stack(freqs) for freqs in ffwd_freqs]), # (n_layer, n_prompts, vocab_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = output_dir.glob('*.json')\n",
    "prompts, emb_freqs, proj_freqs, ffwd_freqs = aggregate_data(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 65])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the real model outputs. This is what we'll evaluate loss against\n",
    "tokens = encoding_helpers.tokenize_strings(prompts)\n",
    "logits, _ = m(tokens)\n",
    "logits = LogitsWrapper(logits.detach(), tokenizer)\n",
    "model_probs = logits.probs()[:, -1, :]\n",
    "model_probs.shape # (n_prompts, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 65]), torch.Size([6, 2000, 65]), torch.Size([6, 2000, 65]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_freqs.shape, proj_freqs.shape, ffwd_freqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training / validation data split\n",
    "n_train = int(len(prompts) * 0.75)\n",
    "n_val = len(prompts) - n_train\n",
    "train_prompts, train_emb_freqs, train_proj_freqs, train_ffwd_freqs, train_model_probs = (\n",
    "    prompts[:n_train],\n",
    "    emb_freqs[:n_train],\n",
    "    proj_freqs[:, :n_train, :],\n",
    "    ffwd_freqs[:, :n_train, :],\n",
    "    model_probs[:n_train, :],\n",
    ")\n",
    "val_prompts, val_emb_freqs, val_proj_freqs, val_ffwd_freqs, val_model_probs = (\n",
    "    prompts[n_train:],\n",
    "    emb_freqs[n_train:],\n",
    "    proj_freqs[:, n_train:, :],\n",
    "    ffwd_freqs[:, n_train:, :],\n",
    "    model_probs[n_train:, :],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,\n",
       " torch.Size([1500, 65]),\n",
       " torch.Size([6, 1500, 65]),\n",
       " torch.Size([6, 1500, 65]),\n",
       " torch.Size([1500, 65]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_prompts), train_emb_freqs.shape, train_proj_freqs.shape, train_ffwd_freqs.shape, train_model_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,\n",
       " torch.Size([500, 65]),\n",
       " torch.Size([6, 500, 65]),\n",
       " torch.Size([6, 500, 65]),\n",
       " torch.Size([500, 65]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_prompts), val_emb_freqs.shape, val_proj_freqs.shape, val_ffwd_freqs.shape, val_model_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.22287389636039734),\n",
       " ('y', 0.13782991468906403),\n",
       " ('t', 0.10263929516077042),\n",
       " ('h', 0.09677419066429138),\n",
       " ('w', 0.08797653764486313),\n",
       " ('m', 0.06451612710952759),\n",
       " ('e', 0.05865102633833885),\n",
       " ('d', 0.0498533733189106),\n",
       " ('i', 0.041055720299482346),\n",
       " ('a', 0.03812316805124283)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the calculation with weights but over all the data at once, just to check that this works.\n",
    "emb_weight = torch.tensor(1.0, dtype=torch.float32)\n",
    "proj_weights = torch.tensor(\n",
    "    [1.0 for _ in range(n_layer)], dtype=torch.float32\n",
    ").unsqueeze(dim=1)\n",
    "ffwd_weights = torch.tensor(\n",
    "    [1 + block_idx for block_idx in range(n_layer)], dtype=torch.float32\n",
    ").unsqueeze(dim=1)\n",
    "\n",
    "freqs = (\n",
    "    emb_weight * emb_freqs\n",
    "    + (proj_weights.expand(-1, len(prompts)).unsqueeze(dim=2) * proj_freqs).sum(dim=0)\n",
    "    + (ffwd_weights.expand(-1, len(prompts)).unsqueeze(dim=2) * ffwd_freqs).sum(dim=0)\n",
    ")\n",
    "sim_output_bulk = top_nonzero_tokens(\n",
    "    (freqs.float() / freqs.sum(dim=-1, keepdim=True))[prompt_idx], tokenizer.itos\n",
    ")[:10]\n",
    "test_eq(sim_output[0], sim_output_bulk)\n",
    "\n",
    "sim_output_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "max_iters = 10000\n",
    "eval_interval=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337) # Ensure stable random values\n",
    "\n",
    "# Initialize all the learnable params\n",
    "emb_weight_param = torch.nn.Parameter(\n",
    "    torch.randn(1, dtype=torch.float32), requires_grad=True\n",
    ").to(device)\n",
    "proj_weights_param = torch.nn.Parameter(\n",
    "    torch.randn(n_layer, 1, dtype=torch.float32), requires_grad=True\n",
    ").to(device)\n",
    "ffwd_weights_param = torch.nn.Parameter(\n",
    "    torch.randn(n_layer, 1, dtype=torch.float32), requires_grad=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1723a13f7e2544ebb6b2acfa27c7f647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train loss: 2.405, val loss: 2.457\n",
      "step 1000, train loss: 2.407, val loss: 2.514\n",
      "step 2000, train loss: 2.405, val loss: 2.468\n",
      "step 3000, train loss: 2.405, val loss: 2.470\n",
      "step 4000, train loss: 2.405, val loss: 2.466\n",
      "step 5000, train loss: 2.405, val loss: 2.466\n",
      "step 6000, train loss: 2.405, val loss: 2.469\n",
      "step 7000, train loss: 2.405, val loss: 2.469\n",
      "step 8000, train loss: 2.405, val loss: 2.472\n",
      "step 9000, train loss: 2.405, val loss: 2.472\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW([emb_weight_param, proj_weights_param, ffwd_weights_param], lr=learning_rate)\n",
    "eval_iters = max_iters // 10\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "kl_loss = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "for step in tqdm(range(max_iters)):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate the loss on the training data\n",
    "    train_freqs = (\n",
    "        emb_weight_param*train_emb_freqs +\n",
    "        (proj_weights_param.expand(-1, n_train).unsqueeze(dim=2) * train_proj_freqs).sum(dim=0) +\n",
    "        (ffwd_weights_param.expand(-1, n_train).unsqueeze(dim=2) * train_ffwd_freqs).sum(dim=0)\n",
    "    )\n",
    "    train_probs = train_freqs.float() / train_freqs.sum(dim=1, keepdim=True)\n",
    "    train_loss = kl_loss(F.log_softmax(train_probs, dim=1), train_model_probs)\n",
    "\n",
    "    train_losses.append(train_loss.item())\n",
    "\n",
    "    # Calculate the loss on the validation data\n",
    "    val_freqs = (\n",
    "        emb_weight_param*val_emb_freqs +\n",
    "        (proj_weights_param.expand(-1, n_val).unsqueeze(dim=2) * val_proj_freqs).sum(dim=0) +\n",
    "        (ffwd_weights_param.expand(-1, n_val).unsqueeze(dim=2) * val_ffwd_freqs).sum(dim=0)\n",
    "    )\n",
    "    val_probs = val_freqs.float() / val_freqs.sum(dim=1, keepdim=True)\n",
    "    val_loss = kl_loss(F.log_softmax(val_probs, dim=1), val_model_probs)\n",
    "\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    if step % eval_iters == 0:\n",
    "        print(f\"step {step}, train loss: {train_loss.item():.3f}, val loss: {val_loss.item():.3f}\")\n",
    "\n",
    "    # Take a step\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.3451111614704132),\n",
       " ('h', 0.26503869891166687),\n",
       " ('e', 0.15785954892635345),\n",
       " ('b', 0.13836483657360077),\n",
       " ('y', 0.10449229180812836),\n",
       " ('w', 0.07294415682554245),\n",
       " ('d', 0.0656406581401825),\n",
       " ('i', 0.016737107187509537),\n",
       " ('o', 0.011231524869799614),\n",
       " ('a', 0.008981283754110336)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    freqs = (\n",
    "        emb_weight_param*train_emb_freqs +\n",
    "        (proj_weights_param.expand(-1, n_train).unsqueeze(dim=2) * train_proj_freqs).sum(dim=0) +\n",
    "        (ffwd_weights_param.expand(-1, n_train).unsqueeze(dim=2) * train_ffwd_freqs).sum(dim=0)\n",
    "    )\n",
    "\n",
    "    sim_output_after_training = top_nonzero_tokens(\n",
    "        (freqs.float() / freqs.sum(dim=-1, keepdim=True))[prompt_idx], tokenizer.itos\n",
    "    )[:10]\n",
    "\n",
    "sim_output_after_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.12851786613464355),\n",
       " ('t', 0.12471504509449005),\n",
       " ('s', 0.10041031241416931),\n",
       " ('w', 0.10004922747612),\n",
       " ('h', 0.07621816545724869),\n",
       " ('a', 0.06010913848876953),\n",
       " ('m', 0.05443713441491127),\n",
       " ('i', 0.04418765753507614),\n",
       " ('d', 0.03411226347088814),\n",
       " ('y', 0.03171954303979874)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = encoding_helpers.tokenize_string(prompts[prompt_idx])\n",
    "logits, _ = m(tokens)\n",
    "logits = LogitsWrapper(logits.detach(), tokenizer)\n",
    "logits.topk_tokens(k=10)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0528], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weight_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0464],\n",
       "        [ 0.4467],\n",
       "        [ 0.1209],\n",
       "        [ 0.0964],\n",
       "        [-0.0576],\n",
       "        [ 0.3642]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_weights_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0602],\n",
       "        [ 0.1389],\n",
       "        [-0.4730],\n",
       "        [ 0.4425],\n",
       "        [-0.3310],\n",
       "        [-2.1157]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_weights_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of whether there are similar strings of smaller length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slens = [3, 5, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_n = {\n",
    "    n: all_unique_substrings(ts.text, n)\n",
    "    for n in slens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_maps = {\n",
    "    n: build_next_token_map(\n",
    "        ts.text, prefix_len=n, vocab_size=tokenizer.vocab_size, stoi=tokenizer.stoi\n",
    "    )\n",
    "    for n in slens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in slens:\n",
    "    if list(Path(f'../artifacts/block_internals_results/large_files/slen{n}/').glob('*')) == []:\n",
    "        print(f\"Run `make block_internals_slen{n}_dataset` in the project root to generate the required dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = {\n",
    "    n: BatchedBlockInternalsExperiment(\n",
    "        eh=encoding_helpers,\n",
    "        accessors=accessors,\n",
    "        strings=strings_n[n],\n",
    "        output_dir=Path(f'../artifacts/block_internals_results/large_files/slen{n}/'),\n",
    "        batch_size=10000,\n",
    "    )\n",
    "    for n in slens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_similar_strings(\n",
    "    prompt: str,\n",
    "    block_idx: int,\n",
    "    compare_to_slen: int,\n",
    "):\n",
    "    prompt_accessors = BlockInternalsAccessors(prompt, encoding_helpers, accessors)\n",
    "\n",
    "    sim_strings_comp, distances_comp = exps[compare_to_slen].strings_with_topk_closest_proj_outputs(\n",
    "        block_idx=block_idx,\n",
    "        t_i=-1,\n",
    "        queries=prompt_accessors.proj_output(block_idx=block_idx)[:, -1, :],\n",
    "        k=10,\n",
    "        largest=False,\n",
    "    )\n",
    "\n",
    "    sim_strings, distances = exps[len(prompt)].strings_with_topk_closest_proj_outputs(\n",
    "        block_idx=block_idx,\n",
    "        t_i=-1,\n",
    "        queries=prompt_accessors.proj_output(block_idx=block_idx)[:, -1, :],\n",
    "        k=10,\n",
    "        largest=False,\n",
    "    )\n",
    "\n",
    "    print(f\"Length {compare_to_slen} similars:   Length {len(prompt)} similars:\")\n",
    "    for i in range(10):\n",
    "        print(f'{repr(sim_strings_comp[0][i])} {distances_comp[i].item():.3f}        {repr(sim_strings[0][i])} {distances[i].item():.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this a bunch of times, my conclusions from this are:\n",
    "\n",
    "* Yes it's possible to find similar strings with clear patterns in shorter strings\n",
    "* The distances are greater when the strings are shorter\n",
    "* But seeing which shorter strings are similar is illuminating\n",
    "\n",
    "e.g. for block_idx = 1, looking at similar strings of length 5 vs same length as the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 5 similars:   Length 10 similars:\n",
      "'st go' 4.564        'my most gr' 0.000\n",
      "'ot gl' 4.591        'ur most gr' 0.949\n",
      "'st ga' 4.595        'ne most gr' 0.958\n",
      "'ot ga' 4.609        'he most gr' 1.053\n",
      "'st gl' 4.629        'is most gr' 1.056\n",
      "'ot gr' 4.638        'e, most gr' 1.268\n",
      "'st gr' 4.639        'o, must gr' 1.352\n",
      "'rt go' 4.647        't, most gr' 1.361\n",
      "'st gi' 4.662        'be past gr' 1.372\n",
      "'et go' 4.679        'yet not gr' 1.506\n"
     ]
    }
   ],
   "source": [
    "prompt = 'my most gr'\n",
    "compare_similar_strings(prompt, block_idx=1, compare_to_slen=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the length 5 similar strings have `s t`` in common. \n",
    "\n",
    "Now look at block 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 5 similars:   Length 10 similars:\n",
      "'my mo' 4.464        'my most gr' 0.000\n",
      "'my st' 4.917        'my most st' 3.911\n",
      "'my br' 4.969        'my most sa' 4.328\n",
      "'my tr' 4.977        ' my most r' 4.556\n",
      "'my gr' 5.039        ' my most l' 5.160\n",
      "'my sw' 5.115        'my high bl' 5.198\n",
      "'my sc' 5.132        'm thy moth' 5.221\n",
      "'my wr' 5.140        'mt my mast' 5.225\n",
      "'my bl' 5.215        'my most he' 5.338\n",
      "'my tw' 5.267        'my merry m' 5.445\n"
     ]
    }
   ],
   "source": [
    "prompt = 'my most gr'\n",
    "compare_similar_strings(prompt, block_idx=5, compare_to_slen=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the common pattern in the length 5 strings is `my `."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this says something. The closest length 5 strings could have been any substring of the full prompt. Seeing what gets picked must be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with length 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 3 similars:   Length 10 similars:\n",
      "' gn' 6.114        'my most gr' 0.000\n",
      "' gy' 6.142        'ur most gr' 0.949\n",
      "' gl' 6.156        'ne most gr' 0.958\n",
      "' gr' 6.166        'he most gr' 1.053\n",
      "' gu' 6.202        'is most gr' 1.056\n",
      "' gh' 6.218        'e, most gr' 1.268\n",
      "' go' 6.231        'o, must gr' 1.352\n",
      "' ga' 6.232        't, most gr' 1.361\n",
      "' ge' 6.267        'be past gr' 1.372\n",
      "' gi' 6.397        'yet not gr' 1.506\n"
     ]
    }
   ],
   "source": [
    "prompt = 'my most gr'\n",
    "compare_similar_strings(prompt, block_idx=1, compare_to_slen=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greater distance but still, a pattern. And block 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 3 similars:   Length 10 similars:\n",
      "'mys' 6.682        'my most gr' 0.000\n",
      "'my-' 6.722        'my most st' 3.911\n",
      "'ms-' 7.015        'my most sa' 4.328\n",
      "'myr' 7.065        ' my most r' 4.556\n",
      "'mso' 7.115        ' my most l' 5.160\n",
      "\"my'\" 7.123        'my high bl' 5.198\n",
      "'my?' 7.148        'm thy moth' 5.221\n",
      "'mfu' 7.158        'mt my mast' 5.225\n",
      "'moc' 7.168        'my most he' 5.338\n",
      "\"ms'\" 7.214        'my merry m' 5.445\n"
     ]
    }
   ],
   "source": [
    "prompt = 'my most gr'\n",
    "compare_similar_strings(prompt, block_idx=5, compare_to_slen=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different pattern, but still a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can do this with just the length 10 data and not have to generate all the block internals data for the other string lengths from scratch. \n",
    "\n",
    "As a prereq, let's first see if the intermediate values for substrings within a longer string are the same as the values that would have been produced for those substrings on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that for the common letters, the intermediates for a substring\n",
    "# are the same as those in a longer string.\n",
    "prompt_short = 'my mo'\n",
    "prompt_long = 'my most gr'\n",
    "\n",
    "bia_short = BlockInternalsAccessors(prompt_short, encoding_helpers, accessors)\n",
    "bia_long = BlockInternalsAccessors(prompt_long, encoding_helpers, accessors)\n",
    "\n",
    "for t_i in range(len(prompt_short)):\n",
    "    for block_idx in range(n_layer):\n",
    "        test_close(\n",
    "            bia_short.proj_output(block_idx=block_idx)[0, t_i, :],\n",
    "            bia_long.proj_output(block_idx=block_idx)[0, t_i, :],\n",
    "        )\n",
    "        test_close(\n",
    "            bia_short.ffwd_output(block_idx=block_idx)[0, t_i, :],\n",
    "            bia_long.ffwd_output(block_idx=block_idx)[0, t_i, :],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It passes, so this shows we can use the values at the other t_i's from the slen10 dataset. Let's try it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_slen=10\n",
    "target_exp = exps[full_slen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_similar_strings2(\n",
    "    prompt: str,\n",
    "    block_idx: int,\n",
    "    compare_to_slen: int,\n",
    "):\n",
    "    \"\"\"Same as compare_similar_strings() above but just uses a single experiment.\"\"\"\n",
    "    prompt_accessors = BlockInternalsAccessors(prompt, encoding_helpers, accessors)\n",
    "\n",
    "    # indexing `compare_to_slen - 1` below because slicers2 is indexed\n",
    "    # by t_i, not string length\n",
    "    sim_strings_comp, distances_comp = target_exp.strings_with_topk_closest_proj_outputs(\n",
    "        block_idx=block_idx,\n",
    "        t_i=compare_to_slen - 1,\n",
    "        queries=prompt_accessors.proj_output(block_idx=block_idx)[:, -1, :],\n",
    "        k=10,\n",
    "        largest=False,\n",
    "    )\n",
    "\n",
    "    sim_strings, distances = exps[len(prompt)].strings_with_topk_closest_proj_outputs(\n",
    "        block_idx=block_idx,\n",
    "        t_i=-1,\n",
    "        queries=prompt_accessors.proj_output(block_idx=block_idx)[:, -1, :],\n",
    "        k=10,\n",
    "        largest=False,\n",
    "    )\n",
    "\n",
    "    print(f\"Length {compare_to_slen} similars:   Length {len(prompt)} similars:\")\n",
    "    for i in range(10):\n",
    "        print(f'{repr(sim_strings_comp[0][i][:compare_to_slen])} {distances_comp[i].item():.3f}        {repr(sim_strings[0][i])} {distances[i].item():.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 5 similars:   Length 10 similars:\n",
      "'my mo' 4.464        'my most gr' 0.000\n",
      "'my st' 4.917        'my most st' 3.911\n",
      "'my br' 4.969        'my most sa' 4.328\n",
      "'my tr' 4.977        ' my most r' 4.556\n",
      "'my gr' 5.039        ' my most l' 5.160\n",
      "'my sw' 5.115        'my high bl' 5.198\n",
      "'my sc' 5.132        'm thy moth' 5.221\n",
      "'my wr' 5.140        'mt my mast' 5.225\n",
      "'my bl' 5.215        'my most he' 5.338\n",
      "'my tw' 5.267        'my merry m' 5.445\n"
     ]
    }
   ],
   "source": [
    "prompt = 'my most gr'\n",
    "compare_similar_strings2(prompt, block_idx=5, compare_to_slen=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is the same as the output above when we compared to a length 5 experiment's outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can do it for other lengths without having to run experiments for all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 9 similars:   Length 10 similars:\n",
      "'my most r' 2.754        'my most gr' 0.000\n",
      "'my most l' 3.517        'my most st' 3.911\n",
      "'my most h' 3.795        'my most sa' 4.328\n",
      "'m my mout' 4.802        ' my most r' 4.556\n",
      "'m thy mot' 4.808        ' my most l' 5.160\n",
      "'m, my mot' 4.832        'my high bl' 5.198\n",
      "'y most gr' 4.976        'm thy moth' 5.221\n",
      "'my most g' 5.051        'mt my mast' 5.225\n",
      "'mes my br' 5.177        'my most he' 5.338\n",
      "'m my moth' 5.252        'my merry m' 5.445\n"
     ]
    }
   ],
   "source": [
    "prompt = 'my most gr'\n",
    "compare_similar_strings2(prompt, block_idx=5, compare_to_slen=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out loading with mmap_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'my most gr'\n",
    "prompt_accessors = BlockInternalsAccessors(prompt, encoding_helpers, accessors)\n",
    "query = prompt_accessors.proj_output(block_idx=0)[:, -1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time loading a full batch from slen10 the regular way and subtracting the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.4 ms  348 s per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch = torch.load(exps[10].output_dir / 'proj_output-000-00.pt')\n",
    "batch - query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load with `mmap=True` and try again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 ms  56.3 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch = torch.load(str(exps[10].output_dir / 'proj_output-000-00.pt'), mmap=True)\n",
    "batch - query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, it's way faster. Let's see if we can load multiple batches, cat them and do the subtraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.1 ms  637 s per loop (mean  std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "batch1 = torch.load(str(exps[10].output_dir / 'proj_output-000-00.pt'), mmap=True)\n",
    "batch2 = torch.load(str(exps[10].output_dir / 'proj_output-001-00.pt'), mmap=True)\n",
    "batch3 = torch.load(str(exps[10].output_dir / 'proj_output-002-00.pt'), mmap=True)\n",
    "\n",
    "big_batch = torch.cat([batch1, batch2, batch3])\n",
    "big_batch - query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. OK, this is a big deal. We did 3 batches in 51ms vs 28.ms for just one batch in the regular way. And I suspect this scales non-linearly. Let's try it with all the batches:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.88 s  294 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "big_batch = torch.cat([\n",
    "    torch.load(str(exps[10]._proj_output_filename(batch_idx=batch_idx, block_idx=0)), mmap=True)\n",
    "    for batch_idx in range(exps[10].n_batches)\n",
    "])\n",
    "big_batch - query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 8.88s for 86 batches. Memory usage peaked at 25GB during the run but went up and down and settled back down to where it was before the run started. \n",
    "\n",
    "But that's 103ms per batch which seems slower than just loading each batch one at a time. But the computation is simpler (no need for `topk_across_batches()` etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try running through all the batches the old way (no mmap) and time it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32 s  157 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for batch_idx in range(exps[10].n_batches):\n",
    "    batch = torch.load(str(exps[10]._proj_output_filename(batch_idx=batch_idx, block_idx=0))) # no mmap\n",
    "    batch - query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is actually faster. But let's try to do more of the complete operation and do multiple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompts and extract the query values\n",
    "prompts = ['First Citi', 'Citizen:\\nB', 'Shyamalan ', 'more in jo']\n",
    "prompts_exp = BlockInternalsExperiment(encoding_helpers, accessors, prompts)\n",
    "\n",
    "t_i = -1\n",
    "\n",
    "queries = prompts_exp.proj_output(block_idx=0)[:, t_i, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time doing the equivalent of strings_with_topk_closest_ffwd_outputs() on the mmaped data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.51 s  395 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "big_batch = torch.cat([\n",
    "    torch.load(str(exps[10]._proj_output_filename(batch_idx=batch_idx, block_idx=0)), mmap=True)\n",
    "    for batch_idx in range(exps[10].n_batches)\n",
    "])\n",
    "\n",
    "n_queries, _ = queries.shape\n",
    "B, T, _ = big_batch.shape\n",
    "distances = torch.norm(\n",
    "    big_batch[:, t_i, :].reshape(B, 1, -1).expand(-1, n_queries, -1) - queries,\n",
    "    dim=2\n",
    ")\n",
    "topk = torch.topk(distances, k=10, dim=0, largest=False)\n",
    "exps[10].strings_from_indices(topk.indices), topk.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that is slow. But I suspect there is some overhead in loading the data the first time. What if we load the data once and then process the queries on the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_batch = torch.cat([\n",
    "    torch.load(str(exps[10]._proj_output_filename(batch_idx=batch_idx, block_idx=0)), mmap=True)\n",
    "    for batch_idx in range(exps[10].n_batches)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 ms  8.63 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "n_queries, _ = queries.shape\n",
    "B, T, _ = big_batch.shape\n",
    "distances = torch.norm(\n",
    "    big_batch[:, t_i, :].reshape(B, 1, -1).expand(-1, n_queries, -1) - queries,\n",
    "    dim=2\n",
    ")\n",
    "topk = torch.topk(distances, k=10, dim=0, largest=False)\n",
    "exps[10].strings_from_indices(topk.indices), topk.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare that to doing it with a slicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471 ms  3.27 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "slicers[10].strings_with_topk_closest_proj_outputs(block_idx=0, queries=queries, k=10, largest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have the required methods on the exp class anymore, but if we want to test how long this would have taken without the slicer i.e. on the same data that the mmap version is using but without using mmap, we can resurrect the relevant code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the code from block_internals, just so we can run it below\n",
    "def batch_distances(batch: torch.Tensor, queries: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Returns the distance between each item in the batch and the queries.\"\"\"\n",
    "    assert batch.dim() == 2, f\"batch.dim() should be 2, was {batch.dim()}\"\n",
    "    assert queries.dim() == 2, f\"query.dim() should be 2, was {queries.dim()}\"\n",
    "    assert (\n",
    "        batch.shape[-1] == queries.shape[-1]\n",
    "    ), f\"last dimension of batch was {batch.shape[-1]}, which does not match last dimension of queries {queries.shape[-1]}\"\n",
    "\n",
    "    B, _ = batch.shape\n",
    "    n_queries, _ = queries.shape\n",
    "\n",
    "    distances = torch.norm(\n",
    "        # Reshape the batch to a singleton dimension, then expand that dimension\n",
    "        # by the number of queries. We can then subtract all the queries in one\n",
    "        # go.\n",
    "        batch.reshape(B, 1, -1).expand(-1, n_queries, -1) - queries,\n",
    "        dim=2\n",
    "    )\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18 s  29.7 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "n_queries, _ = queries.shape\n",
    "values, indices = topk_across_batches(\n",
    "    n_batches=exps[10].n_batches,\n",
    "    k=10,\n",
    "    largest=False,\n",
    "    load_batch=lambda i: torch.load(exps[10]._proj_output_filename(i, block_idx=0))[:, t_i, :],\n",
    "    process_batch=lambda batch: batch_distances(batch, queries=queries),\n",
    ")\n",
    "exps[10].strings_from_indices(indices), values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mmap way is a faster than the slicer (303ms vs 471ms) and doesn't require materializing the slices. And it's waaaay faster than doing it without the slicer and without mmap (303ms vs 2.18s).\n",
    "\n",
    "In summary: \n",
    "It seems there is a one-time cost to loading all the batches via: \n",
    "\n",
    "```python\n",
    "big_batch = torch.cat([\n",
    "    torch.load(str(exps[10]._proj_output_filename(batch_idx=batch_idx, block_idx=0)), mmap=True)\n",
    "    for batch_idx in range(exps[10].n_batches)\n",
    "])\n",
    "```\n",
    "\n",
    "But this doesn't take up too much memory (fresh Jupyter kernel running just the stuff in this and the previous section has about 13 GB of memory per Activity Monitor). So we can load this once and run a lot of queries very fast. \n",
    "\n",
    "Let's check that the results are correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do for real so we can compare the results\n",
    "big_batch = torch.cat([\n",
    "    torch.load(str(exps[10]._proj_output_filename(batch_idx=batch_idx, block_idx=0)), mmap=True)\n",
    "    for batch_idx in range(exps[10].n_batches)\n",
    "])\n",
    "\n",
    "n_queries, _ = queries.shape\n",
    "B, T, _ = big_batch.shape\n",
    "distances = torch.norm(\n",
    "    big_batch[:, t_i, :].reshape(B, 1, -1).expand(-1, n_queries, -1) - queries,\n",
    "    dim=2\n",
    ")\n",
    "topk = torch.topk(distances, k=10, dim=0, largest=False)\n",
    "exps[10].strings_from_indices(topk.indices), topk.values\n",
    "\n",
    "sim_strings, distances = slicers[10].strings_with_topk_closest_proj_outputs(block_idx=0, queries=queries, k=10, largest=False)\n",
    "test_eq(exps[10].strings_from_indices(topk.indices), sim_strings)\n",
    "test_close(topk.values, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These test pass, so the output is the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perf tests for using mmap with the slicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis above showed that using mmap on the raw batch data is faster than using the slicer. But yesterday I found that just setting mmap=True on the load_batch function when finding closest embeddings made a huge difference. Let's try the same thing for the slicer and see if it makes a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_i = -1\n",
    "queries = prompts_exp.proj_output(block_idx=0)[:, t_i, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we have a measurement for using the slicer above, let's just replicate it for completeness. Ran this line before making any changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482 ms  14.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "slicers[10].strings_with_topk_closest_proj_outputs(block_idx=0, queries=queries, k=10, largest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that's in line with the measurement above. Now let's try it after changing the implementation to use `mmap=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 ms  8.18 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "slicers[10].strings_with_topk_closest_proj_outputs(block_idx=0, queries=queries, k=10, largest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so it got faster, but it's still not as fast as using the raw batch data with `mmap=True`. So we'll go with that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perf tests for finding closest embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp10 = BatchedBlockInternalsExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings_n[10],\n",
    "    output_dir=Path(f'../artifacts/block_internals_results/large_files/slen10/'),\n",
    "    batch_size=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measurement before any changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.49 s  9.11 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "exp10.strings_with_topk_closest_embeddings(queries=prompts_exp.embeddings, k=10, largest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate loading all the batch data at once and then finding the topk closest strings for all the queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_data = torch.cat([\n",
    "    torch.load(str(exp10._embeddings_filename(batch_idx=batch_idx)), mmap=True)\n",
    "    for batch_idx in range(exp10.n_batches)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent of topk_closest_embeddings - slow\n",
    "B, _, _ = embeddings_data.shape\n",
    "\n",
    "n_queries, _, _ = prompts_exp.embeddings.shape\n",
    "\n",
    "distances = batch_distances(\n",
    "    embeddings_data.reshape(B, -1),\n",
    "    prompts_exp.embeddings.reshape(n_queries, -1)\n",
    ")\n",
    "topk = torch.topk(distances, dim=0, k=k, largest=False)\n",
    "exp10.strings_from_indices(topk.indices), topk.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was really slow and took a ton of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the equivalent thing on the proj_out data is still fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_out_data = torch.cat([\n",
    "    torch.load(str(exp10._proj_output_filename(batch_idx=batch_idx, block_idx=0)), mmap=True)\n",
    "    for batch_idx in range(exp10.n_batches)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries, _ = queries.shape\n",
    "B, T, _ = proj_out_data.shape\n",
    "distances = torch.norm(\n",
    "    proj_out_data[:, t_i, :].reshape(B, 1, -1).expand(-1, n_queries, -1) - queries,\n",
    "    dim=2\n",
    ")\n",
    "topk = torch.topk(distances, k=10, dim=0, largest=False)\n",
    "exp10.strings_from_indices(topk.indices), topk.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes it is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suspecting the issue is the reshape needed. Show that we can calculate the norm we want without the reshape. \n",
    "\n",
    "What the reshape does is stack the embeddings across the T dimension. We have embeddings\n",
    "\n",
    "$$\n",
    "e_1, e_2, \\ldots, e_T \\in \\mathbb{R}^{n\\_embed}\n",
    "$$\n",
    "\n",
    "By stacking them, we get one big embedding:\n",
    "\n",
    "$$\n",
    "e_{1:T} \\in \\mathbb{R}^{T * n\\_embed}\n",
    "$$\n",
    "\n",
    "We do the same with the queries:\n",
    "\n",
    "$$\n",
    "q_1, q_2, \\ldots, q_T \\in \\mathbb{R}^{n\\_embed} \\rightarrow\n",
    "q_{1:T} \\in \\mathbb{R}^{T * n\\_embed}\n",
    "$$\n",
    "\n",
    "We then want to compute\n",
    "\n",
    "$$\n",
    "\\Vert e_{1:T} - q_{1:T} \\Vert_2 = \\sqrt{\\sum_{i=1}^{T * n\\_embed} (e_{1:T} - q_{1:T})_i^2}\n",
    "$$\n",
    "\n",
    "Can we get to this if we only have $e_1, e_2, \\ldots, e_T$ and $q_1, q_2, \\ldots, q_T$? Yes, we can.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Vert e_{1:T} - q_{1:T} \\Vert_2 &= \\sqrt{\\sum_{i=1}^{T * n\\_embed} (e_{1:T} - q_{1:T})_i^2} \\\\\n",
    "\\Vert e_{1:T} - q_{1:T} \\Vert_2^2 &= \\sum_{i=1}^{T * n\\_embed} (e_{1:T} - q_{1:T})_i^2 \\\\\n",
    "&=\\sum_{i=1}^{n\\_embed}(e_{1:T} - q_{1:T})_i^2 + \\sum_{i=n\\_embed+1}^{2*n\\_embed}(e_{1:T} - q_{1:T})_i^2 + \\ldots + \\sum_{i=(T-1)*n\\_embed+1}^{T*n\\_embed}(e_{1:T} - q_{1:T})_i^2 \\\\\n",
    "&=\\sum_{i=1}^{n\\_embed}(e_{1} - q_{1})_i^2 + \\sum_{i=1}^{n\\_embed}(e_{2} - q_{2})_i^2 + \\ldots + \\sum_{i=1}^{n\\_embed}(e_{T} - q_{T})_i^2 \\\\\n",
    "&=\\Vert e_1 - q_1 \\Vert_2^2 + \\Vert e_2 - q_2 \\Vert_2^2 + \\ldots + \\Vert e_T - q_T \\Vert_2^2 \\\\\n",
    "&=\\sum_{i=1}^{T}\\Vert e_i - q_i \\Vert_2^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Vert e_{1:T} - q_{1:T} \\Vert_2 &= \\sqrt{\\sum_{i=1}^{T}\\Vert e_i - q_i \\Vert_2^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let's check it in code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show that we can effectively compute the norm without reshaping\n",
    "x = torch.randn((100, 5, 384))\n",
    "B, T, _ = x.shape\n",
    "q = torch.randn(5, 384)\n",
    "\n",
    "norm1 = torch.norm(x.reshape(B, -1) - q.reshape(-1), dim=-1)\n",
    "norm2 = (torch.norm(x - q, dim=-1) ** 2).sum(dim=-1).sqrt()\n",
    "test_close(norm1, norm2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do it with the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Version without reshaping\n",
    "B, _, _ = embeddings_data.shape\n",
    "\n",
    "n_queries, _, _ = prompts_exp.embeddings.shape\n",
    "\n",
    "distances = (\n",
    "    torch.norm(embeddings_data.unsqueeze(dim=1).expand(-1, n_queries, -1, -1) - prompts_exp.embeddings, dim=-1) ** 2\n",
    ").sum(dim=-1).sqrt()\n",
    "\n",
    "topk = torch.topk(distances, dim=0, k=10, largest=False)\n",
    "exp10.strings_from_indices(topk.indices), topk.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above used so much memory that it crashed the kernel. So this is a no go. I think the fundamental problem is we're computing over a lot more data: all elements of the T dimension vs just one with the proj_outputs/ffwd_outputs. So let's go back to the original way of doing it in batches, but let's see if it helps to load \"super batches\" by combining several of the batches on disk into one batch in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for creating super batches\n",
    "\n",
    "k=10\n",
    "largest=False\n",
    "combine_n_batches = 5\n",
    "\n",
    "batch_size = exp10.batch_size * combine_n_batches\n",
    "n_batches = math.ceil(len(exp10.strings) / batch_size)\n",
    "queries = prompts_exp.embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.19 s  35.9 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "def _load_batch(batch_idx: int):\n",
    "    start = batch_idx * combine_n_batches\n",
    "    end = min((batch_idx + 1) * combine_n_batches, exp10.n_batches)\n",
    "\n",
    "    batch = torch.cat([\n",
    "        torch.load(\n",
    "            str(exp10._embeddings_filename(batch_idx=i)),\n",
    "            mmap=True,\n",
    "        )\n",
    "        for i in range(start, end)\n",
    "    ])\n",
    "    return batch\n",
    "\n",
    "n_queries, _, _ = queries.shape\n",
    "\n",
    "def _process_batch(batch: torch.Tensor) -> torch.Tensor:\n",
    "    B, _, _ = batch.shape\n",
    "    # Batch and queries and both shape (B, s_len, n_embed).\n",
    "    # For the purposes of finding the closest values, we\n",
    "    # reshape both the batch and queries to eliminate the\n",
    "    # s_len dimension, effectively concatenating all the\n",
    "    # embedding tensors across positions.\n",
    "    return batch_distances(batch.reshape(B, -1), queries.reshape(n_queries, -1))\n",
    "\n",
    "values, indices = topk_across_batches(\n",
    "    n_batches=n_batches,\n",
    "    k=k,\n",
    "    largest=largest,\n",
    "    load_batch=_load_batch,\n",
    "    process_batch=_process_batch,\n",
    ")\n",
    "\n",
    "exp10.strings_from_indices(indices), values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helps only a tiny amount. And it seems to get faster the fewer number of batches we combine. So let's just do it with one batch at a time. I added code to load the one batch in the existing implementation with mmap=True and timed it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.34 s  46.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "exp10.strings_with_topk_closest_embeddings(queries=prompts_exp.embeddings, k=10, largest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best result so far so we'll go with this. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
