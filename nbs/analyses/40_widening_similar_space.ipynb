{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widening the Space of Similar Values\n",
    "\n",
    "> A major finding was that the current approaches are considering values that are too similar. This notebook investigates ways to search a wider space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Iterable, Protocol, Sequence, Tuple, TypeVar, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "import math\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import tempfile\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from transformer_experiments.common.substring_generator import all_unique_substrings\n",
    "from transformer_experiments.common.text_analysis import (\n",
    "    build_next_token_map,\n",
    "    SubstringFrequencyAnalysis,\n",
    "    top_nonzero_tokens\n",
    ")\n",
    "from transformer_experiments.common.utils import (\n",
    "    aggregate_by_string_key,\n",
    "    DataWrapper,\n",
    "    topk_across_batches,\n",
    ")\n",
    "from transformer_experiments.dataset_split import split_text_dataset\n",
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import (\n",
    "    n_embed,\n",
    "    n_layer,\n",
    "    TransformerLanguageModel\n",
    ")\n",
    "from transformer_experiments.models.transformer_helpers import (\n",
    "    unsqueeze_emb,\n",
    "    EncodingHelpers,\n",
    "    LogitsWrapper,\n",
    "    TransformerAccessors\n",
    ")\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer\n",
    ")\n",
    "from transformer_experiments.training_utils import CheckPointer\n",
    "from transformer_experiments.experiments.block_internals import (\n",
    "    BlockInternalsAccessors,\n",
    "    BlockInternalsExperiment,\n",
    "    BatchedBlockInternalsExperiment,\n",
    "    BlockInternalsAnalysis,\n",
    "    batch_cosine_sim,\n",
    ")\n",
    "from transformer_experiments.experiments.final_ffwd import FinalFFWDExperiment\n",
    "from transformer_experiments.experiments.similar_strings import (\n",
    "    SimilarStringsData,\n",
    "    SimilarStringsExperiment,\n",
    "    SimilarStringsResult\n",
    ")\n",
    "from transformer_experiments.experiments.logit_lens import LogitLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ts = TinyShakespeareDataSet(cache_file='../artifacts/input.txt')\n",
    "m, tokenizer = create_model_and_tokenizer(\n",
    "    saved_model_filename='../artifacts/shakespeare.pt',\n",
    "    dataset=ts,\n",
    "    device=device,\n",
    ")\n",
    "_, val_data = split_text_dataset(ts.text, tokenizer, train_pct=0.9, device=device)\n",
    "encoding_helpers = EncodingHelpers(tokenizer, device)\n",
    "accessors = TransformerAccessors(m, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list(Path('../artifacts/block_internals_results/large_files/slen10/').glob('*')) == []:\n",
    "    print(\"Run `make block_internals_slen10_dataset` in the project root to generate the required dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings10 = all_unique_substrings(ts.text, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp10 = BatchedBlockInternalsExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings10,\n",
    "    output_dir=Path('../artifacts/block_internals_results/large_files/slen10/'),\n",
    "    batch_size=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "n_samples = 20000\n",
    "indices = torch.randperm(len(strings10))[:n_samples]\n",
    "strings20k = [strings10[i.item()] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of 500 strings\n",
    "sample_size = 500\n",
    "strings_sample = strings20k[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this in a common component\n",
    "def get_model_outputs(prompts: Sequence[str], encoding_helpers: EncodingHelpers):\n",
    "    # Compute the model's predictions:\n",
    "    tokens = encoding_helpers.tokenize_strings(prompts)\n",
    "    logits, _ = m(tokens)\n",
    "\n",
    "    logits = LogitsWrapper(logits, encoding_helpers.tokenizer)\n",
    "    return [topk_tokens[-1] for topk_tokens in logits.topk_tokens(k=10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs_sample = get_model_outputs(strings_sample, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_exp = BlockInternalsExperiment(encoding_helpers, accessors, strings_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by examining what we get when we ask for a much larger top k values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sims, emb_distances = exp10.strings_with_topk_closest_embeddings(\n",
    "    prompts_exp.embeddings[:5, :, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9062, 0.9470, 0.9045, 0.9493, 0.9544],\n",
       "         [0.9062, 0.9462, 0.8602, 0.9083, 0.9443],\n",
       "         [0.9053, 0.9429, 0.8593, 0.9082, 0.9064],\n",
       "         [0.9037, 0.9429, 0.8586, 0.9055, 0.9057],\n",
       "         [0.9027, 0.9404, 0.8566, 0.9052, 0.9045],\n",
       "         [0.9020, 0.9027, 0.8562, 0.9044, 0.8996],\n",
       "         [0.9017, 0.9009, 0.8548, 0.9035, 0.8982],\n",
       "         [0.8962, 0.9009, 0.8545, 0.9034, 0.8656],\n",
       "         [0.8651, 0.9008, 0.8532, 0.9032, 0.8631]]),\n",
       " tensor([[0.7591, 0.7566, 0.7604, 0.8064, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7604, 0.8063, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7603, 0.8063, 0.8042],\n",
       "         [0.7590, 0.7564, 0.7602, 0.8063, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8062, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8061, 0.8040],\n",
       "         [0.7588, 0.7557, 0.7601, 0.8061, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7600, 0.8060, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8038],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8037]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_distances[:10, :], emb_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'is dream o'   'My present'   's eye, mak'   'eart of mo'   ' men, as I'\n",
      "'ur dreams,'   'be present'   's eyes in '   'earn of hi'   ' man, as y'\n",
      "'of dreams,'   'dy present'   'l eyes can'   'ears of ha'   ' man, if I'\n",
      "'us dreams.'   'my present'   's eyes to '   'park of ho'   'oman, as t'\n",
      "'he dreams,'   'ry present'   'l eyes gaz'   'eart of ge'   ' men, as i'\n",
      "'ly dreams,'   'y, present'   'r foes may'   'eard of hi'   ' many as y'\n",
      "'en dreams,'   'on present'   'r ever may'   'east of yo'   'cian, as I'\n",
      "'nd dreams,'   't, present'   's eyes do '   'part of hi'   ' son, as t'\n",
      "'as dream\\nS'   'in present'   's eye; tal'   'earn of yo'   ' long as I'\n",
      "\n",
      "'is presenc'   ' a prisone'   'g over mas'   'efit of se'   ' man: we s'\n",
      "'is prowess'   'ot prone t'   'l even tak'   'wist of ro'   ' wind as s'\n",
      "'is be all,'   'is project'   't so I may'   'e is of so'   ' man; all '\n",
      "'is the mad'   'my person.'   'n thou may'   'gent of hi'   ' man, they'\n",
      "\"'s great s\"   'ay prove.\\n'   'rosper may'   'ture of hu'   'tion, as f'\n",
      "'is deed do'   'by herself'   'e that may'   'ents of so'   ' her, as w'\n",
      "'is present'   'or prisone'   'speaks my '   'eral of yo'   ' maid is m'\n",
      "'rs dry; sc'   'be broken:'   'o not, may'   'mark of ot'   \" man, 'tis\"\n",
      "'ish reason'   'ay prove p'   'ounsel may'   'ents of yo'   ':\\nNo, as I'\n",
      "'py drinks,'   'ng prisone'   'n pity may'   'e is of go'   'sland as a'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "proj_sims, proj_distances = exp10.strings_with_topk_closest_proj_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.proj_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9948, 0.9967, 0.9947, 0.9974, 0.9956],\n",
       "         [0.9942, 0.9967, 0.9945, 0.9960, 0.9933],\n",
       "         [0.9937, 0.9964, 0.9921, 0.9958, 0.9897],\n",
       "         [0.9935, 0.9963, 0.9917, 0.9957, 0.9896],\n",
       "         [0.9928, 0.9962, 0.9910, 0.9956, 0.9871],\n",
       "         [0.9922, 0.9950, 0.9905, 0.9955, 0.9857],\n",
       "         [0.9911, 0.9944, 0.9900, 0.9954, 0.9856],\n",
       "         [0.9897, 0.9942, 0.9895, 0.9950, 0.9850],\n",
       "         [0.9891, 0.9939, 0.9894, 0.9943, 0.9846]]),\n",
       " tensor([[0.9709, 0.9826, 0.9796, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9825, 0.9795, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9824, 0.9794, 0.9854, 0.9726],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9823, 0.9793, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9853, 0.9724],\n",
       "         [0.9707, 0.9823, 0.9791, 0.9853, 0.9723],\n",
       "         [0.9707, 0.9823, 0.9790, 0.9853, 0.9723]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_distances[:10, :], proj_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'ly dreams,'   'my present'   'e case may'   'ster of ho'   ' men, as I'\n",
      "'en dreams,'   'dy present'   ' sense may'   'ffer to ha'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'ied as may'   'ruth of ho'   ' not, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'otes of ho'   'o me, as I'\n",
      "'nd dreams,'   'My present'   'r foes may'   'anes of ho'   'nd I, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'oint of ho'   'cian, as I'\n",
      "'of dreams,'   'in present'   ' haste may'   'yers of ho'   'I am, as t'\n",
      "\"n's beams,\"   'is present'   'odesty may'   'ains of ho'   '-day, as I'\n",
      "'hese arms,'   'im present'   'esence may'   'ound of ho'   '\\nAnd, as I'\n",
      "\n",
      "'sires most'   'ast ungent'   \"'s some am\"   'lf with ho'   ' be, was l'\n",
      "'teous mass'   'What scene'   'e they mad'   'tell of hi'   'Look, as I'\n",
      "'m to kiss,'   'lest scent'   ' am to say'   'Thus to ha'   'wick, as o'\n",
      "'much amiss'   'ondon sent'   ' early mad'   's of a tho'   'aith, as y'\n",
      "'wings misd'   'ng presenc'   'If you may'   'ven for ha'   'ut I was a'\n",
      "'from himse'   ' this sent'   'es the mai'   ' of our ho'   'y, is as a'\n",
      "'isdom hast'   'viest cens'   'et him say'   'tars of he'   'early as m'\n",
      "'hat seems '   'ou dissent'   'lords, may'   's other ho'   ' Yet, as t'\n",
      "'er bosoms!'   'tion spend'   'o them say'   'now the ho'   ' duke as I'\n",
      "' so, himse'   'have spent'   'nd now may'   'keep at ho'   's low as t'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "ffwd_sims, ffwd_distances = exp10.strings_with_topk_closest_ffwd_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.ffwd_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9998, 0.9999, 0.9997, 0.9998, 0.9999],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9995, 0.9998, 0.9997],\n",
       "         [0.9997, 0.9998, 0.9995, 0.9998, 0.9996],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994]]),\n",
       " tensor([[0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_distances[:10, :], ffwd_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'en dreams,'   'my present'   ' sense may'   'ster of ho'   ' men, as I'\n",
      "'ly dreams,'   'dy present'   'e case may'   'otes of ho'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'r foes may'   'anes of ho'   ' not, as I'\n",
      "'nd dreams,'   'My present'   'ied as may'   'ains of ho'   'o me, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'oint of ho'   'nd I, as I'\n",
      "'of dreams,'   'y, present'   ' bones may'   'ound of ho'   '-day, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'fear to ho'   ' but, as I'\n",
      "'rate arms,'   'im present'   ' grace may'   'ally of ho'   'rd me as I'\n",
      "'hese arms,'   'in present'   'e more may'   'yers of ho'   '\\nYes, as I'\n",
      "\n",
      "'ck groans,'   'll\\nPresent'   'en you say'   'ace our ho'   'r sakes, I'\n",
      "'te builds,'   's innocent'   'Hope I may'   'he that ho'   'early as I'\n",
      "'she finds,'   'me Florent'   'e must say'   'Half an ho'   'nes, and I'\n",
      "'reat loss,'   'their gent'   'n thou may'   'as mine ho'   'fe,--\\nAs I'\n",
      "'ld cramps,'   ', insolent'   'ctions may'   'When it ho'   ' see it, I'\n",
      "'he bleeds,'   'say I\\nsent'   'How he may'   '\\nIf so tho'   'ess woe, I'\n",
      "'our cross,'   'fore, gent'   'ame,\\nI say'   'us, the ho'   ' he does I'\n",
      "'han tears,'   'ldness ent'   'no way say'   'ale and ho'   'mad,--as I'\n",
      "'hese wars,'   'ch garment'   'e now, say'   'out any ho'   ' way can I'\n",
      "'to adders,'   'ic garment'   'ple,\\nI may'   'here\\nat ho'   'rant, an I'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the 500 Sample Strings, Can we Calculate Cosine Similarity to Every Other String?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilaritiesExperiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp: BatchedBlockInternalsExperiment,\n",
    "        output_folder: Path,\n",
    "    ):\n",
    "        self.exp = exp\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        self.n_batches = exp.n_batches\n",
    "\n",
    "    def embedding_sims_filename(self, batch_idx: int):\n",
    "        return self.output_folder / f'embedding_sims_{batch_idx:03d}.pt'\n",
    "\n",
    "    def proj_out_sims_filename(self, batch_idx: int, block_idx: int):\n",
    "        return self.output_folder / f'proj_out_sims_{batch_idx:03d}_{block_idx:02d}.pt'\n",
    "\n",
    "    def ffwd_out_sims_filename(self, batch_idx: int, block_idx: int):\n",
    "        return self.output_folder / f'ffwds_out_sims_{batch_idx:03d}_{block_idx:02d}.pt'\n",
    "\n",
    "    def generate_embedding_sims(self, chunk_size: int, queries: torch.Tensor, disable_progress_bar: bool = False):\n",
    "        n_chunks = exp10.batch_size // chunk_size\n",
    "\n",
    "        assert queries.dim() == 2\n",
    "        n_queries = queries.shape[0]\n",
    "\n",
    "        def sims_for_chunk(emb_batch: torch.Tensor, chunk_idx: int):\n",
    "            chunk = emb_batch[chunk_idx*chunk_size:(chunk_idx+1)*chunk_size, :, :]\n",
    "            actual_chunk_size = chunk.shape[0]\n",
    "            return F.cosine_similarity(\n",
    "                chunk.reshape(actual_chunk_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                queries,\n",
    "                dim=-1\n",
    "            )\n",
    "\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            emb_batch = torch.load(str(self.exp._embeddings_filename(batch_idx=batch_idx)), mmap=True)\n",
    "            sims = torch.cat([\n",
    "                sims_for_chunk(emb_batch, i)\n",
    "                for i in range(n_chunks)\n",
    "            ], dim=0)\n",
    "            torch.save(sims, str(self.embedding_sims_filename(batch_idx=batch_idx)))\n",
    "\n",
    "    def generate_proj_out_sims(self, get_queries: Callable[[int], torch.Tensor], disable_progress_bar=False):\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            for block_idx in range(n_layer):\n",
    "                queries = get_queries(block_idx)\n",
    "\n",
    "                assert queries.dim() == 2\n",
    "                n_queries = queries.shape[0]\n",
    "\n",
    "                proj_out_batch = torch.load(str(self.exp._proj_output_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True)\n",
    "                batch_size = proj_out_batch.shape[0]\n",
    "                sims = F.cosine_similarity(\n",
    "                    proj_out_batch[:, -1, :].reshape(batch_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                    queries,\n",
    "                    dim=-1\n",
    "                )\n",
    "                torch.save(sims, str(self.proj_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)))\n",
    "\n",
    "    def generate_ffwd_out_sims(self, get_queries: Callable[[int], torch.Tensor], disable_progress_bar=False):\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            for block_idx in range(n_layer):\n",
    "                queries = get_queries(block_idx)\n",
    "                assert queries.dim() == 2\n",
    "                n_queries = queries.shape[0]\n",
    "\n",
    "                ffwd_out_batch = torch.load(str(self.exp._ffwd_output_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True)\n",
    "                batch_size = ffwd_out_batch.shape[0]\n",
    "                sims = F.cosine_similarity(\n",
    "                    ffwd_out_batch[:, -1, :].reshape(batch_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                    queries,\n",
    "                    dim=-1\n",
    "                )\n",
    "                torch.save(sims, str(self.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by doing some analysis on the first 500 strings.\n",
    "output_folder = exp10.output_dir / 'cosine_sims_000'\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp = CosineSimilaritiesExperiment(exp10, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp.generate_embedding_sims(chunk_size=2000, queries=prompts_exp.embeddings.reshape(sample_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp.generate_proj_out_sims(get_queries=lambda block_idx: prompts_exp.proj_output(block_idx=block_idx)[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp.generate_ffwd_out_sims(get_queries=lambda block_idx: prompts_exp.ffwd_output(block_idx=block_idx)[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e389da6335b43e2be61cffe53728391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now generate cosine sims for ffwd output for the remaining 15000 strings\n",
    "n_all_strings = 20000\n",
    "sample_size = 500\n",
    "n_chunks = math.ceil(n_all_strings / sample_size)\n",
    "\n",
    "for sample_idx in tqdm(range(0, n_chunks)):\n",
    "    start_idx = sample_idx * sample_size\n",
    "    end_idx = min(start_idx + sample_size, n_all_strings)\n",
    "\n",
    "    # Create a sample of 500 strings\n",
    "    strings = strings20k[start_idx:end_idx]\n",
    "\n",
    "    output_folder = exp10.output_dir / f'cosine_sims_{sample_idx:03d}'\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    exp = CosineSimilaritiesExperiment(exp10, output_folder)\n",
    "\n",
    "    sample_prompts_exp = BlockInternalsExperiment(encoding_helpers, accessors, strings)\n",
    "\n",
    "    exp.generate_ffwd_out_sims(\n",
    "        get_queries=lambda block_idx: sample_prompts_exp.ffwd_output(block_idx=block_idx)[:, -1, :],\n",
    "        disable_progress_bar=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation crashed somewhere during sample_idx 26. We'll have to try again to generate the rest but today we'll work with what we have. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, collect some stats about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_across_batches(\n",
    "    get_batch: Callable[[int], torch.Tensor],\n",
    "    n_batches: int,\n",
    "    n_queries: int,\n",
    "):\n",
    "    mins = torch.zeros(n_queries)\n",
    "    maxs = torch.zeros(n_queries)\n",
    "    means = torch.zeros(n_queries)\n",
    "    s = torch.zeros(n_queries)\n",
    "\n",
    "    total_count = 0\n",
    "    for i in range(n_batches):\n",
    "        batch = get_batch(i)\n",
    "        batch_size, n_queries_batch = batch.shape\n",
    "        assert n_queries_batch == n_queries\n",
    "\n",
    "        mins = torch.minimum(mins, batch.min(dim=0).values)\n",
    "        maxs = torch.maximum(maxs, batch.max(dim=0).values)\n",
    "\n",
    "        # Implement Chan, Golub, and LeVeque method\n",
    "        total_count += batch_size\n",
    "        delta = batch.mean(dim=0) - means\n",
    "        means += delta * batch_size / total_count\n",
    "        s += batch.var(dim=0) * (batch_size - 1) + delta**2 * batch_size * (total_count - batch_size) / total_count\n",
    "\n",
    "    vars = s / (total_count - 1)\n",
    "    stds = torch.sqrt(vars)\n",
    "    return mins, maxs, means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd_mins, ffwd_maxs, ffwd_means, ffwd_stds = zip(*[\n",
    "    stats_across_batches(\n",
    "        get_batch=lambda i: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=i, block_idx=block_idx))),\n",
    "        n_batches=cos_exp.n_batches,\n",
    "        n_queries=sample_size,\n",
    "    )\n",
    "    for block_idx in range(n_layer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 0: ffwd_out mean: 0.801 ± 0.092\n",
      "Block 1: ffwd_out mean: 0.365 ± 0.042\n",
      "Block 2: ffwd_out mean: 0.160 ± 0.033\n",
      "Block 3: ffwd_out mean: 0.072 ± 0.036\n",
      "Block 4: ffwd_out mean: 0.088 ± 0.059\n",
      "Block 5: ffwd_out mean: 0.133 ± 0.091\n"
     ]
    }
   ],
   "source": [
    "for block_idx in range(n_layer):\n",
    "    print(f\"Block {block_idx}: ffwd_out mean: {ffwd_means[block_idx].mean():.3f} ± {ffwd_means[block_idx].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_across_batches(\n",
    "    get_batch: Callable[[int], torch.Tensor],\n",
    "    n_batches: int,\n",
    "    filter_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    n_queries: int,\n",
    "):\n",
    "    total_count = 0\n",
    "    matching_indices = [[] for _ in range(n_queries)]\n",
    "    for i in range(n_batches):\n",
    "        batch = get_batch(i)\n",
    "        batch_size, n_queries_batch = batch.shape\n",
    "        assert n_queries_batch == n_queries\n",
    "\n",
    "        filtered = filter_fn(batch)\n",
    "        nonzeros = torch.nonzero(filtered)\n",
    "        for i in range(nonzeros.shape[0]):\n",
    "            idx_in_batch, query_idx = nonzeros[i, :]\n",
    "            matching_indices[query_idx.item()].append(total_count + idx_in_batch.item())\n",
    "\n",
    "        total_count += batch_size\n",
    "\n",
    "    return matching_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for filter_across_batches()\n",
    "\n",
    "batches = [\n",
    "    torch.tensor([\n",
    "        [0.0, 0.6, 0.4, 0.3],\n",
    "        [0.1, 0.3, 0.5, 0.1],\n",
    "        [0.0, 0.1, 0.8, 0.0],\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [0.7, 0.2, 0.6, 0.3],\n",
    "        [0.1, 0.8, 0.2, 0.8],\n",
    "    ]),\n",
    "]\n",
    "\n",
    "result = filter_across_batches(\n",
    "    get_batch=lambda i: batches[i],\n",
    "    n_batches=len(batches),\n",
    "    filter_fn=lambda batch: batch > 0.5,\n",
    "    n_queries=4,\n",
    ")\n",
    "test_eq(result, [\n",
    "    [3,],\n",
    "    [0, 4],\n",
    "    [2, 3],\n",
    "    [4],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_result_stats(\n",
    "    filter_results: List[List[int]],\n",
    "):\n",
    "    lens = [len(result) for result in filter_results]\n",
    "    return {\n",
    "        'min': min(lens),\n",
    "        'max': max(lens),\n",
    "        'mean': np.mean(lens),\n",
    "        'std': np.std(lens),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_strings(\n",
    "    filter_result: List[List[int]],\n",
    "    strings: Sequence[str],\n",
    "):\n",
    "    return [\n",
    "        [\n",
    "            strings[j]\n",
    "            for j in filter_result[i]\n",
    "        ]\n",
    "        for i in range(len(filter_result))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_map10 = build_next_token_map(ts.text, 10, tokenizer.vocab_size, tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this in a common component\n",
    "def analyze_simulate_results(sim_freqs, model_outputs):\n",
    "    assert len(sim_freqs) == len(model_outputs)\n",
    "    topn_matches = [0 for _ in range(10)]\n",
    "    topn_matches_any_order = [0 for _ in range(10)]\n",
    "    for i, sim_freq in enumerate(sim_freqs):\n",
    "        sim_output = top_nonzero_tokens(sim_freq, encoding_helpers.tokenizer.itos)[:10]\n",
    "        model_output = model_outputs[i]\n",
    "\n",
    "        sim_tokens, _ = zip(*sim_output)\n",
    "        model_tokens, _ = zip(*model_output)\n",
    "\n",
    "        n = min(len(sim_tokens), len(model_tokens))\n",
    "        for j in range(n):\n",
    "            if sim_tokens[j] == model_tokens[j]:\n",
    "                topn_matches[j] += 1\n",
    "            if set(sim_tokens[:j+1]) == set(model_tokens[:j+1]):\n",
    "                topn_matches_any_order[j] += 1\n",
    "\n",
    "    return topn_matches, topn_matches_any_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(\n",
    "    get_batch: Callable[[int], torch.Tensor],\n",
    "    n_batches: int,\n",
    "    filter_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    n_queries: int,\n",
    "    all_strings: Sequence[str],\n",
    "    next_token_map: Dict[str, torch.Tensor],\n",
    "    model_outputs: Sequence[Sequence[Tuple[str, float]]],\n",
    "):\n",
    "    filter_results = filter_across_batches(\n",
    "        get_batch=get_batch,\n",
    "        n_batches=n_batches,\n",
    "        filter_fn=filter_fn,\n",
    "        n_queries=n_queries,\n",
    "    )\n",
    "\n",
    "    print(filter_result_stats(filter_results))\n",
    "\n",
    "    filter_results_strings = get_matching_strings(filter_results, all_strings)\n",
    "    filter_result_freqs = [\n",
    "        torch.stack([\n",
    "            next_token_map[matching_string]\n",
    "            for matching_string in matching_strings\n",
    "        ]).sum(dim=0)\n",
    "        for matching_strings in filter_results_strings\n",
    "    ]\n",
    "\n",
    "    filter_result_probs = [\n",
    "        freqs / freqs.sum()\n",
    "        for freqs in filter_result_freqs\n",
    "    ]\n",
    "\n",
    "    topn_matches, topn_matches_any_order = analyze_simulate_results(filter_result_probs, model_outputs)\n",
    "    for i in range(10):\n",
    "        print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "        print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")\n",
    "\n",
    "    return filter_result_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 16224, 'mean': 922.742, 'std': 2399.3301297312128}\n",
      "Top 1 matches: 0.786\n",
      "Top 1 matches (any order): 0.786\n",
      "Top 2 matches: 0.404\n",
      "Top 2 matches (any order): 0.440\n",
      "Top 3 matches: 0.236\n",
      "Top 3 matches (any order): 0.306\n",
      "Top 4 matches: 0.186\n",
      "Top 4 matches (any order): 0.222\n",
      "Top 5 matches: 0.118\n",
      "Top 5 matches (any order): 0.164\n",
      "Top 6 matches: 0.104\n",
      "Top 6 matches (any order): 0.124\n",
      "Top 7 matches: 0.066\n",
      "Top 7 matches (any order): 0.082\n",
      "Top 8 matches: 0.052\n",
      "Top 8 matches (any order): 0.054\n",
      "Top 9 matches: 0.040\n",
      "Top 9 matches (any order): 0.048\n",
      "Top 10 matches: 0.034\n",
      "Top 10 matches (any order): 0.034\n"
     ]
    }
   ],
   "source": [
    "block_idx = 5\n",
    "ffwd5_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.95,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 48461, 'mean': 1877.104, 'std': 5356.329997786171}\n",
      "Top 1 matches: 0.776\n",
      "Top 1 matches (any order): 0.776\n",
      "Top 2 matches: 0.456\n",
      "Top 2 matches (any order): 0.520\n",
      "Top 3 matches: 0.296\n",
      "Top 3 matches (any order): 0.382\n",
      "Top 4 matches: 0.198\n",
      "Top 4 matches (any order): 0.260\n",
      "Top 5 matches: 0.174\n",
      "Top 5 matches (any order): 0.196\n",
      "Top 6 matches: 0.130\n",
      "Top 6 matches (any order): 0.176\n",
      "Top 7 matches: 0.096\n",
      "Top 7 matches (any order): 0.124\n",
      "Top 8 matches: 0.078\n",
      "Top 8 matches (any order): 0.092\n",
      "Top 9 matches: 0.078\n",
      "Top 9 matches (any order): 0.080\n",
      "Top 10 matches: 0.062\n",
      "Top 10 matches (any order): 0.052\n"
     ]
    }
   ],
   "source": [
    "block_idx = 4\n",
    "ffwd4_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.83,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 1260, 'mean': 38.416, 'std': 114.08503383003399}\n",
      "Top 1 matches: 0.724\n",
      "Top 1 matches (any order): 0.724\n",
      "Top 2 matches: 0.256\n",
      "Top 2 matches (any order): 0.282\n",
      "Top 3 matches: 0.084\n",
      "Top 3 matches (any order): 0.098\n",
      "Top 4 matches: 0.060\n",
      "Top 4 matches (any order): 0.068\n",
      "Top 5 matches: 0.046\n",
      "Top 5 matches (any order): 0.062\n",
      "Top 6 matches: 0.030\n",
      "Top 6 matches (any order): 0.022\n",
      "Top 7 matches: 0.022\n",
      "Top 7 matches (any order): 0.016\n",
      "Top 8 matches: 0.018\n",
      "Top 8 matches (any order): 0.008\n",
      "Top 9 matches: 0.018\n",
      "Top 9 matches (any order): 0.016\n",
      "Top 10 matches: 0.008\n",
      "Top 10 matches (any order): 0.008\n"
     ]
    }
   ],
   "source": [
    "block_idx = 3\n",
    "ffwd3_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.97,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 6046, 'mean': 468.448, 'std': 876.6662804602445}\n",
      "Top 1 matches: 0.770\n",
      "Top 1 matches (any order): 0.770\n",
      "Top 2 matches: 0.454\n",
      "Top 2 matches (any order): 0.500\n",
      "Top 3 matches: 0.278\n",
      "Top 3 matches (any order): 0.360\n",
      "Top 4 matches: 0.214\n",
      "Top 4 matches (any order): 0.246\n",
      "Top 5 matches: 0.136\n",
      "Top 5 matches (any order): 0.174\n",
      "Top 6 matches: 0.102\n",
      "Top 6 matches (any order): 0.130\n",
      "Top 7 matches: 0.110\n",
      "Top 7 matches (any order): 0.098\n",
      "Top 8 matches: 0.062\n",
      "Top 8 matches (any order): 0.082\n",
      "Top 9 matches: 0.060\n",
      "Top 9 matches (any order): 0.072\n",
      "Top 10 matches: 0.052\n",
      "Top 10 matches (any order): 0.050\n"
     ]
    }
   ],
   "source": [
    "block_idx = 2\n",
    "ffwd2_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.90,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 4263, 'mean': 169.482, 'std': 383.18133784932684}\n",
      "Top 1 matches: 0.736\n",
      "Top 1 matches (any order): 0.736\n",
      "Top 2 matches: 0.394\n",
      "Top 2 matches (any order): 0.444\n",
      "Top 3 matches: 0.196\n",
      "Top 3 matches (any order): 0.270\n",
      "Top 4 matches: 0.144\n",
      "Top 4 matches (any order): 0.192\n",
      "Top 5 matches: 0.122\n",
      "Top 5 matches (any order): 0.138\n",
      "Top 6 matches: 0.080\n",
      "Top 6 matches (any order): 0.072\n",
      "Top 7 matches: 0.066\n",
      "Top 7 matches (any order): 0.064\n",
      "Top 8 matches: 0.046\n",
      "Top 8 matches (any order): 0.046\n",
      "Top 9 matches: 0.062\n",
      "Top 9 matches (any order): 0.048\n",
      "Top 10 matches: 0.032\n",
      "Top 10 matches (any order): 0.022\n"
     ]
    }
   ],
   "source": [
    "block_idx = 1\n",
    "ffwd1_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.99,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 216, 'max': 111556, 'mean': 23359.618, 'std': 29254.668618804688}\n",
      "Top 1 matches: 0.444\n",
      "Top 1 matches (any order): 0.444\n",
      "Top 2 matches: 0.216\n",
      "Top 2 matches (any order): 0.208\n",
      "Top 3 matches: 0.142\n",
      "Top 3 matches (any order): 0.116\n",
      "Top 4 matches: 0.164\n",
      "Top 4 matches (any order): 0.130\n",
      "Top 5 matches: 0.124\n",
      "Top 5 matches (any order): 0.100\n",
      "Top 6 matches: 0.124\n",
      "Top 6 matches (any order): 0.104\n",
      "Top 7 matches: 0.094\n",
      "Top 7 matches (any order): 0.060\n",
      "Top 8 matches: 0.076\n",
      "Top 8 matches (any order): 0.032\n",
      "Top 9 matches: 0.076\n",
      "Top 9 matches (any order): 0.022\n",
      "Top 10 matches: 0.048\n",
      "Top 10 matches (any order): 0.016\n"
     ]
    }
   ],
   "source": [
    "block_idx = 0\n",
    "ffwd0_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.97,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.800\n",
      "Top 1 matches (any order): 0.800\n",
      "Top 2 matches: 0.502\n",
      "Top 2 matches (any order): 0.548\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.420\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.316\n",
      "Top 5 matches: 0.208\n",
      "Top 5 matches (any order): 0.232\n",
      "Top 6 matches: 0.198\n",
      "Top 6 matches (any order): 0.218\n",
      "Top 7 matches: 0.142\n",
      "Top 7 matches (any order): 0.138\n",
      "Top 8 matches: 0.096\n",
      "Top 8 matches (any order): 0.114\n",
      "Top 9 matches: 0.114\n",
      "Top 9 matches (any order): 0.094\n",
      "Top 10 matches: 0.098\n",
      "Top 10 matches (any order): 0.072\n"
     ]
    }
   ],
   "source": [
    "total_freqs = [\n",
    "    (\n",
    "        0.00110*ffwd0_freqs[i] +\n",
    "        0.63*ffwd1_freqs[i] +\n",
    "        0.08*ffwd2_freqs[i] +\n",
    "        2*ffwd3_freqs[i] +\n",
    "        3*ffwd4_freqs[i] +\n",
    "        10*ffwd5_freq\n",
    "    )\n",
    "    for i, ffwd5_freq in enumerate(ffwd5_freqs)\n",
    "]\n",
    "total_probs = [\n",
    "    freqs / freqs.sum()\n",
    "    for freqs in total_freqs\n",
    "]\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs_sample)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate data from the rest of the strings (everything above just looked at first 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74a5bb0c8904fabaa94b81a6edafcd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_all_strings = 20000\n",
    "sample_size = 500\n",
    "n_chunks = math.ceil(n_all_strings / sample_size)\n",
    "\n",
    "last_sample_idx = 25  # This is all we have generated. Get rid of this and just iterate to n_chunks-1 when we have all the data.\n",
    "\n",
    "next_token_map = next_token_map10\n",
    "all_strings = strings10\n",
    "\n",
    "ffwd_thresholds = [0.97, 0.99, 0.90, 0.97, 0.83, 0.95]\n",
    "ffwd_freqs = [[] for _ in range(n_layer)]\n",
    "model_outputs = []\n",
    "\n",
    "for sample_idx in tqdm(range(0, last_sample_idx + 1)):\n",
    "    output_folder = exp10.output_dir / f\"cosine_sims_{sample_idx:03d}\"\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    exp = CosineSimilaritiesExperiment(exp10, output_folder)\n",
    "\n",
    "    start_idx = sample_idx * sample_size\n",
    "    end_idx = min(start_idx + sample_size, n_all_strings)\n",
    "\n",
    "    strings = strings20k[start_idx:end_idx]\n",
    "\n",
    "    model_outputs.extend(get_model_outputs(strings, encoding_helpers))\n",
    "\n",
    "    for block_idx in range(n_layer):\n",
    "        get_batch = lambda batch_idx: torch.load(\n",
    "            str(exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)),\n",
    "            mmap=True,\n",
    "        )\n",
    "\n",
    "        filter_results = filter_across_batches(\n",
    "            get_batch=get_batch,\n",
    "            n_batches=exp.n_batches,\n",
    "            filter_fn=lambda batch: batch > ffwd_thresholds[block_idx],\n",
    "            n_queries=sample_size,\n",
    "        )\n",
    "        filter_results_strings = get_matching_strings(filter_results, all_strings)\n",
    "        filter_result_freqs = [\n",
    "            torch.stack(\n",
    "                [\n",
    "                    next_token_map[matching_string]\n",
    "                    for matching_string in matching_strings\n",
    "                ]\n",
    "            ).sum(dim=0)\n",
    "            for matching_strings in filter_results_strings\n",
    "        ]\n",
    "        ffwd_freqs[block_idx].extend(filter_result_freqs)\n",
    "\n",
    "ffwd_freqs = torch.stack(\n",
    "    [torch.stack(ffwd_freqs[block_idx]) for block_idx in range(n_layer)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ffwd_freqs, str(exp10.output_dir / 'learn_coefficients/ffwd_freqs.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 13000, 65]), 13000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_freqs.shape, len(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.800\n",
      "Top 1 matches (any order): 0.800\n",
      "Top 2 matches: 0.502\n",
      "Top 2 matches (any order): 0.548\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.420\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.316\n",
      "Top 5 matches: 0.208\n",
      "Top 5 matches (any order): 0.232\n",
      "Top 6 matches: 0.198\n",
      "Top 6 matches (any order): 0.218\n",
      "Top 7 matches: 0.142\n",
      "Top 7 matches (any order): 0.138\n",
      "Top 8 matches: 0.096\n",
      "Top 8 matches (any order): 0.114\n",
      "Top 9 matches: 0.114\n",
      "Top 9 matches (any order): 0.094\n",
      "Top 10 matches: 0.098\n",
      "Top 10 matches (any order): 0.072\n"
     ]
    }
   ],
   "source": [
    "# Check that we still get the same results for the first 500\n",
    "hand_rolled_coeffs = torch.tensor([0.00110, 0.63, 0.08, 2, 3, 10]) .unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs[:, :500, :] * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs_sample[:500])\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.816\n",
      "Top 1 matches (any order): 0.816\n",
      "Top 2 matches: 0.506\n",
      "Top 2 matches (any order): 0.577\n",
      "Top 3 matches: 0.356\n",
      "Top 3 matches (any order): 0.413\n",
      "Top 4 matches: 0.277\n",
      "Top 4 matches (any order): 0.330\n",
      "Top 5 matches: 0.222\n",
      "Top 5 matches (any order): 0.254\n",
      "Top 6 matches: 0.200\n",
      "Top 6 matches (any order): 0.220\n",
      "Top 7 matches: 0.141\n",
      "Top 7 matches (any order): 0.153\n",
      "Top 8 matches: 0.125\n",
      "Top 8 matches (any order): 0.126\n",
      "Top 9 matches: 0.107\n",
      "Top 9 matches (any order): 0.104\n",
      "Top 10 matches: 0.080\n",
      "Top 10 matches (any order): 0.064\n"
     ]
    }
   ],
   "source": [
    "# Look at it for all samples\n",
    "hand_rolled_coeffs = torch.tensor([0.00110, 0.63, 0.08, 2, 3, 10]) .unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSim(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.coeffs = torch.nn.Parameter(\n",
    "            torch.randn(n_layer, 1, 1, dtype=torch.float32, requires_grad=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, freqs: torch.Tensor, model_output: Optional[torch.Tensor]=None):\n",
    "        total_freqs = (freqs * self.coeffs).sum(dim=0)\n",
    "        total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "        if model_output is not None:\n",
    "            loss = torch.norm(total_probs - model_output, dim=-1).sum()\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "\n",
    "        return total_probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 100\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: ModelSim, get_batch: Callable[[str], Tuple[torch.Tensor, torch.Tensor]]\n",
    "):\n",
    "    out = {}\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "\n",
    "            _, loss = model(X, Y)\n",
    "\n",
    "            losses[k] = loss.item()\n",
    "\n",
    "        out[split] = losses.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    iters: Sequence[int],\n",
    "    model: ModelSim,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    get_batch: Callable[[str], Tuple[torch.Tensor, torch.Tensor]],\n",
    "    checkpointer: CheckPointer,\n",
    "    eval_interval: int = 500\n",
    "):\n",
    "    for step in tqdm(iters):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        X, Y = get_batch(\"train\")\n",
    "\n",
    "        _, loss = model(X, Y)\n",
    "\n",
    "        if step % eval_interval == 0:\n",
    "            losses = estimate_loss(model, get_batch)\n",
    "            print(\n",
    "                f\"step {step}, train loss: {losses['train']:.3f}, val_loss {losses['val']:.3f}\"\n",
    "            )\n",
    "            checkpointer.save_checkpoint(\n",
    "                step, model, losses[\"train\"], losses[\"val\"]\n",
    "            )\n",
    "\n",
    "        # Take a step\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size: int, freqs: torch.Tensor, split: str='train', train_pct: float=0.9):\n",
    "    n = freqs.shape[1]\n",
    "    assert split in ['train', 'val']\n",
    "    n_train = int(n * train_pct)\n",
    "    low = 0 if split == 'train' else n_train\n",
    "    high = n_train if split == 'train' else n\n",
    "\n",
    "    batch_indices = torch.randint(low=low, high=high, size=(batch_size,), dtype=torch.long)\n",
    "    batch_strings = [strings20k[i.item()] for i in batch_indices]\n",
    "\n",
    "    tokens = encoding_helpers.tokenize_strings(batch_strings)\n",
    "    logits, _ = m(tokens)\n",
    "    model_output = F.softmax(logits[:, -1, :], dim=-1)\n",
    "\n",
    "    return freqs[:, batch_indices, :].clone(), model_output.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=500\n",
    "get_batch_func = lambda split: get_batch(\n",
    "    batch_size=batch_size, freqs=ffwd_freqs, split=split, train_pct=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(1337) # Ensure stable random values\n",
    "m2 = ModelSim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = exp10.output_dir / 'learn_coefficients'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "checkpointer = CheckPointer(output_dir, 'coeff_model', start_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a pretty high learning rate\n",
    "learning_rate = 3e-2\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "start_iter = 0\n",
    "iters = range(start_iter, start_iter+1001)\n",
    "eval_interval=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb3eb97c9534423b4d66abebba9b6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train loss: 241.612, val_loss 237.651\n",
      "step 500, train loss: 201.557, val_loss 204.529\n",
      "step 1000, train loss: 135.628, val_loss 137.657\n"
     ]
    }
   ],
   "source": [
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(133.8761), tensor(136.0159))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = estimate_loss(m2, get_batch_func)\n",
    "losses['train'], losses['val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we are in a pretty good place. I learned from experience that after this, at the same learning rate, the loss gets worse and then bounces around, never getting back to this point. So we'll slow down the learning rate and go a bit more. But first, let's check in on where we're at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -0.2058]],\n",
       "\n",
       "        [[-21.7527]],\n",
       "\n",
       "        [[-10.9828]],\n",
       "\n",
       "        [[-21.4913]],\n",
       "\n",
       "        [[ -8.8436]],\n",
       "\n",
       "        [[ -0.2939]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.736\n",
      "Top 1 matches (any order): 0.736\n",
      "Top 2 matches: 0.404\n",
      "Top 2 matches (any order): 0.466\n",
      "Top 3 matches: 0.284\n",
      "Top 3 matches (any order): 0.317\n",
      "Top 4 matches: 0.236\n",
      "Top 4 matches (any order): 0.263\n",
      "Top 5 matches: 0.186\n",
      "Top 5 matches (any order): 0.195\n",
      "Top 6 matches: 0.166\n",
      "Top 6 matches (any order): 0.163\n",
      "Top 7 matches: 0.117\n",
      "Top 7 matches (any order): 0.112\n",
      "Top 8 matches: 0.102\n",
      "Top 8 matches (any order): 0.090\n",
      "Top 9 matches: 0.095\n",
      "Top 9 matches (any order): 0.073\n",
      "Top 10 matches: 0.070\n",
      "Top 10 matches (any order): 0.041\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad but we know we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where did iters end up?\n",
    "iters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ed23ff45c14b7eb725f2d9efe1e6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1500, train loss: 88.177, val_loss 87.328\n",
      "step 2000, train loss: 86.917, val_loss 86.809\n"
     ]
    }
   ],
   "source": [
    "iters = range(1001, 2001)\n",
    "\n",
    "# Reduce the learning rate by one order of magnitude\n",
    "learning_rate = 3e-3\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.7885e-04]],\n",
       "\n",
       "        [[-2.1236e+01]],\n",
       "\n",
       "        [[-1.0711e+01]],\n",
       "\n",
       "        [[-2.1363e+01]],\n",
       "\n",
       "        [[-8.9933e+00]],\n",
       "\n",
       "        [[-5.4774e-02]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.789\n",
      "Top 1 matches (any order): 0.789\n",
      "Top 2 matches: 0.484\n",
      "Top 2 matches (any order): 0.560\n",
      "Top 3 matches: 0.347\n",
      "Top 3 matches (any order): 0.408\n",
      "Top 4 matches: 0.273\n",
      "Top 4 matches (any order): 0.331\n",
      "Top 5 matches: 0.219\n",
      "Top 5 matches (any order): 0.251\n",
      "Top 6 matches: 0.196\n",
      "Top 6 matches (any order): 0.219\n",
      "Top 7 matches: 0.145\n",
      "Top 7 matches (any order): 0.152\n",
      "Top 8 matches: 0.121\n",
      "Top 8 matches (any order): 0.123\n",
      "Top 9 matches: 0.107\n",
      "Top 9 matches (any order): 0.107\n",
      "Top 10 matches: 0.081\n",
      "Top 10 matches (any order): 0.066\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement! Let's try a lot more iterations at this same learning rate and see where we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where did iters end up?\n",
    "iters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8929725e78941f2985b956ecc6fe45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2500, train loss: 86.974, val_loss 86.748\n",
      "step 3000, train loss: 86.863, val_loss 86.883\n",
      "step 3500, train loss: 87.361, val_loss 86.588\n",
      "step 4000, train loss: 87.380, val_loss 86.652\n",
      "step 4500, train loss: 85.888, val_loss 85.819\n",
      "step 5000, train loss: 86.133, val_loss 85.628\n",
      "step 5500, train loss: 85.582, val_loss 85.125\n",
      "step 6000, train loss: 84.050, val_loss 84.298\n",
      "step 6500, train loss: 83.721, val_loss 83.268\n",
      "step 7000, train loss: 82.888, val_loss 82.894\n"
     ]
    }
   ],
   "source": [
    "# Let's go for 5000 iterations. We can always go back if it overshoots.\n",
    "iters = range(2001, 7001)\n",
    "\n",
    "# Train some more\n",
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.6660e-03]],\n",
       "\n",
       "        [[-1.1624e+01]],\n",
       "\n",
       "        [[-5.4355e-01]],\n",
       "\n",
       "        [[-2.6189e+01]],\n",
       "\n",
       "        [[-1.3666e+01]],\n",
       "\n",
       "        [[-6.0726e-02]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.800\n",
      "Top 1 matches (any order): 0.800\n",
      "Top 2 matches: 0.491\n",
      "Top 2 matches (any order): 0.565\n",
      "Top 3 matches: 0.348\n",
      "Top 3 matches (any order): 0.407\n",
      "Top 4 matches: 0.276\n",
      "Top 4 matches (any order): 0.329\n",
      "Top 5 matches: 0.220\n",
      "Top 5 matches (any order): 0.255\n",
      "Top 6 matches: 0.199\n",
      "Top 6 matches (any order): 0.218\n",
      "Top 7 matches: 0.141\n",
      "Top 7 matches (any order): 0.153\n",
      "Top 8 matches: 0.124\n",
      "Top 8 matches (any order): 0.121\n",
      "Top 9 matches: 0.106\n",
      "Top 9 matches (any order): 0.104\n",
      "Top 10 matches: 0.078\n",
      "Top 10 matches (any order): 0.063\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where did iters end up?\n",
    "iters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9797077d13924726ab968e34ae7b2df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7500, train loss: 81.342, val_loss 82.018\n",
      "step 8000, train loss: 81.164, val_loss 81.277\n",
      "step 8500, train loss: 80.309, val_loss 80.065\n",
      "step 9000, train loss: 78.922, val_loss 79.470\n",
      "step 9500, train loss: 77.919, val_loss 78.434\n",
      "step 10000, train loss: 77.058, val_loss 78.159\n",
      "step 10500, train loss: 77.470, val_loss 78.453\n",
      "step 11000, train loss: 77.198, val_loss 78.682\n",
      "step 11500, train loss: 77.445, val_loss 78.351\n",
      "step 12000, train loss: 77.037, val_loss 78.661\n"
     ]
    }
   ],
   "source": [
    "# Let's go for 5000 iterations. We can always go back if it overshoots.\n",
    "iters = range(7001, 12001)\n",
    "\n",
    "# Train some more\n",
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4626e-03]],\n",
       "\n",
       "        [[-3.7772e-01]],\n",
       "\n",
       "        [[ 1.3287e-02]],\n",
       "\n",
       "        [[-3.2255e+01]],\n",
       "\n",
       "        [[-1.5003e+01]],\n",
       "\n",
       "        [[-6.6595e-02]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.810\n",
      "Top 1 matches (any order): 0.810\n",
      "Top 2 matches: 0.496\n",
      "Top 2 matches (any order): 0.567\n",
      "Top 3 matches: 0.347\n",
      "Top 3 matches (any order): 0.403\n",
      "Top 4 matches: 0.271\n",
      "Top 4 matches (any order): 0.324\n",
      "Top 5 matches: 0.217\n",
      "Top 5 matches (any order): 0.252\n",
      "Top 6 matches: 0.196\n",
      "Top 6 matches (any order): 0.215\n",
      "Top 7 matches: 0.142\n",
      "Top 7 matches (any order): 0.152\n",
      "Top 8 matches: 0.122\n",
      "Top 8 matches (any order): 0.121\n",
      "Top 9 matches: 0.104\n",
      "Top 9 matches (any order): 0.099\n",
      "Top 10 matches: 0.079\n",
      "Top 10 matches (any order): 0.061\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where did iters end up?\n",
    "iters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f57b95adcb0411e8ea838ba19214ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12500, train loss: 77.357, val_loss 79.174\n",
      "step 13000, train loss: 77.685, val_loss 78.382\n"
     ]
    }
   ],
   "source": [
    "# Let's go for 1000 more\n",
    "iters = range(12001, 13001)\n",
    "\n",
    "# Train some more\n",
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we're kinda stuck here. Let's see what happens if we go back to a bigger learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where did iters end up?\n",
    "iters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6972aa000b1f4a84ba43e379af24f692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13500, train loss: 135.310, val_loss 135.358\n",
      "step 14000, train loss: 122.897, val_loss 124.560\n"
     ]
    }
   ],
   "source": [
    "iters = range(13001, 14001)\n",
    "\n",
    "# Reduce the learning rate by one order of magnitude\n",
    "learning_rate = 3e-2\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK that was a big step backwards. Let's go back to the checkpoint for step 12000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, tensor(77.0366), tensor(78.6612))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpointer.output_dir / 'coeff_model_000024.pt')\n",
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(76.3558), 'val': tensor(78.6847)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_loss(m2, get_batch_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so we're back to a good state. From here, let's try a smaller learning rate and see if we can get to a better place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ded80881576465eaa3322a0a9b59a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12500, train loss: 77.424, val_loss 77.532\n",
      "step 13000, train loss: 77.258, val_loss 77.458\n",
      "step 13500, train loss: 77.586, val_loss 78.413\n",
      "step 14000, train loss: 77.379, val_loss 77.972\n",
      "step 14500, train loss: 77.640, val_loss 77.830\n",
      "step 15000, train loss: 77.147, val_loss 77.483\n",
      "step 15500, train loss: 77.133, val_loss 78.076\n",
      "step 16000, train loss: 77.453, val_loss 77.666\n",
      "step 16500, train loss: 77.320, val_loss 77.908\n",
      "step 17000, train loss: 77.376, val_loss 77.925\n",
      "step 17500, train loss: 77.313, val_loss 78.315\n",
      "step 18000, train loss: 77.748, val_loss 78.471\n",
      "step 18500, train loss: 76.673, val_loss 78.184\n",
      "step 19000, train loss: 77.181, val_loss 78.109\n",
      "step 19500, train loss: 77.044, val_loss 78.242\n",
      "step 20000, train loss: 76.708, val_loss 77.908\n",
      "step 20500, train loss: 77.322, val_loss 78.222\n",
      "step 21000, train loss: 77.078, val_loss 77.792\n",
      "step 21500, train loss: 76.784, val_loss 77.895\n",
      "step 22000, train loss: 76.980, val_loss 77.926\n"
     ]
    }
   ],
   "source": [
    "iters = range(12001, 22001)\n",
    "\n",
    "# Reduce the learning rate by one order of magnitude\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, seems like this is stagnating. Try slowing down the learning rate even further and going for one more round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where did iters end up?\n",
    "iters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff1e7caf2744cfd956a1ed3e844657f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22500, train loss: 76.870, val_loss 77.868\n",
      "step 23000, train loss: 76.529, val_loss 77.656\n",
      "step 23500, train loss: 76.755, val_loss 78.100\n",
      "step 24000, train loss: 77.780, val_loss 78.070\n",
      "step 24500, train loss: 77.234, val_loss 77.849\n",
      "step 25000, train loss: 77.190, val_loss 77.891\n",
      "step 25500, train loss: 77.453, val_loss 77.203\n",
      "step 26000, train loss: 76.894, val_loss 77.747\n",
      "step 26500, train loss: 77.383, val_loss 77.889\n",
      "step 27000, train loss: 77.054, val_loss 77.632\n",
      "step 27500, train loss: 77.147, val_loss 77.393\n",
      "step 28000, train loss: 77.582, val_loss 77.413\n",
      "step 28500, train loss: 77.349, val_loss 77.526\n",
      "step 29000, train loss: 77.317, val_loss 78.182\n",
      "step 29500, train loss: 76.733, val_loss 77.809\n",
      "step 30000, train loss: 77.529, val_loss 77.429\n",
      "step 30500, train loss: 77.185, val_loss 77.459\n",
      "step 31000, train loss: 77.191, val_loss 77.592\n",
      "step 31500, train loss: 77.590, val_loss 78.024\n",
      "step 32000, train loss: 77.452, val_loss 78.473\n"
     ]
    }
   ],
   "source": [
    "iters = range(22001, 32001)\n",
    "\n",
    "# Reduce the learning rate by one order of magnitude\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "train(iters=iters, model=m2, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, looks like this is still kind of stuck in this region and maybe can't go anywhere better from here. What if we initialize with the hand-rolled weights and see if it can improve that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = ModelSim()\n",
    "m3.coeffs = torch.nn.Parameter(torch.tensor([0.00110, 0.63, 0.08, 2, 3, 10]).unsqueeze(dim=1).unsqueeze(dim=2))\n",
    "m3.coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = exp10.output_dir / 'learn_coefficients'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "checkpointer = CheckPointer(output_dir, 'coeff_model_hand_rolled', start_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin with a moderate learning rate\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.AdamW(m3.parameters(), lr=learning_rate)\n",
    "\n",
    "start_iter = 0\n",
    "iters = range(start_iter, start_iter+1001)\n",
    "eval_interval=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a586cfcb6cbf4afdbd163c0f80a5ea38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train loss: 78.948, val_loss 80.359\n",
      "step 500, train loss: 76.345, val_loss 77.676\n",
      "step 1000, train loss: 76.179, val_loss 77.503\n"
     ]
    }
   ],
   "source": [
    "train(iters=iters, model=m3, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.0409e-04]],\n",
       "\n",
       "        [[ 3.6633e-01]],\n",
       "\n",
       "        [[-1.7641e-02]],\n",
       "\n",
       "        [[ 2.1913e+00]],\n",
       "\n",
       "        [[ 3.0050e+00]],\n",
       "\n",
       "        [[ 1.0185e+01]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.817\n",
      "Top 1 matches (any order): 0.817\n",
      "Top 2 matches: 0.504\n",
      "Top 2 matches (any order): 0.574\n",
      "Top 3 matches: 0.355\n",
      "Top 3 matches (any order): 0.413\n",
      "Top 4 matches: 0.275\n",
      "Top 4 matches (any order): 0.330\n",
      "Top 5 matches: 0.221\n",
      "Top 5 matches (any order): 0.253\n",
      "Top 6 matches: 0.198\n",
      "Top 6 matches (any order): 0.218\n",
      "Top 7 matches: 0.141\n",
      "Top 7 matches (any order): 0.153\n",
      "Top 8 matches: 0.124\n",
      "Top 8 matches (any order): 0.124\n",
      "Top 9 matches: 0.105\n",
      "Top 9 matches (any order): 0.102\n",
      "Top 10 matches: 0.078\n",
      "Top 10 matches (any order): 0.063\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m3(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost as good as what I had hand-rolled. Let's go a little more and see if we can improve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(m3.parameters(), lr=learning_rate)\n",
    "\n",
    "iters = range(1001, 11001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398c986be8cd4fbe9663fd24aee277ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1500, train loss: 76.471, val_loss 76.904\n",
      "step 2000, train loss: 75.632, val_loss 77.666\n",
      "step 2500, train loss: 76.099, val_loss 76.458\n",
      "step 3000, train loss: 75.324, val_loss 76.594\n",
      "step 3500, train loss: 76.446, val_loss 76.955\n",
      "step 4000, train loss: 75.880, val_loss 76.352\n",
      "step 4500, train loss: 76.183, val_loss 76.920\n",
      "step 5000, train loss: 75.911, val_loss 76.729\n",
      "step 5500, train loss: 75.490, val_loss 76.433\n",
      "step 6000, train loss: 75.511, val_loss 77.376\n",
      "step 6500, train loss: 75.577, val_loss 75.980\n",
      "step 7000, train loss: 76.168, val_loss 76.554\n",
      "step 7500, train loss: 75.267, val_loss 76.620\n",
      "step 8000, train loss: 76.097, val_loss 76.439\n",
      "step 8500, train loss: 75.934, val_loss 76.713\n",
      "step 9000, train loss: 75.824, val_loss 76.684\n",
      "step 9500, train loss: 75.885, val_loss 76.549\n",
      "step 10000, train loss: 75.604, val_loss 76.377\n",
      "step 10500, train loss: 75.899, val_loss 76.442\n",
      "step 11000, train loss: 75.453, val_loss 76.470\n"
     ]
    }
   ],
   "source": [
    "train(iters=iters, model=m3, optimizer=optimizer, get_batch=get_batch_func, checkpointer=checkpointer, eval_interval=eval_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.5622e-04]],\n",
       "\n",
       "        [[ 1.7031e-01]],\n",
       "\n",
       "        [[-7.9133e-03]],\n",
       "\n",
       "        [[ 2.3232e+00]],\n",
       "\n",
       "        [[ 2.9156e+00]],\n",
       "\n",
       "        [[ 1.0321e+01]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.818\n",
      "Top 1 matches (any order): 0.818\n",
      "Top 2 matches: 0.507\n",
      "Top 2 matches (any order): 0.576\n",
      "Top 3 matches: 0.356\n",
      "Top 3 matches (any order): 0.413\n",
      "Top 4 matches: 0.275\n",
      "Top 4 matches (any order): 0.330\n",
      "Top 5 matches: 0.221\n",
      "Top 5 matches (any order): 0.254\n",
      "Top 6 matches: 0.198\n",
      "Top 6 matches (any order): 0.220\n",
      "Top 7 matches: 0.142\n",
      "Top 7 matches (any order): 0.154\n",
      "Top 8 matches: 0.123\n",
      "Top 8 matches (any order): 0.125\n",
      "Top 9 matches: 0.106\n",
      "Top 9 matches (any order): 0.102\n",
      "Top 10 matches: 0.079\n",
      "Top 10 matches (any order): 0.063\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m3(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually the best result so far. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Sims for Length 256 Strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings256 = all_unique_substrings(ts.text, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "sample_size = 500\n",
    "indices256 = torch.randperm(len(strings256))[:sample_size]\n",
    "strings256_sample = [strings256[i.item()] for i in indices256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs_sample256 = get_model_outputs(strings256_sample, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_exp256 = BlockInternalsExperiment(encoding_helpers, accessors, strings256_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilaritiesForFinalFFWDExperiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp: FinalFFWDExperiment,\n",
    "        output_folder: Path,\n",
    "    ):\n",
    "        self.exp = exp\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        self.n_batches = exp.n_batches\n",
    "\n",
    "    def ffwd_out_sims_filename(self, batch_idx: int, block_idx: int):\n",
    "        return self.output_folder / f'ffwds_out_sims_{batch_idx:04d}_{block_idx:02d}.pt'\n",
    "\n",
    "    def generate_ffwd_out_sims(self, get_queries: Callable[[int], torch.Tensor], disable_progress_bar=False):\n",
    "        block_idx = n_layer - 1\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            queries = get_queries(block_idx)\n",
    "            assert queries.dim() == 2\n",
    "            n_queries = queries.shape[0]\n",
    "\n",
    "            ffwd_out_batch = torch.load(str(self.exp._ffwd_output_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True)\n",
    "            batch_size = ffwd_out_batch.shape[0]\n",
    "            sims = F.cosine_similarity(\n",
    "                ffwd_out_batch.reshape(batch_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                queries,\n",
    "                dim=-1\n",
    "            )\n",
    "            torch.save(sims, str(self.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd_exp256 = FinalFFWDExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings256,\n",
    "    output_dir=Path('../artifacts/block_internals_results/large_files/slen256'),\n",
    "    batch_size=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ffwd_exp256.output_dir / 'cosine_sims'\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp256 = CosineSimilaritiesForFinalFFWDExperiment(ffwd_exp256, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa11ce5d335947219d9e20bb0294dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos_exp256.generate_ffwd_out_sims(get_queries=lambda block_idx: prompts_exp256.ffwd_output(block_idx=block_idx)[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_map256 = build_next_token_map(ts.text, 256, tokenizer.vocab_size, tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 1, 'max': 38780, 'mean': 1561.9, 'std': 4162.8430373964375}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_idx = n_layer - 1\n",
    "ffwd256 = filter_across_batches(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp256.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp256.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.91,\n",
    "    n_queries=sample_size,\n",
    ")\n",
    "filter_result_stats(ffwd256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd256_strings = get_matching_strings(ffwd256, strings256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd256_freqs = [\n",
    "    torch.stack([\n",
    "        next_token_map256[matching_string]\n",
    "        for matching_string in matching_strings\n",
    "    ]).sum(dim=0)\n",
    "    for matching_strings in ffwd256_strings\n",
    "]\n",
    "ffwd256_probs = [\n",
    "    freqs / freqs.sum()\n",
    "    for freqs in ffwd256_freqs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.802\n",
      "Top 1 matches (any order): 0.802\n",
      "Top 2 matches: 0.362\n",
      "Top 2 matches (any order): 0.412\n",
      "Top 3 matches: 0.246\n",
      "Top 3 matches (any order): 0.298\n",
      "Top 4 matches: 0.200\n",
      "Top 4 matches (any order): 0.250\n",
      "Top 5 matches: 0.156\n",
      "Top 5 matches (any order): 0.154\n",
      "Top 6 matches: 0.128\n",
      "Top 6 matches (any order): 0.148\n",
      "Top 7 matches: 0.070\n",
      "Top 7 matches (any order): 0.086\n",
      "Top 8 matches: 0.044\n",
      "Top 8 matches (any order): 0.068\n",
      "Top 9 matches: 0.032\n",
      "Top 9 matches (any order): 0.038\n",
      "Top 10 matches: 0.030\n",
      "Top 10 matches (any order): 0.016\n"
     ]
    }
   ],
   "source": [
    "topn_matches, topn_matches_any_order = analyze_simulate_results(ffwd256_probs, model_outputs_sample256)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 (\" see my shame in him.\\nThou art a widow; yet thou art a mother,\\nAnd hast the comfort of thy children left thee:\\nBut death hath snatch'd my husband from mine arms,\\nAnd pluck'd two crutches from my feeble limbs,\\nEdward and Clarence. O, what cause have I,\\nThin\"): \n",
      "  \" so.\\n\\nSICINIUS:\\nLet them assemble,\\nAnd on a safer judgment all revoke\\nYour ignorant election; enforce his pride,\\nAnd his old hate unto you; besides, forget not\\nWith what contempt he wore the humble weed,\\nHow in his suit he scorn'd you; but your loves,\\nThin\"\n",
      "  \"I'ld have beaten him like a dog, but for\\ndisturbing the lords within.\\n\\nAUFIDIUS:\\nWhence comest thou? what wouldst thou? thy name?\\nWhy speak'st not? speak, man: what's thy name?\\n\\nCORIOLANUS:\\nIf, Tullus,\\nNot yet thou knowest me, and, seeing me, dost not\\nThin\"\n",
      "  \"e not--to save my life, for if\\nI had fear'd death, of all the men i' the world\\nI would have 'voided thee, but in mere spite,\\nTo be full quit of those my banishers,\\nStand I before thee here. Then if thou hast\\nA heart of wreak in thee, that wilt revenge\\nThin\"\n",
      "  \"t,\\nwhich should\\nMake our eyes flow with joy, hearts dance\\nwith comforts,\\nConstrains them weep and shake with fear and sorrow;\\nMaking the mother, wife and child to see\\nThe son, the husband and the father tearing\\nHis country's bowels out. And to poor we\\nThin\"\n",
      "  \" abhorr'd.' Speak to me, son:\\nThou hast affected the fine strains of honour,\\nTo imitate the graces of the gods;\\nTo tear with thunder the wide cheeks o' the air,\\nAnd yet to charge thy sulphur with a bolt\\nThat should but rive an oak. Why dost not speak?\\nThin\"\n",
      "  \"d me, in the field by Tewksbury\\nWhen Oxford had me down, he rescued me,\\nAnd said, 'Dear brother, live, and be a king'?\\nWho told me, when we both lay in the field\\nFrozen almost to death, how he did lap me\\nEven in his own garments, and gave himself,\\nAll thin\"\n",
      "  \" see my shame in him.\\nThou art a widow; yet thou art a mother,\\nAnd hast the comfort of thy children left thee:\\nBut death hath snatch'd my husband from mine arms,\\nAnd pluck'd two crutches from my feeble limbs,\\nEdward and Clarence. O, what cause have I,\\nThin\"\n",
      "  \" uncle Clarence' angry ghost:\\nMy grandam told me he was murdered there.\\n\\nPRINCE EDWARD:\\nI fear no uncles dead.\\n\\nGLOUCESTER:\\nNor none that live, I hope.\\n\\nPRINCE EDWARD:\\nAn if they live, I hope I need not fear.\\nBut come, my lord; and with a heavy heart,\\nThin\"\n",
      "  \"ard, capable\\nHe is all the mother's, from the top to toe.\\n\\nBUCKINGHAM:\\nWell, let them rest. Come hither, Catesby.\\nThou art sworn as deeply to effect what we intend\\nAs closely to conceal what we impart:\\nThou know'st our reasons urged upon the way;\\nWhat thin\"\n",
      "  \"ng that yet think not on it.\\n\\nCATESBY:\\n'Tis a vile thing to die, my gracious lord,\\nWhen men are unprepared and look not for it.\\n\\nHASTINGS:\\nO monstrous, monstrous! and so falls it out\\nWith Rivers, Vaughan, Grey: and so 'twill do\\nWith some men else, who thin\"\n",
      "  \"od morrow; good morrow, Catesby:\\nYou may jest on, but, by the holy rood,\\nI do not like these several councils, I.\\n\\nHASTINGS:\\nMy lord,\\nI hold my life as dear as you do yours;\\nAnd never in my life, I do protest,\\nWas it more precious to me than 'tis now:\\nThin\"\n",
      "  \"fitting for that royal time?\\n\\nDERBY:\\nIt is, and wants but nomination.\\n\\nBISHOP OF ELY:\\nTo-morrow, then, I judge a happy day.\\n\\nBUCKINGHAM:\\nWho knows the lord protector's mind herein?\\nWho is most inward with the royal duke?\\n\\nBISHOP OF ELY:\\nYour grace, we thin\"\n",
      "  \"e English woes will make me smile in France.\\n\\nQUEEN ELIZABETH:\\nO thou well skill'd in curses, stay awhile,\\nAnd teach me how to curse mine enemies!\\n\\nQUEEN MARGARET:\\nForbear to sleep the nights, and fast the days;\\nCompare dead happiness with living woe;\\nThin\"\n",
      "  'thy daughter,\\nAnd mean to make her queen of England.\\n\\nQUEEN ELIZABETH:\\nSay then, who dost thou mean shall be her king?\\n\\nKING RICHARD III:\\nEven he that makes her queen who should be else?\\n\\nQUEEN ELIZABETH:\\nWhat, thou?\\n\\nKING RICHARD III:\\nI, even I: what thin'\n",
      "  \"w near,\\nAnd list what with our council we have done.\\nFor that our kingdom's earth should not be soil'd\\nWith that dear blood which it hath fostered;\\nAnd for our eyes do hate the dire aspect\\nOf civil wounds plough'd up with neighbours' sword;\\nAnd for we thin\"\n",
      "  'd,\\nHaving my freedom, boast of nothing else\\nBut that I was a journeyman to grief?\\n\\nJOHN OF GAUNT:\\nAll places that the eye of heaven visits\\nAre to a wise man ports and happy havens.\\nTeach thy necessity to reason thus;\\nThere is no virtue like necessity.\\nThin'\n",
      "  \"eys-general to sue\\nHis livery, and deny his offer'd homage,\\nYou pluck a thousand dangers on your head,\\nYou lose a thousand well-disposed hearts\\nAnd prick my tender patience, to those thoughts\\nWhich honour and allegiance cannot think.\\n\\nKING RICHARD II:\\nThin\"\n",
      "  \"their complices,\\nThe caterpillars of the commonwealth,\\nWhich I have sworn to weed and pluck away.\\n\\nDUKE OF YORK:\\nIt may be I will go with you: but yet I'll pause;\\nFor I am loath to break our country's laws.\\nNor friends nor foes, to me welcome you are:\\nThin\"\n",
      "  \"ee to France\\nAnd cloister thee in some religious house:\\nOur holy lives must win a new world's crown,\\nWhich our profane hours here have stricken down.\\n\\nQUEEN:\\nWhat, is my Richard both in shape and mind\\nTransform'd and weaken'd? hath Bolingbroke deposed\\nThin\"\n",
      "  'ildly, kiss the rod,\\nAnd fawn on rage with base humility,\\nWhich art a lion and a king of beasts?\\n\\nKING RICHARD II:\\nA king of beasts, indeed; if aught but beasts,\\nI had been still a happy king of men.\\nGood sometime queen, prepare thee hence for France:\\nThin'\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(f\"Query {idx} ({repr(strings256_sample[idx])}): \")\n",
    "result = ffwd256[idx]\n",
    "for j in result[:20]:\n",
    "    print(f\"  {repr(strings256[j])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorBatchIterator:\n",
    "    def __init__(self, n_batches: int, get_batch: Callable[[int], torch.Tensor]):\n",
    "        self.n_batches = n_batches\n",
    "        self.get_batch = get_batch\n",
    "\n",
    "        self.next_batch_idx = 0\n",
    "        self.current_batch: Optional[torch.Tensor] = None\n",
    "        self.idx_within_batch = 0\n",
    "\n",
    "        self._load_next_batch()\n",
    "\n",
    "    def _load_next_batch(self):\n",
    "        if self.next_batch_idx >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "\n",
    "        self.current_batch = self.get_batch(self.next_batch_idx)\n",
    "        self.idx_within_batch = 0\n",
    "        self.next_batch_idx += 1\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch is None:\n",
    "            raise StopIteration()\n",
    "\n",
    "        if self.idx_within_batch >= self.current_batch.shape[0]:\n",
    "            self._load_next_batch()\n",
    "            if self.current_batch is None:\n",
    "                raise StopIteration()\n",
    "\n",
    "        result = self.current_batch[self.idx_within_batch, :]\n",
    "        self.idx_within_batch += 1\n",
    "        return result\n",
    "\n",
    "class EmbeddingCosineSims:\n",
    "    def __init__(self, exp: CosineSimilaritiesExperiment):\n",
    "        self.exp = exp\n",
    "\n",
    "    def __iter__(self):\n",
    "        return TensorBatchIterator(\n",
    "            n_batches=self.exp.n_batches,\n",
    "            get_batch=lambda batch_idx: torch.load(str(self.exp.embedding_sims_filename(batch_idx=batch_idx)), mmap=True)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sims = EmbeddingCosineSims(cos_exp)\n",
    "for i, sim in enumerate(emb_sims):\n",
    "    print(i, sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = next(iter(emb_sims))\n",
    "sims.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
