{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widening the Space of Similar Values\n",
    "\n",
    "> A major finding was that the current approaches are considering values that are too similar. This notebook investigates ways to search a wider space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Iterable, Protocol, Sequence, Tuple, TypeVar, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "import math\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import tempfile\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from transformer_experiments.common.substring_generator import all_unique_substrings\n",
    "from transformer_experiments.common.text_analysis import (\n",
    "    build_next_token_map,\n",
    "    SubstringFrequencyAnalysis,\n",
    "    top_nonzero_tokens\n",
    ")\n",
    "from transformer_experiments.common.utils import (\n",
    "    aggregate_by_string_key,\n",
    "    DataWrapper,\n",
    "    topk_across_batches,\n",
    ")\n",
    "from transformer_experiments.dataset_split import split_text_dataset\n",
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import (\n",
    "    n_embed,\n",
    "    n_layer,\n",
    "    TransformerLanguageModel\n",
    ")\n",
    "from transformer_experiments.models.transformer_helpers import (\n",
    "    unsqueeze_emb,\n",
    "    EncodingHelpers,\n",
    "    LogitsWrapper,\n",
    "    TransformerAccessors\n",
    ")\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer\n",
    ")\n",
    "from transformer_experiments.training_utils import CheckPointer, GetBatchFunction, Trainer\n",
    "from transformer_experiments.experiments.block_internals import (\n",
    "    BlockInternalsAccessors,\n",
    "    BlockInternalsExperiment,\n",
    "    BatchedBlockInternalsExperiment,\n",
    "    BlockInternalsAnalysis,\n",
    "    batch_cosine_sim,\n",
    ")\n",
    "from transformer_experiments.experiments.final_ffwd import FinalFFWDExperiment\n",
    "from transformer_experiments.experiments.similar_strings import (\n",
    "    SimilarStringsData,\n",
    "    SimilarStringsExperiment,\n",
    "    SimilarStringsResult\n",
    ")\n",
    "from transformer_experiments.experiments.logit_lens import LogitLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ts = TinyShakespeareDataSet(cache_file='../artifacts/input.txt')\n",
    "m, tokenizer = create_model_and_tokenizer(\n",
    "    saved_model_filename='../artifacts/shakespeare-20231109.pt',\n",
    "    dataset=ts,\n",
    "    device=device,\n",
    ")\n",
    "_, val_data = split_text_dataset(ts.text, tokenizer, train_pct=0.9, device=device)\n",
    "encoding_helpers = EncodingHelpers(tokenizer, device)\n",
    "accessors = TransformerAccessors(m, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list(Path('../artifacts/block_internals_results/large_files/slen10/').glob('*')) == []:\n",
    "    print(\"Run `make block_internals_slen10_dataset` in the project root to generate the required dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings10 = all_unique_substrings(ts.text, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp10 = BatchedBlockInternalsExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings10,\n",
    "    output_dir=Path('../artifacts/block_internals_results/large_files/slen10/'),\n",
    "    batch_size=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "n_samples = 20000\n",
    "indices = torch.randperm(len(strings10))[:n_samples]\n",
    "strings20k = [strings10[i.item()] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of 500 strings\n",
    "sample_size = 500\n",
    "strings_sample = strings20k[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this in a common component\n",
    "def get_model_outputs(prompts: Sequence[str], encoding_helpers: EncodingHelpers):\n",
    "    # Compute the model's predictions:\n",
    "    tokens = encoding_helpers.tokenize_strings(prompts)\n",
    "    logits, _ = m(tokens)\n",
    "\n",
    "    logits = LogitsWrapper(logits, encoding_helpers.tokenizer)\n",
    "    return [topk_tokens[-1] for topk_tokens in logits.topk_tokens(k=10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs_sample = get_model_outputs(strings_sample, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_exp = BlockInternalsExperiment(encoding_helpers, accessors, strings_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by examining what we get when we ask for a much larger top k values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sims, emb_distances = exp10.strings_with_topk_closest_embeddings(\n",
    "    prompts_exp.embeddings[:5, :, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9062, 0.9470, 0.9045, 0.9493, 0.9544],\n",
       "         [0.9062, 0.9462, 0.8602, 0.9083, 0.9443],\n",
       "         [0.9053, 0.9429, 0.8593, 0.9082, 0.9064],\n",
       "         [0.9037, 0.9429, 0.8586, 0.9055, 0.9057],\n",
       "         [0.9027, 0.9404, 0.8566, 0.9052, 0.9045],\n",
       "         [0.9020, 0.9027, 0.8562, 0.9044, 0.8996],\n",
       "         [0.9017, 0.9009, 0.8548, 0.9035, 0.8982],\n",
       "         [0.8962, 0.9009, 0.8545, 0.9034, 0.8656],\n",
       "         [0.8651, 0.9008, 0.8532, 0.9032, 0.8631]]),\n",
       " tensor([[0.7591, 0.7566, 0.7604, 0.8064, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7604, 0.8063, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7603, 0.8063, 0.8042],\n",
       "         [0.7590, 0.7564, 0.7602, 0.8063, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8062, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8061, 0.8040],\n",
       "         [0.7588, 0.7557, 0.7601, 0.8061, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7600, 0.8060, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8038],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8037]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_distances[:10, :], emb_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'is dream o'   'My present'   's eye, mak'   'eart of mo'   ' men, as I'\n",
      "'ur dreams,'   'be present'   's eyes in '   'earn of hi'   ' man, as y'\n",
      "'of dreams,'   'dy present'   'l eyes can'   'ears of ha'   ' man, if I'\n",
      "'us dreams.'   'my present'   's eyes to '   'park of ho'   'oman, as t'\n",
      "'he dreams,'   'ry present'   'l eyes gaz'   'eart of ge'   ' men, as i'\n",
      "'ly dreams,'   'y, present'   'r foes may'   'eard of hi'   ' many as y'\n",
      "'en dreams,'   'on present'   'r ever may'   'east of yo'   'cian, as I'\n",
      "'nd dreams,'   't, present'   's eyes do '   'part of hi'   ' son, as t'\n",
      "'as dream\\nS'   'in present'   's eye; tal'   'earn of yo'   ' long as I'\n",
      "\n",
      "'is presenc'   ' a prisone'   'g over mas'   'efit of se'   ' man: we s'\n",
      "'is prowess'   'ot prone t'   'l even tak'   'wist of ro'   ' wind as s'\n",
      "'is be all,'   'is project'   't so I may'   'e is of so'   ' man; all '\n",
      "'is the mad'   'my person.'   'n thou may'   'gent of hi'   ' man, they'\n",
      "\"'s great s\"   'ay prove.\\n'   'rosper may'   'ture of hu'   'tion, as f'\n",
      "'is deed do'   'by herself'   'e that may'   'ents of so'   ' her, as w'\n",
      "'is present'   'or prisone'   'speaks my '   'eral of yo'   ' maid is m'\n",
      "'rs dry; sc'   'be broken:'   'o not, may'   'mark of ot'   \" man, 'tis\"\n",
      "'ish reason'   'ay prove p'   'ounsel may'   'ents of yo'   ':\\nNo, as I'\n",
      "'py drinks,'   'ng prisone'   'n pity may'   'e is of go'   'sland as a'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "proj_sims, proj_distances = exp10.strings_with_topk_closest_proj_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.proj_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9948, 0.9967, 0.9947, 0.9974, 0.9956],\n",
       "         [0.9942, 0.9967, 0.9945, 0.9960, 0.9933],\n",
       "         [0.9937, 0.9964, 0.9921, 0.9958, 0.9897],\n",
       "         [0.9935, 0.9963, 0.9917, 0.9957, 0.9896],\n",
       "         [0.9928, 0.9962, 0.9910, 0.9956, 0.9871],\n",
       "         [0.9922, 0.9950, 0.9905, 0.9955, 0.9857],\n",
       "         [0.9911, 0.9944, 0.9900, 0.9954, 0.9856],\n",
       "         [0.9897, 0.9942, 0.9895, 0.9950, 0.9850],\n",
       "         [0.9891, 0.9939, 0.9894, 0.9943, 0.9846]]),\n",
       " tensor([[0.9709, 0.9826, 0.9796, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9825, 0.9795, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9824, 0.9794, 0.9854, 0.9726],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9823, 0.9793, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9853, 0.9724],\n",
       "         [0.9707, 0.9823, 0.9791, 0.9853, 0.9723],\n",
       "         [0.9707, 0.9823, 0.9790, 0.9853, 0.9723]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_distances[:10, :], proj_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'ly dreams,'   'my present'   'e case may'   'ster of ho'   ' men, as I'\n",
      "'en dreams,'   'dy present'   ' sense may'   'ffer to ha'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'ied as may'   'ruth of ho'   ' not, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'otes of ho'   'o me, as I'\n",
      "'nd dreams,'   'My present'   'r foes may'   'anes of ho'   'nd I, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'oint of ho'   'cian, as I'\n",
      "'of dreams,'   'in present'   ' haste may'   'yers of ho'   'I am, as t'\n",
      "\"n's beams,\"   'is present'   'odesty may'   'ains of ho'   '-day, as I'\n",
      "'hese arms,'   'im present'   'esence may'   'ound of ho'   '\\nAnd, as I'\n",
      "\n",
      "'sires most'   'ast ungent'   \"'s some am\"   'lf with ho'   ' be, was l'\n",
      "'teous mass'   'What scene'   'e they mad'   'tell of hi'   'Look, as I'\n",
      "'m to kiss,'   'lest scent'   ' am to say'   'Thus to ha'   'wick, as o'\n",
      "'much amiss'   'ondon sent'   ' early mad'   's of a tho'   'aith, as y'\n",
      "'wings misd'   'ng presenc'   'If you may'   'ven for ha'   'ut I was a'\n",
      "'from himse'   ' this sent'   'es the mai'   ' of our ho'   'y, is as a'\n",
      "'isdom hast'   'viest cens'   'et him say'   'tars of he'   'early as m'\n",
      "'hat seems '   'ou dissent'   'lords, may'   's other ho'   ' Yet, as t'\n",
      "'er bosoms!'   'tion spend'   'o them say'   'now the ho'   ' duke as I'\n",
      "' so, himse'   'have spent'   'nd now may'   'keep at ho'   's low as t'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "ffwd_sims, ffwd_distances = exp10.strings_with_topk_closest_ffwd_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.ffwd_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9998, 0.9999, 0.9997, 0.9998, 0.9999],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9995, 0.9998, 0.9997],\n",
       "         [0.9997, 0.9998, 0.9995, 0.9998, 0.9996],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994]]),\n",
       " tensor([[0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_distances[:10, :], ffwd_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'en dreams,'   'my present'   ' sense may'   'ster of ho'   ' men, as I'\n",
      "'ly dreams,'   'dy present'   'e case may'   'otes of ho'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'r foes may'   'anes of ho'   ' not, as I'\n",
      "'nd dreams,'   'My present'   'ied as may'   'ains of ho'   'o me, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'oint of ho'   'nd I, as I'\n",
      "'of dreams,'   'y, present'   ' bones may'   'ound of ho'   '-day, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'fear to ho'   ' but, as I'\n",
      "'rate arms,'   'im present'   ' grace may'   'ally of ho'   'rd me as I'\n",
      "'hese arms,'   'in present'   'e more may'   'yers of ho'   '\\nYes, as I'\n",
      "\n",
      "'ck groans,'   'll\\nPresent'   'en you say'   'ace our ho'   'r sakes, I'\n",
      "'te builds,'   's innocent'   'Hope I may'   'he that ho'   'early as I'\n",
      "'she finds,'   'me Florent'   'e must say'   'Half an ho'   'nes, and I'\n",
      "'reat loss,'   'their gent'   'n thou may'   'as mine ho'   'fe,--\\nAs I'\n",
      "'ld cramps,'   ', insolent'   'ctions may'   'When it ho'   ' see it, I'\n",
      "'he bleeds,'   'say I\\nsent'   'How he may'   '\\nIf so tho'   'ess woe, I'\n",
      "'our cross,'   'fore, gent'   'ame,\\nI say'   'us, the ho'   ' he does I'\n",
      "'han tears,'   'ldness ent'   'no way say'   'ale and ho'   'mad,--as I'\n",
      "'hese wars,'   'ch garment'   'e now, say'   'out any ho'   ' way can I'\n",
      "'to adders,'   'ic garment'   'ple,\\nI may'   'here\\nat ho'   'rant, an I'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the 500 Sample Strings, Can we Calculate Cosine Similarity to Every Other String?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilaritiesExperiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp: BatchedBlockInternalsExperiment,\n",
    "        output_folder: Path,\n",
    "    ):\n",
    "        self.exp = exp\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        self.n_batches = exp.n_batches\n",
    "\n",
    "    def embedding_sims_filename(self, batch_idx: int):\n",
    "        return self.output_folder / f'embedding_sims_{batch_idx:03d}.pt'\n",
    "\n",
    "    def proj_out_sims_filename(self, batch_idx: int, block_idx: int):\n",
    "        return self.output_folder / f'proj_out_sims_{batch_idx:03d}_{block_idx:02d}.pt'\n",
    "\n",
    "    def ffwd_out_sims_filename(self, batch_idx: int, block_idx: int):\n",
    "        return self.output_folder / f'ffwds_out_sims_{batch_idx:03d}_{block_idx:02d}.pt'\n",
    "\n",
    "    def generate_embedding_sims(self, chunk_size: int, queries: torch.Tensor, disable_progress_bar: bool = False):\n",
    "        n_chunks = exp10.batch_size // chunk_size\n",
    "\n",
    "        assert queries.dim() == 2\n",
    "        n_queries = queries.shape[0]\n",
    "\n",
    "        def sims_for_chunk(emb_batch: torch.Tensor, chunk_idx: int):\n",
    "            chunk = emb_batch[chunk_idx*chunk_size:(chunk_idx+1)*chunk_size, :, :]\n",
    "            actual_chunk_size = chunk.shape[0]\n",
    "            return F.cosine_similarity(\n",
    "                chunk.reshape(actual_chunk_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                queries,\n",
    "                dim=-1\n",
    "            )\n",
    "\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            emb_batch = torch.load(str(self.exp._embeddings_filename(batch_idx=batch_idx)), mmap=True)\n",
    "            sims = torch.cat([\n",
    "                sims_for_chunk(emb_batch, i)\n",
    "                for i in range(n_chunks)\n",
    "            ], dim=0)\n",
    "            torch.save(sims, str(self.embedding_sims_filename(batch_idx=batch_idx)))\n",
    "\n",
    "    def generate_proj_out_sims(self, get_queries: Callable[[int], torch.Tensor], disable_progress_bar=False):\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            for block_idx in range(n_layer):\n",
    "                queries = get_queries(block_idx)\n",
    "\n",
    "                assert queries.dim() == 2\n",
    "                n_queries = queries.shape[0]\n",
    "\n",
    "                proj_out_batch = torch.load(str(self.exp._proj_output_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True)\n",
    "                batch_size = proj_out_batch.shape[0]\n",
    "                sims = F.cosine_similarity(\n",
    "                    proj_out_batch[:, -1, :].reshape(batch_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                    queries,\n",
    "                    dim=-1\n",
    "                )\n",
    "                torch.save(sims, str(self.proj_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)))\n",
    "\n",
    "    def generate_ffwd_out_sims(self, get_queries: Callable[[int], torch.Tensor], disable_progress_bar=False):\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            for block_idx in range(n_layer):\n",
    "                queries = get_queries(block_idx)\n",
    "                assert queries.dim() == 2\n",
    "                n_queries = queries.shape[0]\n",
    "\n",
    "                ffwd_out_batch = torch.load(str(self.exp._ffwd_output_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True)\n",
    "                batch_size = ffwd_out_batch.shape[0]\n",
    "                sims = F.cosine_similarity(\n",
    "                    ffwd_out_batch[:, -1, :].reshape(batch_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                    queries,\n",
    "                    dim=-1\n",
    "                )\n",
    "                torch.save(sims, str(self.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by doing some analysis on the first 500 strings.\n",
    "output_folder = exp10.output_dir / 'cosine_sims_000'\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp = CosineSimilaritiesExperiment(exp10, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp.generate_embedding_sims(chunk_size=2000, queries=prompts_exp.embeddings.reshape(sample_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp.generate_proj_out_sims(get_queries=lambda block_idx: prompts_exp.proj_output(block_idx=block_idx)[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp.generate_ffwd_out_sims(get_queries=lambda block_idx: prompts_exp.ffwd_output(block_idx=block_idx)[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate cosine sims for ffwd output for the remaining 15000 strings\n",
    "n_all_strings = 20000\n",
    "sample_size = 500\n",
    "n_chunks = math.ceil(n_all_strings / sample_size)\n",
    "\n",
    "for sample_idx in tqdm(range(0, n_chunks)):\n",
    "    start_idx = sample_idx * sample_size\n",
    "    end_idx = min(start_idx + sample_size, n_all_strings)\n",
    "\n",
    "    strings = strings20k[start_idx:end_idx]\n",
    "\n",
    "    output_folder = exp10.output_dir / f'cosine_sims_{sample_idx:03d}'\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    exp = CosineSimilaritiesExperiment(exp10, output_folder)\n",
    "\n",
    "    sample_prompts_exp = BlockInternalsExperiment(encoding_helpers, accessors, strings)\n",
    "\n",
    "    exp.generate_ffwd_out_sims(\n",
    "        get_queries=lambda block_idx: sample_prompts_exp.ffwd_output(block_idx=block_idx)[:, -1, :],\n",
    "        disable_progress_bar=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, collect some stats about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_across_batches(\n",
    "    get_batch: Callable[[int], torch.Tensor],\n",
    "    n_batches: int,\n",
    "    n_queries: int,\n",
    "):\n",
    "    mins = torch.zeros(n_queries)\n",
    "    maxs = torch.zeros(n_queries)\n",
    "    means = torch.zeros(n_queries)\n",
    "    s = torch.zeros(n_queries)\n",
    "\n",
    "    total_count = 0\n",
    "    for i in range(n_batches):\n",
    "        batch = get_batch(i)\n",
    "        batch_size, n_queries_batch = batch.shape\n",
    "        assert n_queries_batch == n_queries\n",
    "\n",
    "        mins = torch.minimum(mins, batch.min(dim=0).values)\n",
    "        maxs = torch.maximum(maxs, batch.max(dim=0).values)\n",
    "\n",
    "        # Implement Chan, Golub, and LeVeque method\n",
    "        total_count += batch_size\n",
    "        delta = batch.mean(dim=0) - means\n",
    "        means += delta * batch_size / total_count\n",
    "        s += batch.var(dim=0) * (batch_size - 1) + delta**2 * batch_size * (total_count - batch_size) / total_count\n",
    "\n",
    "    vars = s / (total_count - 1)\n",
    "    stds = torch.sqrt(vars)\n",
    "    return mins, maxs, means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd_mins, ffwd_maxs, ffwd_means, ffwd_stds = zip(*[\n",
    "    stats_across_batches(\n",
    "        get_batch=lambda i: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=i, block_idx=block_idx))),\n",
    "        n_batches=cos_exp.n_batches,\n",
    "        n_queries=sample_size,\n",
    "    )\n",
    "    for block_idx in range(n_layer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 0: ffwd_out mean: 0.165 ± 0.029\n",
      "Block 1: ffwd_out mean: 0.095 ± 0.030\n",
      "Block 2: ffwd_out mean: 0.053 ± 0.024\n",
      "Block 3: ffwd_out mean: 0.057 ± 0.028\n",
      "Block 4: ffwd_out mean: 0.069 ± 0.047\n",
      "Block 5: ffwd_out mean: 0.090 ± 0.069\n"
     ]
    }
   ],
   "source": [
    "for block_idx in range(n_layer):\n",
    "    print(f\"Block {block_idx}: ffwd_out mean: {ffwd_means[block_idx].mean():.3f} ± {ffwd_means[block_idx].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 0: ffwd_out mean: 0.801 ± 0.092\n",
      "Block 1: ffwd_out mean: 0.365 ± 0.042\n",
      "Block 2: ffwd_out mean: 0.160 ± 0.033\n",
      "Block 3: ffwd_out mean: 0.072 ± 0.036\n",
      "Block 4: ffwd_out mean: 0.088 ± 0.059\n",
      "Block 5: ffwd_out mean: 0.133 ± 0.091\n"
     ]
    }
   ],
   "source": [
    "for block_idx in range(n_layer):\n",
    "    print(f\"Block {block_idx}: ffwd_out mean: {ffwd_means[block_idx].mean():.3f} ± {ffwd_means[block_idx].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_across_batches(\n",
    "    get_batch: Callable[[int], torch.Tensor],\n",
    "    n_batches: int,\n",
    "    filter_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    n_queries: int,\n",
    "):\n",
    "    total_count = 0\n",
    "    matching_indices = [[] for _ in range(n_queries)]\n",
    "    for i in range(n_batches):\n",
    "        batch = get_batch(i)\n",
    "        batch_size, n_queries_batch = batch.shape\n",
    "        assert n_queries_batch == n_queries\n",
    "\n",
    "        filtered = filter_fn(batch)\n",
    "        nonzeros = torch.nonzero(filtered)\n",
    "        for i in range(nonzeros.shape[0]):\n",
    "            idx_in_batch, query_idx = nonzeros[i, :]\n",
    "            matching_indices[query_idx.item()].append(total_count + idx_in_batch.item())\n",
    "\n",
    "        total_count += batch_size\n",
    "\n",
    "    return matching_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for filter_across_batches()\n",
    "\n",
    "batches = [\n",
    "    torch.tensor([\n",
    "        [0.0, 0.6, 0.4, 0.3],\n",
    "        [0.1, 0.3, 0.5, 0.1],\n",
    "        [0.0, 0.1, 0.8, 0.0],\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [0.7, 0.2, 0.6, 0.3],\n",
    "        [0.1, 0.8, 0.2, 0.8],\n",
    "    ]),\n",
    "]\n",
    "\n",
    "result = filter_across_batches(\n",
    "    get_batch=lambda i: batches[i],\n",
    "    n_batches=len(batches),\n",
    "    filter_fn=lambda batch: batch > 0.5,\n",
    "    n_queries=4,\n",
    ")\n",
    "test_eq(result, [\n",
    "    [3,],\n",
    "    [0, 4],\n",
    "    [2, 3],\n",
    "    [4],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_result_stats(\n",
    "    filter_results: List[List[int]],\n",
    "):\n",
    "    lens = [len(result) for result in filter_results]\n",
    "    return {\n",
    "        'min': min(lens),\n",
    "        'max': max(lens),\n",
    "        'mean': np.mean(lens),\n",
    "        'std': np.std(lens),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_strings(\n",
    "    filter_result: List[List[int]],\n",
    "    strings: Sequence[str],\n",
    "):\n",
    "    return [\n",
    "        [\n",
    "            strings[j]\n",
    "            for j in filter_result[i]\n",
    "        ]\n",
    "        for i in range(len(filter_result))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_map10 = build_next_token_map(ts.text, 10, tokenizer.vocab_size, tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this in a common component\n",
    "def analyze_simulate_results(sim_freqs, model_outputs):\n",
    "    assert len(sim_freqs) == len(model_outputs)\n",
    "    topn_matches = [0 for _ in range(10)]\n",
    "    topn_matches_any_order = [0 for _ in range(10)]\n",
    "    for i, sim_freq in enumerate(sim_freqs):\n",
    "        sim_output = top_nonzero_tokens(sim_freq, encoding_helpers.tokenizer.itos)[:10]\n",
    "        model_output = model_outputs[i]\n",
    "\n",
    "        sim_tokens, _ = zip(*sim_output)\n",
    "        model_tokens, _ = zip(*model_output)\n",
    "\n",
    "        n = min(len(sim_tokens), len(model_tokens))\n",
    "        for j in range(n):\n",
    "            if sim_tokens[j] == model_tokens[j]:\n",
    "                topn_matches[j] += 1\n",
    "            if set(sim_tokens[:j+1]) == set(model_tokens[:j+1]):\n",
    "                topn_matches_any_order[j] += 1\n",
    "\n",
    "    return topn_matches, topn_matches_any_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(\n",
    "    get_batch: Callable[[int], torch.Tensor],\n",
    "    n_batches: int,\n",
    "    filter_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    n_queries: int,\n",
    "    all_strings: Sequence[str],\n",
    "    next_token_map: Dict[str, torch.Tensor],\n",
    "    model_outputs: Sequence[Sequence[Tuple[str, float]]],\n",
    "):\n",
    "    filter_results = filter_across_batches(\n",
    "        get_batch=get_batch,\n",
    "        n_batches=n_batches,\n",
    "        filter_fn=filter_fn,\n",
    "        n_queries=n_queries,\n",
    "    )\n",
    "\n",
    "    print(filter_result_stats(filter_results))\n",
    "\n",
    "    filter_results_strings = get_matching_strings(filter_results, all_strings)\n",
    "    filter_result_freqs = [\n",
    "        torch.stack([\n",
    "            next_token_map[matching_string]\n",
    "            for matching_string in matching_strings\n",
    "        ]).sum(dim=0)\n",
    "        for matching_strings in filter_results_strings\n",
    "    ]\n",
    "\n",
    "    filter_result_probs = [\n",
    "        freqs / freqs.sum()\n",
    "        for freqs in filter_result_freqs\n",
    "    ]\n",
    "\n",
    "    topn_matches, topn_matches_any_order = analyze_simulate_results(filter_result_probs, model_outputs)\n",
    "    for i in range(10):\n",
    "        print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "        print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")\n",
    "\n",
    "    return filter_result_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 57024, 'mean': 5336.108, 'std': 11856.829263354348}\n",
      "Top 1 matches: 0.786\n",
      "Top 1 matches (any order): 0.786\n",
      "Top 2 matches: 0.448\n",
      "Top 2 matches (any order): 0.486\n",
      "Top 3 matches: 0.282\n",
      "Top 3 matches (any order): 0.338\n",
      "Top 4 matches: 0.188\n",
      "Top 4 matches (any order): 0.264\n",
      "Top 5 matches: 0.166\n",
      "Top 5 matches (any order): 0.192\n",
      "Top 6 matches: 0.142\n",
      "Top 6 matches (any order): 0.178\n",
      "Top 7 matches: 0.116\n",
      "Top 7 matches (any order): 0.128\n",
      "Top 8 matches: 0.108\n",
      "Top 8 matches (any order): 0.102\n",
      "Top 9 matches: 0.062\n",
      "Top 9 matches (any order): 0.086\n",
      "Top 10 matches: 0.052\n",
      "Top 10 matches (any order): 0.044\n"
     ]
    }
   ],
   "source": [
    "block_idx = 5\n",
    "ffwd5_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.86,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 12997, 'mean': 696.508, 'std': 1755.2617850155573}\n",
      "Top 1 matches: 0.800\n",
      "Top 1 matches (any order): 0.800\n",
      "Top 2 matches: 0.440\n",
      "Top 2 matches (any order): 0.494\n",
      "Top 3 matches: 0.272\n",
      "Top 3 matches (any order): 0.338\n",
      "Top 4 matches: 0.194\n",
      "Top 4 matches (any order): 0.236\n",
      "Top 5 matches: 0.162\n",
      "Top 5 matches (any order): 0.182\n",
      "Top 6 matches: 0.090\n",
      "Top 6 matches (any order): 0.130\n",
      "Top 7 matches: 0.074\n",
      "Top 7 matches (any order): 0.078\n",
      "Top 8 matches: 0.070\n",
      "Top 8 matches (any order): 0.064\n",
      "Top 9 matches: 0.054\n",
      "Top 9 matches (any order): 0.062\n",
      "Top 10 matches: 0.048\n",
      "Top 10 matches (any order): 0.054\n"
     ]
    }
   ],
   "source": [
    "block_idx = 4\n",
    "ffwd4_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.82,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 7598, 'mean': 473.594, 'std': 1144.8101122736468}\n",
      "Top 1 matches: 0.812\n",
      "Top 1 matches (any order): 0.812\n",
      "Top 2 matches: 0.470\n",
      "Top 2 matches (any order): 0.512\n",
      "Top 3 matches: 0.280\n",
      "Top 3 matches (any order): 0.366\n",
      "Top 4 matches: 0.206\n",
      "Top 4 matches (any order): 0.246\n",
      "Top 5 matches: 0.160\n",
      "Top 5 matches (any order): 0.194\n",
      "Top 6 matches: 0.130\n",
      "Top 6 matches (any order): 0.136\n",
      "Top 7 matches: 0.088\n",
      "Top 7 matches (any order): 0.080\n",
      "Top 8 matches: 0.062\n",
      "Top 8 matches (any order): 0.064\n",
      "Top 9 matches: 0.066\n",
      "Top 9 matches (any order): 0.076\n",
      "Top 10 matches: 0.056\n",
      "Top 10 matches (any order): 0.064\n"
     ]
    }
   ],
   "source": [
    "block_idx = 3\n",
    "ffwd3_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.80,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 5826, 'mean': 246.946, 'std': 670.6073121313248}\n",
      "Top 1 matches: 0.810\n",
      "Top 1 matches (any order): 0.810\n",
      "Top 2 matches: 0.466\n",
      "Top 2 matches (any order): 0.500\n",
      "Top 3 matches: 0.230\n",
      "Top 3 matches (any order): 0.276\n",
      "Top 4 matches: 0.174\n",
      "Top 4 matches (any order): 0.180\n",
      "Top 5 matches: 0.126\n",
      "Top 5 matches (any order): 0.164\n",
      "Top 6 matches: 0.100\n",
      "Top 6 matches (any order): 0.094\n",
      "Top 7 matches: 0.044\n",
      "Top 7 matches (any order): 0.058\n",
      "Top 8 matches: 0.078\n",
      "Top 8 matches (any order): 0.052\n",
      "Top 9 matches: 0.032\n",
      "Top 9 matches (any order): 0.056\n",
      "Top 10 matches: 0.046\n",
      "Top 10 matches (any order): 0.042\n"
     ]
    }
   ],
   "source": [
    "block_idx = 2\n",
    "ffwd2_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.92,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 5094, 'mean': 475.298, 'std': 823.7842880244804}\n",
      "Top 1 matches: 0.758\n",
      "Top 1 matches (any order): 0.758\n",
      "Top 2 matches: 0.428\n",
      "Top 2 matches (any order): 0.474\n",
      "Top 3 matches: 0.256\n",
      "Top 3 matches (any order): 0.358\n",
      "Top 4 matches: 0.192\n",
      "Top 4 matches (any order): 0.230\n",
      "Top 5 matches: 0.180\n",
      "Top 5 matches (any order): 0.200\n",
      "Top 6 matches: 0.116\n",
      "Top 6 matches (any order): 0.142\n",
      "Top 7 matches: 0.098\n",
      "Top 7 matches (any order): 0.104\n",
      "Top 8 matches: 0.076\n",
      "Top 8 matches (any order): 0.078\n",
      "Top 9 matches: 0.064\n",
      "Top 9 matches (any order): 0.076\n",
      "Top 10 matches: 0.062\n",
      "Top 10 matches (any order): 0.042\n"
     ]
    }
   ],
   "source": [
    "block_idx = 1\n",
    "ffwd1_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.95,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 5174, 'mean': 476.89, 'std': 769.571469000768}\n",
      "Top 1 matches: 0.734\n",
      "Top 1 matches (any order): 0.734\n",
      "Top 2 matches: 0.428\n",
      "Top 2 matches (any order): 0.466\n",
      "Top 3 matches: 0.262\n",
      "Top 3 matches (any order): 0.340\n",
      "Top 4 matches: 0.200\n",
      "Top 4 matches (any order): 0.230\n",
      "Top 5 matches: 0.164\n",
      "Top 5 matches (any order): 0.190\n",
      "Top 6 matches: 0.122\n",
      "Top 6 matches (any order): 0.144\n",
      "Top 7 matches: 0.096\n",
      "Top 7 matches (any order): 0.106\n",
      "Top 8 matches: 0.078\n",
      "Top 8 matches (any order): 0.078\n",
      "Top 9 matches: 0.052\n",
      "Top 9 matches (any order): 0.078\n",
      "Top 10 matches: 0.054\n",
      "Top 10 matches (any order): 0.048\n"
     ]
    }
   ],
   "source": [
    "block_idx = 0\n",
    "ffwd0_freqs = analyze_dataset(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.95,\n",
    "    n_queries=sample_size,\n",
    "    all_strings=exp10.strings,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.814\n",
      "Top 1 matches (any order): 0.814\n",
      "Top 2 matches: 0.514\n",
      "Top 2 matches (any order): 0.562\n",
      "Top 3 matches: 0.348\n",
      "Top 3 matches (any order): 0.402\n",
      "Top 4 matches: 0.250\n",
      "Top 4 matches (any order): 0.312\n",
      "Top 5 matches: 0.198\n",
      "Top 5 matches (any order): 0.234\n",
      "Top 6 matches: 0.160\n",
      "Top 6 matches (any order): 0.192\n",
      "Top 7 matches: 0.126\n",
      "Top 7 matches (any order): 0.136\n",
      "Top 8 matches: 0.118\n",
      "Top 8 matches (any order): 0.116\n",
      "Top 9 matches: 0.080\n",
      "Top 9 matches (any order): 0.096\n",
      "Top 10 matches: 0.082\n",
      "Top 10 matches (any order): 0.084\n"
     ]
    }
   ],
   "source": [
    "total_freqs = [\n",
    "    (\n",
    "        0.005*ffwd0_freqs[i] +\n",
    "        0.01*ffwd1_freqs[i] +\n",
    "        0.1*ffwd2_freqs[i] +\n",
    "        0.1*ffwd3_freqs[i] +\n",
    "        3*ffwd4_freqs[i] +\n",
    "        0.005*ffwd5_freq\n",
    "    )\n",
    "    for i, ffwd5_freq in enumerate(ffwd5_freqs)\n",
    "]\n",
    "total_probs = [\n",
    "    freqs / freqs.sum()\n",
    "    for freqs in total_freqs\n",
    "]\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs_sample)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate data from the rest of the strings (everything above just looked at first 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaefc7d0aad43aab9687394a3f8d48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_all_strings = 20000\n",
    "sample_size = 500\n",
    "n_chunks = math.ceil(n_all_strings / sample_size)\n",
    "\n",
    "next_token_map = next_token_map10\n",
    "all_strings = strings10\n",
    "\n",
    "ffwd_thresholds = [0.95, 0.95, 0.92, 0.80, 0.82, 0.86]\n",
    "ffwd_freqs = [[] for _ in range(n_layer)]\n",
    "model_outputs = []\n",
    "\n",
    "for sample_idx in tqdm(range(0, n_chunks)):\n",
    "    output_folder = exp10.output_dir / f\"cosine_sims_{sample_idx:03d}\"\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    exp = CosineSimilaritiesExperiment(exp10, output_folder)\n",
    "\n",
    "    start_idx = sample_idx * sample_size\n",
    "    end_idx = min(start_idx + sample_size, n_all_strings)\n",
    "\n",
    "    strings = strings20k[start_idx:end_idx]\n",
    "\n",
    "    model_outputs.extend(get_model_outputs(strings, encoding_helpers))\n",
    "\n",
    "    for block_idx in range(n_layer):\n",
    "        get_batch = lambda batch_idx: torch.load(\n",
    "            str(exp.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)),\n",
    "            mmap=True,\n",
    "        )\n",
    "\n",
    "        filter_results = filter_across_batches(\n",
    "            get_batch=get_batch,\n",
    "            n_batches=exp.n_batches,\n",
    "            filter_fn=lambda batch: batch > ffwd_thresholds[block_idx],\n",
    "            n_queries=sample_size,\n",
    "        )\n",
    "        filter_results_strings = get_matching_strings(filter_results, all_strings)\n",
    "        filter_result_freqs = [\n",
    "            torch.stack(\n",
    "                [\n",
    "                    next_token_map[matching_string]\n",
    "                    for matching_string in matching_strings\n",
    "                ]\n",
    "            ).sum(dim=0)\n",
    "            for matching_strings in filter_results_strings\n",
    "        ]\n",
    "        ffwd_freqs[block_idx].extend(filter_result_freqs)\n",
    "\n",
    "ffwd_freqs = torch.stack(\n",
    "    [torch.stack(ffwd_freqs[block_idx]) for block_idx in range(n_layer)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 20000, 65]), 20000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_freqs.shape, len(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(exp10.output_dir / 'learn_coefficients').mkdir(exist_ok=True)\n",
    "torch.save(ffwd_freqs, str(exp10.output_dir / 'learn_coefficients/ffwd_freqs.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.814\n",
      "Top 1 matches (any order): 0.814\n",
      "Top 2 matches: 0.514\n",
      "Top 2 matches (any order): 0.562\n",
      "Top 3 matches: 0.348\n",
      "Top 3 matches (any order): 0.402\n",
      "Top 4 matches: 0.250\n",
      "Top 4 matches (any order): 0.312\n",
      "Top 5 matches: 0.198\n",
      "Top 5 matches (any order): 0.234\n",
      "Top 6 matches: 0.160\n",
      "Top 6 matches (any order): 0.192\n",
      "Top 7 matches: 0.126\n",
      "Top 7 matches (any order): 0.136\n",
      "Top 8 matches: 0.118\n",
      "Top 8 matches (any order): 0.116\n",
      "Top 9 matches: 0.080\n",
      "Top 9 matches (any order): 0.096\n",
      "Top 10 matches: 0.082\n",
      "Top 10 matches (any order): 0.084\n"
     ]
    }
   ],
   "source": [
    "# Check that we still get the same results for the first 500\n",
    "hand_rolled_coeffs = torch.tensor([0.005, 0.01, 0.1, 0.1, 3, 0.005]) .unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs[:, :500, :] * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs[:500])\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.814\n",
      "Top 1 matches (any order): 0.814\n",
      "Top 2 matches: 0.498\n",
      "Top 2 matches (any order): 0.556\n",
      "Top 3 matches: 0.341\n",
      "Top 3 matches (any order): 0.412\n",
      "Top 4 matches: 0.271\n",
      "Top 4 matches (any order): 0.339\n",
      "Top 5 matches: 0.209\n",
      "Top 5 matches (any order): 0.257\n",
      "Top 6 matches: 0.178\n",
      "Top 6 matches (any order): 0.211\n",
      "Top 7 matches: 0.132\n",
      "Top 7 matches (any order): 0.153\n",
      "Top 8 matches: 0.112\n",
      "Top 8 matches (any order): 0.129\n",
      "Top 9 matches: 0.097\n",
      "Top 9 matches (any order): 0.107\n",
      "Top 10 matches: 0.063\n",
      "Top 10 matches (any order): 0.066\n"
     ]
    }
   ],
   "source": [
    "# Look at it for all samples\n",
    "hand_rolled_coeffs = torch.tensor([0.005, 0.01, 0.1, 0.1, 3, 0.005]) .unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can we tweak these hand-rolled coefficients for the full data set and get better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.814\n",
      "Top 1 matches (any order): 0.814\n",
      "Top 2 matches: 0.500\n",
      "Top 2 matches (any order): 0.562\n",
      "Top 3 matches: 0.346\n",
      "Top 3 matches (any order): 0.420\n",
      "Top 4 matches: 0.277\n",
      "Top 4 matches (any order): 0.345\n",
      "Top 5 matches: 0.210\n",
      "Top 5 matches (any order): 0.259\n",
      "Top 6 matches: 0.177\n",
      "Top 6 matches (any order): 0.210\n",
      "Top 7 matches: 0.133\n",
      "Top 7 matches (any order): 0.154\n",
      "Top 8 matches: 0.112\n",
      "Top 8 matches (any order): 0.129\n",
      "Top 9 matches: 0.099\n",
      "Top 9 matches (any order): 0.109\n",
      "Top 10 matches: 0.064\n",
      "Top 10 matches (any order): 0.068\n"
     ]
    }
   ],
   "source": [
    "hand_rolled_coeffs = torch.tensor([0.001, 0.01, 0.01, 0.9, 3, 0.05]) .unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best yet for the full data set, with hand-rolled coefficients. Let's see if we can learn better values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSim(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.coeffs = torch.nn.Parameter(\n",
    "            torch.randn(n_layer, 1, 1, dtype=torch.float32, requires_grad=True)\n",
    "        )\n",
    "        torch.nn.init.normal_(self.coeffs.data, mean=0.0, std=0.2)\n",
    "\n",
    "    def forward(self, freqs: torch.Tensor, model_output: Optional[torch.Tensor]=None):\n",
    "        total_freqs = (freqs * self.coeffs).sum(dim=0)\n",
    "        total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "        if model_output is not None:\n",
    "            loss = torch.norm(total_probs - model_output, dim=-1).sum()\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "\n",
    "        return total_probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: ModelSim, get_batch_func: GetBatchFunction, eval_iters: int=100\n",
    "):\n",
    "    out = {}\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch_func(split=split)\n",
    "\n",
    "            _, loss = model(X, Y)\n",
    "\n",
    "            losses[k] = loss.item()\n",
    "\n",
    "        out[split] = losses.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size: int, freqs: torch.Tensor, split: str='train', train_pct: float=0.9):\n",
    "    n = freqs.shape[1]\n",
    "    assert split in ['train', 'val']\n",
    "    n_train = int(n * train_pct)\n",
    "    low = 0 if split == 'train' else n_train\n",
    "    high = n_train if split == 'train' else n\n",
    "\n",
    "    batch_indices = torch.randint(low=low, high=high, size=(batch_size,), dtype=torch.long)\n",
    "    batch_strings = [strings20k[i.item()] for i in batch_indices]\n",
    "\n",
    "    tokens = encoding_helpers.tokenize_strings(batch_strings)\n",
    "    logits, _ = m(tokens)\n",
    "    model_output = F.softmax(logits[:, -1, :], dim=-1)\n",
    "\n",
    "    return freqs[:, batch_indices, :].clone(), model_output.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=500\n",
    "eval_iters = 100\n",
    "\n",
    "get_batch_func = partial(get_batch, batch_size=batch_size, freqs=ffwd_freqs, train_pct=0.9)\n",
    "estimate_loss_func = partial(estimate_loss, get_batch_func=get_batch_func, eval_iters=eval_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(1337) # Ensure stable random values\n",
    "m2 = ModelSim()\n",
    "_ = m2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = exp10.output_dir / 'learn_coefficients'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "checkpointer = CheckPointer(output_dir, 'coeff_model_checkpoint', start_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=m2,\n",
    "    checkpointer=checkpointer,\n",
    "    get_batch_func=get_batch_func,\n",
    "    estimate_loss_func=estimate_loss_func,\n",
    "    iters_trained=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(397.8691), 'val': tensor(419.5697)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a starting point for the loss\n",
    "estimate_loss_func(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a003ea35f3cb47c0912cebe627679a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 100.8659, val loss 100.7756\n",
      "step 999: train loss 98.1379, val loss 98.4768\n"
     ]
    }
   ],
   "source": [
    "# Start with a pretty high learning rate and go for 1000 iterations\n",
    "learning_rate = 3e-2\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer.train(1000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0683]],\n",
       "\n",
       "        [[0.1038]],\n",
       "\n",
       "        [[0.1724]],\n",
       "\n",
       "        [[0.0944]],\n",
       "\n",
       "        [[0.2360]],\n",
       "\n",
       "        [[0.1929]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.768\n",
      "Top 1 matches (any order): 0.768\n",
      "Top 2 matches: 0.458\n",
      "Top 2 matches (any order): 0.520\n",
      "Top 3 matches: 0.316\n",
      "Top 3 matches (any order): 0.381\n",
      "Top 4 matches: 0.256\n",
      "Top 4 matches (any order): 0.320\n",
      "Top 5 matches: 0.195\n",
      "Top 5 matches (any order): 0.235\n",
      "Top 6 matches: 0.169\n",
      "Top 6 matches (any order): 0.202\n",
      "Top 7 matches: 0.131\n",
      "Top 7 matches (any order): 0.149\n",
      "Top 8 matches: 0.111\n",
      "Top 8 matches (any order): 0.128\n",
      "Top 9 matches: 0.093\n",
      "Top 9 matches (any order): 0.102\n",
      "Top 10 matches: 0.059\n",
      "Top 10 matches (any order): 0.061\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for 1 round of training but we know there is a better solution. Let's try a few more rounds at this learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238e474215e1457cadc3c7939840a7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 86.7757, val loss 85.7378\n",
      "step 999: train loss 86.2982, val loss 85.2880\n"
     ]
    }
   ],
   "source": [
    "trainer.train(1000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0016]],\n",
       "\n",
       "        [[-0.0015]],\n",
       "\n",
       "        [[ 0.1099]],\n",
       "\n",
       "        [[ 0.0926]],\n",
       "\n",
       "        [[ 0.2220]],\n",
       "\n",
       "        [[ 0.1237]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.791\n",
      "Top 1 matches (any order): 0.791\n",
      "Top 2 matches: 0.479\n",
      "Top 2 matches (any order): 0.541\n",
      "Top 3 matches: 0.332\n",
      "Top 3 matches (any order): 0.397\n",
      "Top 4 matches: 0.264\n",
      "Top 4 matches (any order): 0.329\n",
      "Top 5 matches: 0.201\n",
      "Top 5 matches (any order): 0.244\n",
      "Top 6 matches: 0.171\n",
      "Top 6 matches (any order): 0.207\n",
      "Top 7 matches: 0.131\n",
      "Top 7 matches (any order): 0.151\n",
      "Top 8 matches: 0.110\n",
      "Top 8 matches (any order): 0.127\n",
      "Top 9 matches: 0.095\n",
      "Top 9 matches (any order): 0.102\n",
      "Top 10 matches: 0.059\n",
      "Top 10 matches (any order): 0.061\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still going down, so let's keep trying. Let it run more rounds and we can always backtrack if it overshoots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52cb016abc14a17ad2b4cf850b21f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 83.4608, val loss 82.6918\n",
      "step 999: train loss 101.8541, val loss 103.2045\n",
      "step 1499: train loss 102.3397, val loss 102.5408\n",
      "step 1999: train loss 102.3909, val loss 102.3771\n",
      "step 2499: train loss 101.9758, val loss 102.9581\n",
      "step 2999: train loss 102.1723, val loss 103.8465\n",
      "step 3499: train loss 102.7493, val loss 102.4819\n",
      "step 3999: train loss 101.7291, val loss 103.1296\n",
      "step 4499: train loss 102.1053, val loss 103.0395\n",
      "step 4999: train loss 101.2512, val loss 102.7032\n"
     ]
    }
   ],
   "source": [
    "trainer.train(5000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that clearly overshot. Let's go back to the good point and try a smaller learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, tensor(83.4608), tensor(82.6918))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpointer.output_dir / 'coeff_model_checkpoint_000004.pt')\n",
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are back at a good state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0034]],\n",
       "\n",
       "        [[-0.0006]],\n",
       "\n",
       "        [[ 0.0434]],\n",
       "\n",
       "        [[ 0.0864]],\n",
       "\n",
       "        [[ 0.2299]],\n",
       "\n",
       "        [[ 0.0290]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.803\n",
      "Top 1 matches (any order): 0.803\n",
      "Top 2 matches: 0.490\n",
      "Top 2 matches (any order): 0.552\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.410\n",
      "Top 4 matches: 0.272\n",
      "Top 4 matches (any order): 0.335\n",
      "Top 5 matches: 0.205\n",
      "Top 5 matches (any order): 0.254\n",
      "Top 6 matches: 0.178\n",
      "Top 6 matches (any order): 0.209\n",
      "Top 7 matches: 0.133\n",
      "Top 7 matches (any order): 0.154\n",
      "Top 8 matches: 0.114\n",
      "Top 8 matches (any order): 0.128\n",
      "Top 9 matches: 0.095\n",
      "Top 9 matches (any order): 0.103\n",
      "Top 10 matches: 0.060\n",
      "Top 10 matches (any order): 0.064\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad but we know we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd47bb6c83648bba1b910de3ad46b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 86.5964, val loss 85.8480\n",
      "step 999: train loss 85.6861, val loss 86.0898\n",
      "step 1499: train loss 86.2156, val loss 85.8741\n",
      "step 1999: train loss 86.1549, val loss 86.1937\n"
     ]
    }
   ],
   "source": [
    "# Reduce the learning rate by one order of magnitude\n",
    "learning_rate = 3e-3\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "trainer.train(2000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This got worse. Let's go back to the checkpoint and try an even smaller learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, tensor(83.4608), tensor(82.6918))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a57adc80f241e28767a46dff557000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 77.9547, val loss 76.8849\n",
      "step 999: train loss 81.7565, val loss 81.3437\n",
      "step 1499: train loss 81.5345, val loss 81.1168\n",
      "step 1999: train loss 81.3728, val loss 80.8595\n"
     ]
    }
   ],
   "source": [
    "# Go down one more order of magnitude\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "trainer.train(2000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That made some progress and then reverted. Let's go back to the checkpoint that was the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9500, tensor(77.9547), tensor(76.8849))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpointer.output_dir / 'coeff_model_checkpoint_000018.pt')\n",
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0018]],\n",
       "\n",
       "        [[-0.0005]],\n",
       "\n",
       "        [[-0.0024]],\n",
       "\n",
       "        [[ 0.0622]],\n",
       "\n",
       "        [[ 0.2803]],\n",
       "\n",
       "        [[ 0.0006]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.814\n",
      "Top 1 matches (any order): 0.814\n",
      "Top 2 matches: 0.499\n",
      "Top 2 matches (any order): 0.559\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.414\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.342\n",
      "Top 5 matches: 0.209\n",
      "Top 5 matches (any order): 0.258\n",
      "Top 6 matches: 0.178\n",
      "Top 6 matches (any order): 0.208\n",
      "Top 7 matches: 0.130\n",
      "Top 7 matches (any order): 0.151\n",
      "Top 8 matches: 0.110\n",
      "Top 8 matches (any order): 0.126\n",
      "Top 9 matches: 0.095\n",
      "Top 9 matches (any order): 0.106\n",
      "Top 10 matches: 0.062\n",
      "Top 10 matches (any order): 0.066\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not as good as the hand-rolled coefficients but very close. Let's try one final time with a smaller learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7356f6f3740c45f8a0814ee4650f6f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 77.4044, val loss 77.3757\n",
      "step 999: train loss 77.7672, val loss 76.8020\n",
      "step 1499: train loss 77.8616, val loss 76.1973\n",
      "step 1999: train loss 77.6942, val loss 76.3575\n"
     ]
    }
   ],
   "source": [
    "# Go down one more order of magnitude\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "trainer.train(2000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0014]],\n",
       "\n",
       "        [[-0.0006]],\n",
       "\n",
       "        [[-0.0019]],\n",
       "\n",
       "        [[ 0.0627]],\n",
       "\n",
       "        [[ 0.2819]],\n",
       "\n",
       "        [[ 0.0006]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.815\n",
      "Top 1 matches (any order): 0.815\n",
      "Top 2 matches: 0.499\n",
      "Top 2 matches (any order): 0.560\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.413\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.341\n",
      "Top 5 matches: 0.209\n",
      "Top 5 matches (any order): 0.257\n",
      "Top 6 matches: 0.177\n",
      "Top 6 matches (any order): 0.207\n",
      "Top 7 matches: 0.130\n",
      "Top 7 matches (any order): 0.150\n",
      "Top 8 matches: 0.109\n",
      "Top 8 matches (any order): 0.125\n",
      "Top 9 matches: 0.095\n",
      "Top 9 matches (any order): 0.106\n",
      "Top 10 matches: 0.061\n",
      "Top 10 matches (any order): 0.066\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very slightly better for top 1 but worse on everything else. I think this is the best it can do from here. What if we initialize with the hand-rolled weights and see if it can improve that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = ModelSim()\n",
    "m3.coeffs = torch.nn.Parameter(torch.tensor([0.001, 0.01, 0.01, 0.9, 3, 0.05]).unsqueeze(dim=1).unsqueeze(dim=2))\n",
    "m3.coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = exp10.output_dir / 'learn_coefficients'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "checkpointer = CheckPointer(output_dir, 'coeff_model_hand_rolled_checkpoint', start_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=m3,\n",
    "    checkpointer=checkpointer,\n",
    "    get_batch_func=get_batch_func,\n",
    "    estimate_loss_func=estimate_loss_func,\n",
    "    iters_trained=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(79.1921), 'val': tensor(77.6637)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a starting point for the loss\n",
    "estimate_loss_func(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a96b2dae9bc4b0488df96de9b0e9026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 77.9316, val loss 76.6000\n",
      "step 999: train loss 78.6018, val loss 77.1291\n"
     ]
    }
   ],
   "source": [
    "# Begin with a moderate learning rate\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.AdamW(m3.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer.train(1000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It got slightly better then slightly worse. Let's go back to the first checkpoint of this training run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, tensor(77.9316), tensor(76.6000))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpointer.output_dir / 'coeff_model_hand_rolled_checkpoint_000000.pt')\n",
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0184]],\n",
       "\n",
       "        [[-0.0071]],\n",
       "\n",
       "        [[-0.0237]],\n",
       "\n",
       "        [[ 0.8463]],\n",
       "\n",
       "        [[ 3.0463]],\n",
       "\n",
       "        [[ 0.0057]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.815\n",
      "Top 1 matches (any order): 0.815\n",
      "Top 2 matches: 0.499\n",
      "Top 2 matches (any order): 0.559\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.414\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.341\n",
      "Top 5 matches: 0.210\n",
      "Top 5 matches (any order): 0.258\n",
      "Top 6 matches: 0.178\n",
      "Top 6 matches (any order): 0.207\n",
      "Top 7 matches: 0.131\n",
      "Top 7 matches (any order): 0.150\n",
      "Top 8 matches: 0.109\n",
      "Top 8 matches (any order): 0.125\n",
      "Top 9 matches: 0.095\n",
      "Top 9 matches (any order): 0.106\n",
      "Top 10 matches: 0.062\n",
      "Top 10 matches (any order): 0.066\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m3(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar to what the model got to from random initialization. Let's try one more time with a smaller learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504632e5d1014b6686c450b36f10309b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 77.8812, val loss 76.5227\n",
      "step 999: train loss 77.9839, val loss 76.7161\n",
      "step 1499: train loss 78.1107, val loss 77.1959\n",
      "step 1999: train loss 77.7038, val loss 76.5574\n",
      "step 2499: train loss 77.8688, val loss 76.9922\n",
      "step 2999: train loss 78.2711, val loss 76.3786\n",
      "step 3499: train loss 78.3931, val loss 76.5468\n",
      "step 3999: train loss 77.9371, val loss 76.7095\n",
      "step 4499: train loss 77.7700, val loss 76.4692\n",
      "step 4999: train loss 78.1189, val loss 77.1611\n",
      "step 5499: train loss 77.3637, val loss 76.8556\n",
      "step 5999: train loss 78.4040, val loss 76.5145\n",
      "step 6499: train loss 77.7374, val loss 76.2394\n",
      "step 6999: train loss 77.5930, val loss 76.9928\n",
      "step 7499: train loss 78.1478, val loss 76.7629\n",
      "step 7999: train loss 77.6600, val loss 76.6683\n",
      "step 8499: train loss 77.6980, val loss 76.7173\n",
      "step 8999: train loss 78.3584, val loss 76.5446\n",
      "step 9499: train loss 78.1036, val loss 76.6569\n",
      "step 9999: train loss 78.4474, val loss 76.7377\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(m3.parameters(), lr=learning_rate)\n",
    "\n",
    "# Give it a lot more time to run\n",
    "trainer.train(10000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0178]],\n",
       "\n",
       "        [[-0.0051]],\n",
       "\n",
       "        [[-0.0226]],\n",
       "\n",
       "        [[ 0.7633]],\n",
       "\n",
       "        [[ 3.1019]],\n",
       "\n",
       "        [[ 0.0050]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.814\n",
      "Top 1 matches (any order): 0.814\n",
      "Top 2 matches: 0.498\n",
      "Top 2 matches (any order): 0.559\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.414\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.341\n",
      "Top 5 matches: 0.210\n",
      "Top 5 matches (any order): 0.258\n",
      "Top 6 matches: 0.178\n",
      "Top 6 matches (any order): 0.208\n",
      "Top 7 matches: 0.130\n",
      "Top 7 matches (any order): 0.151\n",
      "Top 8 matches: 0.110\n",
      "Top 8 matches (any order): 0.125\n",
      "Top 9 matches: 0.095\n",
      "Top 9 matches (any order): 0.106\n",
      "Top 10 matches: 0.063\n",
      "Top 10 matches (any order): 0.066\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m3(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very slightly worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Sims for Length 256 Strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings256 = all_unique_substrings(ts.text, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "sample_size = 500\n",
    "indices256 = torch.randperm(len(strings256))[:sample_size]\n",
    "strings256_sample = [strings256[i.item()] for i in indices256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs_sample256 = get_model_outputs(strings256_sample, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_exp256 = BlockInternalsExperiment(encoding_helpers, accessors, strings256_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilaritiesForFinalFFWDExperiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp: FinalFFWDExperiment,\n",
    "        output_folder: Path,\n",
    "    ):\n",
    "        self.exp = exp\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        self.n_batches = exp.n_batches\n",
    "\n",
    "    def ffwd_out_sims_filename(self, batch_idx: int, block_idx: int):\n",
    "        return self.output_folder / f'ffwds_out_sims_{batch_idx:04d}_{block_idx:02d}.pt'\n",
    "\n",
    "    def generate_ffwd_out_sims(self, get_queries: Callable[[int], torch.Tensor], disable_progress_bar=False):\n",
    "        block_idx = n_layer - 1\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            queries = get_queries(block_idx)\n",
    "            assert queries.dim() == 2\n",
    "            n_queries = queries.shape[0]\n",
    "\n",
    "            ffwd_out_batch = torch.load(str(self.exp._ffwd_output_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True)\n",
    "            batch_size = ffwd_out_batch.shape[0]\n",
    "            sims = F.cosine_similarity(\n",
    "                ffwd_out_batch.reshape(batch_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                queries,\n",
    "                dim=-1\n",
    "            )\n",
    "            torch.save(sims, str(self.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd_exp256 = FinalFFWDExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings256,\n",
    "    output_dir=Path('../artifacts/block_internals_results/large_files/slen256'),\n",
    "    batch_size=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ffwd_exp256.output_dir / 'cosine_sims'\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp256 = CosineSimilaritiesForFinalFFWDExperiment(ffwd_exp256, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa11ce5d335947219d9e20bb0294dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos_exp256.generate_ffwd_out_sims(get_queries=lambda block_idx: prompts_exp256.ffwd_output(block_idx=block_idx)[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_map256 = build_next_token_map(ts.text, 256, tokenizer.vocab_size, tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 1, 'max': 38780, 'mean': 1561.9, 'std': 4162.8430373964375}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_idx = n_layer - 1\n",
    "ffwd256 = filter_across_batches(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp256.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp256.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.91,\n",
    "    n_queries=sample_size,\n",
    ")\n",
    "filter_result_stats(ffwd256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd256_strings = get_matching_strings(ffwd256, strings256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd256_freqs = [\n",
    "    torch.stack([\n",
    "        next_token_map256[matching_string]\n",
    "        for matching_string in matching_strings\n",
    "    ]).sum(dim=0)\n",
    "    for matching_strings in ffwd256_strings\n",
    "]\n",
    "ffwd256_probs = [\n",
    "    freqs / freqs.sum()\n",
    "    for freqs in ffwd256_freqs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.802\n",
      "Top 1 matches (any order): 0.802\n",
      "Top 2 matches: 0.362\n",
      "Top 2 matches (any order): 0.412\n",
      "Top 3 matches: 0.246\n",
      "Top 3 matches (any order): 0.298\n",
      "Top 4 matches: 0.200\n",
      "Top 4 matches (any order): 0.250\n",
      "Top 5 matches: 0.156\n",
      "Top 5 matches (any order): 0.154\n",
      "Top 6 matches: 0.128\n",
      "Top 6 matches (any order): 0.148\n",
      "Top 7 matches: 0.070\n",
      "Top 7 matches (any order): 0.086\n",
      "Top 8 matches: 0.044\n",
      "Top 8 matches (any order): 0.068\n",
      "Top 9 matches: 0.032\n",
      "Top 9 matches (any order): 0.038\n",
      "Top 10 matches: 0.030\n",
      "Top 10 matches (any order): 0.016\n"
     ]
    }
   ],
   "source": [
    "topn_matches, topn_matches_any_order = analyze_simulate_results(ffwd256_probs, model_outputs_sample256)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 (\" see my shame in him.\\nThou art a widow; yet thou art a mother,\\nAnd hast the comfort of thy children left thee:\\nBut death hath snatch'd my husband from mine arms,\\nAnd pluck'd two crutches from my feeble limbs,\\nEdward and Clarence. O, what cause have I,\\nThin\"): \n",
      "  \" so.\\n\\nSICINIUS:\\nLet them assemble,\\nAnd on a safer judgment all revoke\\nYour ignorant election; enforce his pride,\\nAnd his old hate unto you; besides, forget not\\nWith what contempt he wore the humble weed,\\nHow in his suit he scorn'd you; but your loves,\\nThin\"\n",
      "  \"I'ld have beaten him like a dog, but for\\ndisturbing the lords within.\\n\\nAUFIDIUS:\\nWhence comest thou? what wouldst thou? thy name?\\nWhy speak'st not? speak, man: what's thy name?\\n\\nCORIOLANUS:\\nIf, Tullus,\\nNot yet thou knowest me, and, seeing me, dost not\\nThin\"\n",
      "  \"e not--to save my life, for if\\nI had fear'd death, of all the men i' the world\\nI would have 'voided thee, but in mere spite,\\nTo be full quit of those my banishers,\\nStand I before thee here. Then if thou hast\\nA heart of wreak in thee, that wilt revenge\\nThin\"\n",
      "  \"t,\\nwhich should\\nMake our eyes flow with joy, hearts dance\\nwith comforts,\\nConstrains them weep and shake with fear and sorrow;\\nMaking the mother, wife and child to see\\nThe son, the husband and the father tearing\\nHis country's bowels out. And to poor we\\nThin\"\n",
      "  \" abhorr'd.' Speak to me, son:\\nThou hast affected the fine strains of honour,\\nTo imitate the graces of the gods;\\nTo tear with thunder the wide cheeks o' the air,\\nAnd yet to charge thy sulphur with a bolt\\nThat should but rive an oak. Why dost not speak?\\nThin\"\n",
      "  \"d me, in the field by Tewksbury\\nWhen Oxford had me down, he rescued me,\\nAnd said, 'Dear brother, live, and be a king'?\\nWho told me, when we both lay in the field\\nFrozen almost to death, how he did lap me\\nEven in his own garments, and gave himself,\\nAll thin\"\n",
      "  \" see my shame in him.\\nThou art a widow; yet thou art a mother,\\nAnd hast the comfort of thy children left thee:\\nBut death hath snatch'd my husband from mine arms,\\nAnd pluck'd two crutches from my feeble limbs,\\nEdward and Clarence. O, what cause have I,\\nThin\"\n",
      "  \" uncle Clarence' angry ghost:\\nMy grandam told me he was murdered there.\\n\\nPRINCE EDWARD:\\nI fear no uncles dead.\\n\\nGLOUCESTER:\\nNor none that live, I hope.\\n\\nPRINCE EDWARD:\\nAn if they live, I hope I need not fear.\\nBut come, my lord; and with a heavy heart,\\nThin\"\n",
      "  \"ard, capable\\nHe is all the mother's, from the top to toe.\\n\\nBUCKINGHAM:\\nWell, let them rest. Come hither, Catesby.\\nThou art sworn as deeply to effect what we intend\\nAs closely to conceal what we impart:\\nThou know'st our reasons urged upon the way;\\nWhat thin\"\n",
      "  \"ng that yet think not on it.\\n\\nCATESBY:\\n'Tis a vile thing to die, my gracious lord,\\nWhen men are unprepared and look not for it.\\n\\nHASTINGS:\\nO monstrous, monstrous! and so falls it out\\nWith Rivers, Vaughan, Grey: and so 'twill do\\nWith some men else, who thin\"\n",
      "  \"od morrow; good morrow, Catesby:\\nYou may jest on, but, by the holy rood,\\nI do not like these several councils, I.\\n\\nHASTINGS:\\nMy lord,\\nI hold my life as dear as you do yours;\\nAnd never in my life, I do protest,\\nWas it more precious to me than 'tis now:\\nThin\"\n",
      "  \"fitting for that royal time?\\n\\nDERBY:\\nIt is, and wants but nomination.\\n\\nBISHOP OF ELY:\\nTo-morrow, then, I judge a happy day.\\n\\nBUCKINGHAM:\\nWho knows the lord protector's mind herein?\\nWho is most inward with the royal duke?\\n\\nBISHOP OF ELY:\\nYour grace, we thin\"\n",
      "  \"e English woes will make me smile in France.\\n\\nQUEEN ELIZABETH:\\nO thou well skill'd in curses, stay awhile,\\nAnd teach me how to curse mine enemies!\\n\\nQUEEN MARGARET:\\nForbear to sleep the nights, and fast the days;\\nCompare dead happiness with living woe;\\nThin\"\n",
      "  'thy daughter,\\nAnd mean to make her queen of England.\\n\\nQUEEN ELIZABETH:\\nSay then, who dost thou mean shall be her king?\\n\\nKING RICHARD III:\\nEven he that makes her queen who should be else?\\n\\nQUEEN ELIZABETH:\\nWhat, thou?\\n\\nKING RICHARD III:\\nI, even I: what thin'\n",
      "  \"w near,\\nAnd list what with our council we have done.\\nFor that our kingdom's earth should not be soil'd\\nWith that dear blood which it hath fostered;\\nAnd for our eyes do hate the dire aspect\\nOf civil wounds plough'd up with neighbours' sword;\\nAnd for we thin\"\n",
      "  'd,\\nHaving my freedom, boast of nothing else\\nBut that I was a journeyman to grief?\\n\\nJOHN OF GAUNT:\\nAll places that the eye of heaven visits\\nAre to a wise man ports and happy havens.\\nTeach thy necessity to reason thus;\\nThere is no virtue like necessity.\\nThin'\n",
      "  \"eys-general to sue\\nHis livery, and deny his offer'd homage,\\nYou pluck a thousand dangers on your head,\\nYou lose a thousand well-disposed hearts\\nAnd prick my tender patience, to those thoughts\\nWhich honour and allegiance cannot think.\\n\\nKING RICHARD II:\\nThin\"\n",
      "  \"their complices,\\nThe caterpillars of the commonwealth,\\nWhich I have sworn to weed and pluck away.\\n\\nDUKE OF YORK:\\nIt may be I will go with you: but yet I'll pause;\\nFor I am loath to break our country's laws.\\nNor friends nor foes, to me welcome you are:\\nThin\"\n",
      "  \"ee to France\\nAnd cloister thee in some religious house:\\nOur holy lives must win a new world's crown,\\nWhich our profane hours here have stricken down.\\n\\nQUEEN:\\nWhat, is my Richard both in shape and mind\\nTransform'd and weaken'd? hath Bolingbroke deposed\\nThin\"\n",
      "  'ildly, kiss the rod,\\nAnd fawn on rage with base humility,\\nWhich art a lion and a king of beasts?\\n\\nKING RICHARD II:\\nA king of beasts, indeed; if aught but beasts,\\nI had been still a happy king of men.\\nGood sometime queen, prepare thee hence for France:\\nThin'\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(f\"Query {idx} ({repr(strings256_sample[idx])}): \")\n",
    "result = ffwd256[idx]\n",
    "for j in result[:20]:\n",
    "    print(f\"  {repr(strings256[j])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorBatchIterator:\n",
    "    def __init__(self, n_batches: int, get_batch: Callable[[int], torch.Tensor]):\n",
    "        self.n_batches = n_batches\n",
    "        self.get_batch = get_batch\n",
    "\n",
    "        self.next_batch_idx = 0\n",
    "        self.current_batch: Optional[torch.Tensor] = None\n",
    "        self.idx_within_batch = 0\n",
    "\n",
    "        self._load_next_batch()\n",
    "\n",
    "    def _load_next_batch(self):\n",
    "        if self.next_batch_idx >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "\n",
    "        self.current_batch = self.get_batch(self.next_batch_idx)\n",
    "        self.idx_within_batch = 0\n",
    "        self.next_batch_idx += 1\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch is None:\n",
    "            raise StopIteration()\n",
    "\n",
    "        if self.idx_within_batch >= self.current_batch.shape[0]:\n",
    "            self._load_next_batch()\n",
    "            if self.current_batch is None:\n",
    "                raise StopIteration()\n",
    "\n",
    "        result = self.current_batch[self.idx_within_batch, :]\n",
    "        self.idx_within_batch += 1\n",
    "        return result\n",
    "\n",
    "class EmbeddingCosineSims:\n",
    "    def __init__(self, exp: CosineSimilaritiesExperiment):\n",
    "        self.exp = exp\n",
    "\n",
    "    def __iter__(self):\n",
    "        return TensorBatchIterator(\n",
    "            n_batches=self.exp.n_batches,\n",
    "            get_batch=lambda batch_idx: torch.load(str(self.exp.embedding_sims_filename(batch_idx=batch_idx)), mmap=True)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sims = EmbeddingCosineSims(cos_exp)\n",
    "for i, sim in enumerate(emb_sims):\n",
    "    print(i, sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = next(iter(emb_sims))\n",
    "sims.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
