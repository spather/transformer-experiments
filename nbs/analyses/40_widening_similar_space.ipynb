{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widening the Space of Similar Values\n",
    "\n",
    "> A major finding was that the current approaches are considering values that are too similar. This notebook investigates ways to search a wider space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Iterable, Protocol, Sequence, Tuple, TypeVar, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from transformer_experiments.common.substring_generator import all_unique_substrings\n",
    "from transformer_experiments.common.text_analysis import (\n",
    "    build_next_token_map,\n",
    "    SubstringFrequencyAnalysis,\n",
    "    top_nonzero_tokens\n",
    ")\n",
    "from transformer_experiments.common.utils import (\n",
    "    aggregate_by_string_key,\n",
    "    DataWrapper,\n",
    "    topk_across_batches,\n",
    ")\n",
    "from transformer_experiments.dataset_split import split_text_dataset\n",
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import (\n",
    "    n_embed,\n",
    "    n_layer,\n",
    "    TransformerLanguageModel\n",
    ")\n",
    "from transformer_experiments.models.transformer_helpers import (\n",
    "    unsqueeze_emb,\n",
    "    EncodingHelpers,\n",
    "    LogitsWrapper,\n",
    "    TransformerAccessors\n",
    ")\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer\n",
    ")\n",
    "from transformer_experiments.experiments.block_internals import (\n",
    "    BlockInternalsAccessors,\n",
    "    BlockInternalsExperiment,\n",
    "    BatchedBlockInternalsExperiment,\n",
    "    BlockInternalsAnalysis,\n",
    "    batch_cosine_sim,\n",
    ")\n",
    "from transformer_experiments.experiments.similar_strings import (\n",
    "    SimilarStringsData,\n",
    "    SimilarStringsExperiment,\n",
    "    SimilarStringsResult\n",
    ")\n",
    "from transformer_experiments.experiments.logit_lens import LogitLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ts = TinyShakespeareDataSet(cache_file='../artifacts/input.txt')\n",
    "m, tokenizer = create_model_and_tokenizer(\n",
    "    saved_model_filename='../artifacts/shakespeare.pt',\n",
    "    dataset=ts,\n",
    "    device=device,\n",
    ")\n",
    "_, val_data = split_text_dataset(ts.text, tokenizer, train_pct=0.9)\n",
    "encoding_helpers = EncodingHelpers(tokenizer, device)\n",
    "accessors = TransformerAccessors(m, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list(Path('../artifacts/block_internals_results/large_files/slen10/').glob('*')) == []:\n",
    "    print(\"Run `make block_internals_slen10_dataset` in the project root to generate the required dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings10 = all_unique_substrings(ts.text, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp10 = BatchedBlockInternalsExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings10,\n",
    "    output_dir=Path('../artifacts/block_internals_results/large_files/slen10/'),\n",
    "    batch_size=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "n_samples = 20000\n",
    "indices = torch.randperm(len(strings10))[:n_samples]\n",
    "strings20k = [strings10[i.item()] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of 500 strings\n",
    "sample_size = 500\n",
    "strings_sample = strings20k[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_exp = BlockInternalsExperiment(encoding_helpers, accessors, strings_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by examining what we get when we ask for a much larger top k values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sims, emb_distances = exp10.strings_with_topk_closest_embeddings(\n",
    "    prompts_exp.embeddings[:5, :, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9062, 0.9470, 0.9045, 0.9493, 0.9544],\n",
       "         [0.9062, 0.9462, 0.8602, 0.9083, 0.9443],\n",
       "         [0.9053, 0.9429, 0.8593, 0.9082, 0.9064],\n",
       "         [0.9037, 0.9429, 0.8586, 0.9055, 0.9057],\n",
       "         [0.9027, 0.9404, 0.8566, 0.9052, 0.9045],\n",
       "         [0.9020, 0.9027, 0.8562, 0.9044, 0.8996],\n",
       "         [0.9017, 0.9009, 0.8548, 0.9035, 0.8982],\n",
       "         [0.8962, 0.9009, 0.8545, 0.9034, 0.8656],\n",
       "         [0.8651, 0.9008, 0.8532, 0.9032, 0.8631]]),\n",
       " tensor([[0.7591, 0.7566, 0.7604, 0.8064, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7604, 0.8063, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7603, 0.8063, 0.8042],\n",
       "         [0.7590, 0.7564, 0.7602, 0.8063, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8062, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8061, 0.8040],\n",
       "         [0.7588, 0.7557, 0.7601, 0.8061, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7600, 0.8060, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8038],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8037]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_distances[:10, :], emb_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'is dream o'   'My present'   's eye, mak'   'eart of mo'   ' men, as I'\n",
      "'ur dreams,'   'be present'   's eyes in '   'earn of hi'   ' man, as y'\n",
      "'of dreams,'   'dy present'   'l eyes can'   'ears of ha'   ' man, if I'\n",
      "'us dreams.'   'my present'   's eyes to '   'park of ho'   'oman, as t'\n",
      "'he dreams,'   'ry present'   'l eyes gaz'   'eart of ge'   ' men, as i'\n",
      "'ly dreams,'   'y, present'   'r foes may'   'eard of hi'   ' many as y'\n",
      "'en dreams,'   'on present'   'r ever may'   'east of yo'   'cian, as I'\n",
      "'nd dreams,'   't, present'   's eyes do '   'part of hi'   ' son, as t'\n",
      "'as dream\\nS'   'in present'   's eye; tal'   'earn of yo'   ' long as I'\n",
      "\n",
      "'is presenc'   ' a prisone'   'g over mas'   'efit of se'   ' man: we s'\n",
      "'is prowess'   'ot prone t'   'l even tak'   'wist of ro'   ' wind as s'\n",
      "'is be all,'   'is project'   't so I may'   'e is of so'   ' man; all '\n",
      "'is the mad'   'my person.'   'n thou may'   'gent of hi'   ' man, they'\n",
      "\"'s great s\"   'ay prove.\\n'   'rosper may'   'ture of hu'   'tion, as f'\n",
      "'is deed do'   'by herself'   'e that may'   'ents of so'   ' her, as w'\n",
      "'is present'   'or prisone'   'speaks my '   'eral of yo'   ' maid is m'\n",
      "'rs dry; sc'   'be broken:'   'o not, may'   'mark of ot'   \" man, 'tis\"\n",
      "'ish reason'   'ay prove p'   'ounsel may'   'ents of yo'   ':\\nNo, as I'\n",
      "'py drinks,'   'ng prisone'   'n pity may'   'e is of go'   'sland as a'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "proj_sims, proj_distances = exp10.strings_with_topk_closest_proj_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.proj_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9948, 0.9967, 0.9947, 0.9974, 0.9956],\n",
       "         [0.9942, 0.9967, 0.9945, 0.9960, 0.9933],\n",
       "         [0.9937, 0.9964, 0.9921, 0.9958, 0.9897],\n",
       "         [0.9935, 0.9963, 0.9917, 0.9957, 0.9896],\n",
       "         [0.9928, 0.9962, 0.9910, 0.9956, 0.9871],\n",
       "         [0.9922, 0.9950, 0.9905, 0.9955, 0.9857],\n",
       "         [0.9911, 0.9944, 0.9900, 0.9954, 0.9856],\n",
       "         [0.9897, 0.9942, 0.9895, 0.9950, 0.9850],\n",
       "         [0.9891, 0.9939, 0.9894, 0.9943, 0.9846]]),\n",
       " tensor([[0.9709, 0.9826, 0.9796, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9825, 0.9795, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9824, 0.9794, 0.9854, 0.9726],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9823, 0.9793, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9853, 0.9724],\n",
       "         [0.9707, 0.9823, 0.9791, 0.9853, 0.9723],\n",
       "         [0.9707, 0.9823, 0.9790, 0.9853, 0.9723]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_distances[:10, :], proj_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'ly dreams,'   'my present'   'e case may'   'ster of ho'   ' men, as I'\n",
      "'en dreams,'   'dy present'   ' sense may'   'ffer to ha'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'ied as may'   'ruth of ho'   ' not, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'otes of ho'   'o me, as I'\n",
      "'nd dreams,'   'My present'   'r foes may'   'anes of ho'   'nd I, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'oint of ho'   'cian, as I'\n",
      "'of dreams,'   'in present'   ' haste may'   'yers of ho'   'I am, as t'\n",
      "\"n's beams,\"   'is present'   'odesty may'   'ains of ho'   '-day, as I'\n",
      "'hese arms,'   'im present'   'esence may'   'ound of ho'   '\\nAnd, as I'\n",
      "\n",
      "'sires most'   'ast ungent'   \"'s some am\"   'lf with ho'   ' be, was l'\n",
      "'teous mass'   'What scene'   'e they mad'   'tell of hi'   'Look, as I'\n",
      "'m to kiss,'   'lest scent'   ' am to say'   'Thus to ha'   'wick, as o'\n",
      "'much amiss'   'ondon sent'   ' early mad'   's of a tho'   'aith, as y'\n",
      "'wings misd'   'ng presenc'   'If you may'   'ven for ha'   'ut I was a'\n",
      "'from himse'   ' this sent'   'es the mai'   ' of our ho'   'y, is as a'\n",
      "'isdom hast'   'viest cens'   'et him say'   'tars of he'   'early as m'\n",
      "'hat seems '   'ou dissent'   'lords, may'   's other ho'   ' Yet, as t'\n",
      "'er bosoms!'   'tion spend'   'o them say'   'now the ho'   ' duke as I'\n",
      "' so, himse'   'have spent'   'nd now may'   'keep at ho'   's low as t'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "ffwd_sims, ffwd_distances = exp10.strings_with_topk_closest_ffwd_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.ffwd_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9998, 0.9999, 0.9997, 0.9998, 0.9999],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9995, 0.9998, 0.9997],\n",
       "         [0.9997, 0.9998, 0.9995, 0.9998, 0.9996],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994]]),\n",
       " tensor([[0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_distances[:10, :], ffwd_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'en dreams,'   'my present'   ' sense may'   'ster of ho'   ' men, as I'\n",
      "'ly dreams,'   'dy present'   'e case may'   'otes of ho'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'r foes may'   'anes of ho'   ' not, as I'\n",
      "'nd dreams,'   'My present'   'ied as may'   'ains of ho'   'o me, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'oint of ho'   'nd I, as I'\n",
      "'of dreams,'   'y, present'   ' bones may'   'ound of ho'   '-day, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'fear to ho'   ' but, as I'\n",
      "'rate arms,'   'im present'   ' grace may'   'ally of ho'   'rd me as I'\n",
      "'hese arms,'   'in present'   'e more may'   'yers of ho'   '\\nYes, as I'\n",
      "\n",
      "'ck groans,'   'll\\nPresent'   'en you say'   'ace our ho'   'r sakes, I'\n",
      "'te builds,'   's innocent'   'Hope I may'   'he that ho'   'early as I'\n",
      "'she finds,'   'me Florent'   'e must say'   'Half an ho'   'nes, and I'\n",
      "'reat loss,'   'their gent'   'n thou may'   'as mine ho'   'fe,--\\nAs I'\n",
      "'ld cramps,'   ', insolent'   'ctions may'   'When it ho'   ' see it, I'\n",
      "'he bleeds,'   'say I\\nsent'   'How he may'   '\\nIf so tho'   'ess woe, I'\n",
      "'our cross,'   'fore, gent'   'ame,\\nI say'   'us, the ho'   ' he does I'\n",
      "'han tears,'   'ldness ent'   'no way say'   'ale and ho'   'mad,--as I'\n",
      "'hese wars,'   'ch garment'   'e now, say'   'out any ho'   ' way can I'\n",
      "'to adders,'   'ic garment'   'ple,\\nI may'   'here\\nat ho'   'rant, an I'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
