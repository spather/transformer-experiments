{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Widening the Space of Similar Values\n",
    "\n",
    "> A major finding was that the current approaches are considering values that are too similar. This notebook investigates ways to search a wider space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Iterable, Protocol, Sequence, Tuple, TypeVar, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "import math\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import tempfile\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "from transformer_experiments.common.substring_generator import all_unique_substrings\n",
    "from transformer_experiments.common.text_analysis import (\n",
    "    build_next_token_map,\n",
    "    SubstringFrequencyAnalysis,\n",
    "    top_nonzero_tokens\n",
    ")\n",
    "from transformer_experiments.common.utils import (\n",
    "    aggregate_by_string_key,\n",
    "    DataWrapper,\n",
    "    topk_across_batches,\n",
    ")\n",
    "from transformer_experiments.dataset_split import split_text_dataset\n",
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.environments import get_environment\n",
    "from transformer_experiments.models.transformer import (\n",
    "    block_size,\n",
    "    n_embed,\n",
    "    n_layer,\n",
    "    TransformerLanguageModel\n",
    ")\n",
    "from transformer_experiments.models.transformer_helpers import (\n",
    "    unsqueeze_emb,\n",
    "    EncodingHelpers,\n",
    "    LogitsWrapper,\n",
    "    TransformerAccessors\n",
    ")\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer\n",
    ")\n",
    "from transformer_experiments.training_utils import CheckPointer, GetBatchFunction, Trainer\n",
    "from transformer_experiments.experiments.block_internals import (\n",
    "    BlockInternalsAccessors,\n",
    "    BlockInternalsExperiment,\n",
    "    BatchedBlockInternalsExperiment,\n",
    "    BlockInternalsAnalysis,\n",
    "    batch_cosine_sim,\n",
    ")\n",
    "from transformer_experiments.experiments.cosine_sims import pre_filter_cosine_sim_results\n",
    "from transformer_experiments.experiments.final_ffwd import FinalFFWDExperiment\n",
    "from transformer_experiments.experiments.similar_strings import (\n",
    "    SimilarStringsData,\n",
    "    SimilarStringsExperiment,\n",
    "    SimilarStringsResult\n",
    ")\n",
    "from transformer_experiments.experiments.logit_lens import LogitLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment is local_mac\n"
     ]
    }
   ],
   "source": [
    "environment = get_environment()\n",
    "print(f\"environment is {environment.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ts = TinyShakespeareDataSet(cache_file=environment.code_root / 'nbs/artifacts/input.txt')\n",
    "m, tokenizer = create_model_and_tokenizer(\n",
    "    saved_model_filename=environment.code_root / 'nbs/artifacts/shakespeare-20231112.pt',\n",
    "    dataset=ts,\n",
    "    device=device,\n",
    ")\n",
    "_, val_data = split_text_dataset(ts.text, tokenizer, train_pct=0.9, device=device)\n",
    "encoding_helpers = EncodingHelpers(tokenizer, device)\n",
    "accessors = TransformerAccessors(m, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if list((environment.data_root / 'block_internals_results/large_files/slen10/').glob('*')) == []:\n",
    "    print(\"Run `make block_internals_slen10_dataset` in the project root to generate the required dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings10 = all_unique_substrings(ts.text, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp10 = BatchedBlockInternalsExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings10,\n",
    "    output_dir=environment.data_root / 'block_internals_results/large_files/slen10/',\n",
    "    batch_size=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "n_samples = 20000\n",
    "indices = torch.randperm(len(strings10))[:n_samples]\n",
    "strings20k = [strings10[i.item()] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of 500 strings\n",
    "sample_size = 500\n",
    "strings_sample = strings20k[:sample_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this in a common component\n",
    "def get_model_outputs(prompts: Sequence[str], encoding_helpers: EncodingHelpers):\n",
    "    # Compute the model's predictions:\n",
    "    tokens = encoding_helpers.tokenize_strings(prompts)\n",
    "    logits, _ = m(tokens)\n",
    "\n",
    "    logits = LogitsWrapper(logits, encoding_helpers.tokenizer)\n",
    "    return [topk_tokens[-1] for topk_tokens in logits.topk_tokens(k=10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs_sample = get_model_outputs(strings_sample, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_exp = BlockInternalsExperiment(encoding_helpers, accessors, strings_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by examining what we get when we ask for a much larger top k values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sims, emb_distances = exp10.strings_with_topk_closest_embeddings(\n",
    "    prompts_exp.embeddings[:5, :, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9062, 0.9470, 0.9045, 0.9493, 0.9544],\n",
       "         [0.9062, 0.9462, 0.8602, 0.9083, 0.9443],\n",
       "         [0.9053, 0.9429, 0.8593, 0.9082, 0.9064],\n",
       "         [0.9037, 0.9429, 0.8586, 0.9055, 0.9057],\n",
       "         [0.9027, 0.9404, 0.8566, 0.9052, 0.9045],\n",
       "         [0.9020, 0.9027, 0.8562, 0.9044, 0.8996],\n",
       "         [0.9017, 0.9009, 0.8548, 0.9035, 0.8982],\n",
       "         [0.8962, 0.9009, 0.8545, 0.9034, 0.8656],\n",
       "         [0.8651, 0.9008, 0.8532, 0.9032, 0.8631]]),\n",
       " tensor([[0.7591, 0.7566, 0.7604, 0.8064, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7604, 0.8063, 0.8047],\n",
       "         [0.7591, 0.7566, 0.7603, 0.8063, 0.8042],\n",
       "         [0.7590, 0.7564, 0.7602, 0.8063, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8062, 0.8041],\n",
       "         [0.7589, 0.7563, 0.7601, 0.8061, 0.8040],\n",
       "         [0.7588, 0.7557, 0.7601, 0.8061, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7600, 0.8060, 0.8039],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8038],\n",
       "         [0.7587, 0.7557, 0.7599, 0.8060, 0.8037]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_distances[:10, :], emb_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'is dream o'   'My present'   's eye, mak'   'eart of mo'   ' men, as I'\n",
      "'ur dreams,'   'be present'   's eyes in '   'earn of hi'   ' man, as y'\n",
      "'of dreams,'   'dy present'   'l eyes can'   'ears of ha'   ' man, if I'\n",
      "'us dreams.'   'my present'   's eyes to '   'park of ho'   'oman, as t'\n",
      "'he dreams,'   'ry present'   'l eyes gaz'   'eart of ge'   ' men, as i'\n",
      "'ly dreams,'   'y, present'   'r foes may'   'eard of hi'   ' many as y'\n",
      "'en dreams,'   'on present'   'r ever may'   'east of yo'   'cian, as I'\n",
      "'nd dreams,'   't, present'   's eyes do '   'part of hi'   ' son, as t'\n",
      "'as dream\\nS'   'in present'   's eye; tal'   'earn of yo'   ' long as I'\n",
      "\n",
      "'is presenc'   ' a prisone'   'g over mas'   'efit of se'   ' man: we s'\n",
      "'is prowess'   'ot prone t'   'l even tak'   'wist of ro'   ' wind as s'\n",
      "'is be all,'   'is project'   't so I may'   'e is of so'   ' man; all '\n",
      "'is the mad'   'my person.'   'n thou may'   'gent of hi'   ' man, they'\n",
      "\"'s great s\"   'ay prove.\\n'   'rosper may'   'ture of hu'   'tion, as f'\n",
      "'is deed do'   'by herself'   'e that may'   'ents of so'   ' her, as w'\n",
      "'is present'   'or prisone'   'speaks my '   'eral of yo'   ' maid is m'\n",
      "'rs dry; sc'   'be broken:'   'o not, may'   'mark of ot'   \" man, 'tis\"\n",
      "'ish reason'   'ay prove p'   'ounsel may'   'ents of yo'   ':\\nNo, as I'\n",
      "'py drinks,'   'ng prisone'   'n pity may'   'e is of go'   'sland as a'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(emb_sims[i][j]) for i in range(len(emb_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "proj_sims, proj_distances = exp10.strings_with_topk_closest_proj_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.proj_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9948, 0.9967, 0.9947, 0.9974, 0.9956],\n",
       "         [0.9942, 0.9967, 0.9945, 0.9960, 0.9933],\n",
       "         [0.9937, 0.9964, 0.9921, 0.9958, 0.9897],\n",
       "         [0.9935, 0.9963, 0.9917, 0.9957, 0.9896],\n",
       "         [0.9928, 0.9962, 0.9910, 0.9956, 0.9871],\n",
       "         [0.9922, 0.9950, 0.9905, 0.9955, 0.9857],\n",
       "         [0.9911, 0.9944, 0.9900, 0.9954, 0.9856],\n",
       "         [0.9897, 0.9942, 0.9895, 0.9950, 0.9850],\n",
       "         [0.9891, 0.9939, 0.9894, 0.9943, 0.9846]]),\n",
       " tensor([[0.9709, 0.9826, 0.9796, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9825, 0.9795, 0.9855, 0.9726],\n",
       "         [0.9709, 0.9824, 0.9794, 0.9854, 0.9726],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9824, 0.9793, 0.9854, 0.9725],\n",
       "         [0.9708, 0.9823, 0.9793, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9854, 0.9724],\n",
       "         [0.9708, 0.9823, 0.9791, 0.9853, 0.9724],\n",
       "         [0.9707, 0.9823, 0.9791, 0.9853, 0.9723],\n",
       "         [0.9707, 0.9823, 0.9790, 0.9853, 0.9723]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_distances[:10, :], proj_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'ly dreams,'   'my present'   'e case may'   'ster of ho'   ' men, as I'\n",
      "'en dreams,'   'dy present'   ' sense may'   'ffer to ha'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'ied as may'   'ruth of ho'   ' not, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'otes of ho'   'o me, as I'\n",
      "'nd dreams,'   'My present'   'r foes may'   'anes of ho'   'nd I, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'oint of ho'   'cian, as I'\n",
      "'of dreams,'   'in present'   ' haste may'   'yers of ho'   'I am, as t'\n",
      "\"n's beams,\"   'is present'   'odesty may'   'ains of ho'   '-day, as I'\n",
      "'hese arms,'   'im present'   'esence may'   'ound of ho'   '\\nAnd, as I'\n",
      "\n",
      "'sires most'   'ast ungent'   \"'s some am\"   'lf with ho'   ' be, was l'\n",
      "'teous mass'   'What scene'   'e they mad'   'tell of hi'   'Look, as I'\n",
      "'m to kiss,'   'lest scent'   ' am to say'   'Thus to ha'   'wick, as o'\n",
      "'much amiss'   'ondon sent'   ' early mad'   's of a tho'   'aith, as y'\n",
      "'wings misd'   'ng presenc'   'If you may'   'ven for ha'   'ut I was a'\n",
      "'from himse'   ' this sent'   'es the mai'   ' of our ho'   'y, is as a'\n",
      "'isdom hast'   'viest cens'   'et him say'   'tars of he'   'early as m'\n",
      "'hat seems '   'ou dissent'   'lords, may'   's other ho'   ' Yet, as t'\n",
      "'er bosoms!'   'tion spend'   'o them say'   'now the ho'   ' duke as I'\n",
      "' so, himse'   'have spent'   'nd now may'   'keep at ho'   's low as t'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(proj_sims[i][j]) for i in range(len(proj_sims))])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 0\n",
    "ffwd_sims, ffwd_distances = exp10.strings_with_topk_closest_ffwd_outputs(\n",
    "    block_idx=block_idx,\n",
    "    t_i=-1,\n",
    "    queries=prompts_exp.ffwd_output(block_idx=block_idx)[:5, -1, :],\n",
    "    k=200,\n",
    "    largest=True,\n",
    "    distance_function=batch_cosine_sim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.9998, 0.9999, 0.9997, 0.9998, 0.9999],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9996, 0.9998, 0.9997],\n",
       "         [0.9998, 0.9998, 0.9995, 0.9998, 0.9997],\n",
       "         [0.9997, 0.9998, 0.9995, 0.9998, 0.9996],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9997, 0.9997, 0.9995, 0.9998, 0.9995],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994],\n",
       "         [0.9996, 0.9997, 0.9995, 0.9997, 0.9994]]),\n",
       " tensor([[0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9988, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983],\n",
       "         [0.9987, 0.9990, 0.9989, 0.9992, 0.9983]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_distances[:10, :], ffwd_distances[-10:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is dreams,'   'by present'   's eyes may'   'eart of ho'   ' man, as I'\n",
      "'en dreams,'   'my present'   ' sense may'   'ster of ho'   ' men, as I'\n",
      "'ly dreams,'   'dy present'   'e case may'   'otes of ho'   ' and, as I'\n",
      "'he dreams,'   'ry present'   'r foes may'   'anes of ho'   ' not, as I'\n",
      "'nd dreams,'   'My present'   'ied as may'   'ains of ho'   'o me, as I'\n",
      "'ur dreams,'   'be present'   'ay she may'   'oint of ho'   'nd I, as I'\n",
      "'of dreams,'   'y, present'   ' bones may'   'ound of ho'   '-day, as I'\n",
      "'ery beams,'   'y; present'   'So she may'   'fear to ho'   ' but, as I'\n",
      "'rate arms,'   'im present'   ' grace may'   'ally of ho'   'rd me as I'\n",
      "'hese arms,'   'in present'   'e more may'   'yers of ho'   '\\nYes, as I'\n",
      "\n",
      "'ck groans,'   'll\\nPresent'   'en you say'   'ace our ho'   'r sakes, I'\n",
      "'te builds,'   's innocent'   'Hope I may'   'he that ho'   'early as I'\n",
      "'she finds,'   'me Florent'   'e must say'   'Half an ho'   'nes, and I'\n",
      "'reat loss,'   'their gent'   'n thou may'   'as mine ho'   'fe,--\\nAs I'\n",
      "'ld cramps,'   ', insolent'   'ctions may'   'When it ho'   ' see it, I'\n",
      "'he bleeds,'   'say I\\nsent'   'How he may'   '\\nIf so tho'   'ess woe, I'\n",
      "'our cross,'   'fore, gent'   'ame,\\nI say'   'us, the ho'   ' he does I'\n",
      "'han tears,'   'ldness ent'   'no way say'   'ale and ho'   'mad,--as I'\n",
      "'hese wars,'   'ch garment'   'e now, say'   'out any ho'   ' way can I'\n",
      "'to adders,'   'ic garment'   'ple,\\nI may'   'here\\nat ho'   'rant, an I'\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")\n",
    "\n",
    "print()\n",
    "for j in range(-10, 0):\n",
    "    print(f\"{'   '.join([repr(ffwd_sims[i][j]) for i in range(len(ffwd_sims))])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Cosine Sim Data for 20,000 Strings Against all Length 10 Strings\n",
    "\n",
    "This uses the output of ConsineSimilarityExperiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = environment.data_root / 'cosine_sim_results/large_files/slen10/'\n",
    "n_batches = 8590\n",
    "n_queries = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_map10 = build_next_token_map(ts.text, 10, tokenizer.vocab_size, tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow - prefer using pre-filtering and then using filter_on_prefiltered_results()\n",
    "def filter_across_batches(\n",
    "    get_batch: Callable[[int], torch.Tensor],\n",
    "    n_batches: int,\n",
    "    filter_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "    n_queries: int,\n",
    "):\n",
    "    total_count = 0\n",
    "    matching_indices = [[] for _ in range(n_queries)]\n",
    "    for batch_idx in range(n_batches):\n",
    "        batch = get_batch(batch_idx)\n",
    "        batch_size, n_queries_batch = batch.shape\n",
    "        assert n_queries_batch == n_queries\n",
    "\n",
    "        filtered = filter_fn(batch)\n",
    "        nonzeros = torch.nonzero(filtered)\n",
    "        for i in range(nonzeros.shape[0]):\n",
    "            idx_in_batch, query_idx = nonzeros[i, :]\n",
    "            matching_indices[query_idx.item()].append(total_count + idx_in_batch.item())\n",
    "\n",
    "        total_count += batch_size\n",
    "\n",
    "    return matching_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for filter_across_batches()\n",
    "\n",
    "batches = [\n",
    "    torch.tensor([\n",
    "        [0.0, 0.6, 0.4, 0.3],\n",
    "        [0.1, 0.3, 0.5, 0.1],\n",
    "        [0.0, 0.1, 0.8, 0.0],\n",
    "    ]),\n",
    "    torch.tensor([\n",
    "        [0.7, 0.2, 0.6, 0.3],\n",
    "        [0.1, 0.8, 0.2, 0.8],\n",
    "    ]),\n",
    "]\n",
    "\n",
    "result = filter_across_batches(\n",
    "    get_batch=lambda i: batches[i],\n",
    "    n_batches=len(batches),\n",
    "    filter_fn=lambda batch: batch > 0.5,\n",
    "    n_queries=4,\n",
    ")\n",
    "test_eq(result, [\n",
    "    [3,],\n",
    "    [0, 4],\n",
    "    [2, 3],\n",
    "    [4],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefiltering Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, pre-filter the results for the first 500 queries to just the values > 0.7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_batch = lambda batch_idx: torch.load(results_folder / f'cosine_sim_ffwd_out_{batch_idx:05d}.pt')\n",
    "q_idx_start = 0\n",
    "q_idx_end = 500\n",
    "threshold = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow, takes ~15 mins to run\n",
    "prefiltered_result = pre_filter_cosine_sim_results(\n",
    "    load_batch=load_batch,\n",
    "    n_batches=n_batches,\n",
    "    q_idx_start=q_idx_start,\n",
    "    q_idx_end=q_idx_end,\n",
    "    threshold=threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the prefiltered results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefiltered_results_folder = results_folder / f'prefiltered_{threshold}'\n",
    "prefiltered_results_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefiltered_filename(q_idx: int, block_idx: int) -> Path:\n",
    "    return prefiltered_results_folder / f'cosine_sim_ffwd_out_{q_idx:05d}_{block_idx:02d}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd2789d021044e38969cd3c0322818c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for q_idx in tqdm(range(q_idx_start, q_idx_end)):\n",
    "    for block_idx in range(n_layer):\n",
    "        torch.save(\n",
    "            prefiltered_result[q_idx - q_idx_start][block_idx],\n",
    "            prefiltered_filename(q_idx, block_idx),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadPrefilteredFunction(Protocol):\n",
    "    def __call__(self, q_idx: int) -> torch.Tensor:\n",
    "        ...\n",
    "\n",
    "\n",
    "def filter_on_prefiltered_results(\n",
    "    load_prefiltered: LoadPrefilteredFunction,\n",
    "    q_idx_start: int,\n",
    "    q_idx_end: int,\n",
    "    filter_fn: Callable[[torch.Tensor], torch.Tensor],\n",
    "):\n",
    "    matching_indices = []\n",
    "    for q_idx in range(q_idx_start, q_idx_end):\n",
    "        prefiltered = load_prefiltered(q_idx)\n",
    "        indices, values = itemgetter('indices', 'values')(prefiltered)\n",
    "        indices_into_values = torch.nonzero(filter_fn(values)).squeeze(dim=-1)\n",
    "        matching_indices.append(indices[indices_into_values])\n",
    "\n",
    "    return matching_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, collect some stats about the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_result_stats(\n",
    "    filter_results: List[List[int]],\n",
    "):\n",
    "    lens = [len(result) for result in filter_results]\n",
    "    return {\n",
    "        'min': min(lens),\n",
    "        'max': max(lens),\n",
    "        'mean': np.mean(lens),\n",
    "        'std': np.std(lens),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_strings(\n",
    "    filter_result: List[List[int]],\n",
    "    strings: Sequence[str],\n",
    "):\n",
    "    return [\n",
    "        [\n",
    "            strings[j]\n",
    "            for j in filter_result[i]\n",
    "        ]\n",
    "        for i in range(len(filter_result))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put this in a common component\n",
    "def analyze_simulate_results(sim_freqs, model_outputs):\n",
    "    assert len(sim_freqs) == len(model_outputs)\n",
    "    topn_matches = [0 for _ in range(10)]\n",
    "    topn_matches_any_order = [0 for _ in range(10)]\n",
    "    for i, sim_freq in enumerate(sim_freqs):\n",
    "        sim_output = top_nonzero_tokens(sim_freq, encoding_helpers.tokenizer.itos)[:10]\n",
    "        model_output = model_outputs[i]\n",
    "\n",
    "        sim_tokens, _ = zip(*sim_output)\n",
    "        model_tokens, _ = zip(*model_output)\n",
    "\n",
    "        n = min(len(sim_tokens), len(model_tokens))\n",
    "        for j in range(n):\n",
    "            if sim_tokens[j] == model_tokens[j]:\n",
    "                topn_matches[j] += 1\n",
    "            if set(sim_tokens[:j+1]) == set(model_tokens[:j+1]):\n",
    "                topn_matches_any_order[j] += 1\n",
    "\n",
    "    return topn_matches, topn_matches_any_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(\n",
    "    matching_indices: Sequence[Sequence[int]],\n",
    "    n_queries: int,\n",
    "    all_strings: Sequence[str],\n",
    "    next_token_map: Dict[str, torch.Tensor],\n",
    "    model_outputs: Sequence[Sequence[Tuple[str, float]]],\n",
    "):\n",
    "    print(filter_result_stats(matching_indices))\n",
    "\n",
    "    filter_results_strings = get_matching_strings(matching_indices, all_strings)\n",
    "    filter_result_freqs = [\n",
    "        torch.stack([\n",
    "            next_token_map[matching_string]\n",
    "            for matching_string in matching_strings\n",
    "        ]).sum(dim=0)\n",
    "        for matching_strings in filter_results_strings\n",
    "    ]\n",
    "\n",
    "    filter_result_probs = [\n",
    "        freqs / freqs.sum()\n",
    "        for freqs in filter_result_freqs\n",
    "    ]\n",
    "\n",
    "    topn_matches, topn_matches_any_order = analyze_simulate_results(filter_result_probs, model_outputs)\n",
    "    for i in range(10):\n",
    "        print(f\"Top {i+1} matches: {topn_matches[i] / n_queries:.3f}\")\n",
    "        print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_queries:.3f}\")\n",
    "\n",
    "    return filter_result_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_queries_sample = 500\n",
    "q_idx_start = 0\n",
    "q_idx_end = n_queries_sample\n",
    "model_outputs_sample = get_model_outputs(strings20k[:n_queries_sample], encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 30527, 'mean': 2143.642, 'std': 5838.287069495299}\n",
      "Top 1 matches: 0.788\n",
      "Top 1 matches (any order): 0.788\n",
      "Top 2 matches: 0.424\n",
      "Top 2 matches (any order): 0.504\n",
      "Top 3 matches: 0.268\n",
      "Top 3 matches (any order): 0.334\n",
      "Top 4 matches: 0.186\n",
      "Top 4 matches (any order): 0.260\n",
      "Top 5 matches: 0.164\n",
      "Top 5 matches (any order): 0.198\n",
      "Top 6 matches: 0.088\n",
      "Top 6 matches (any order): 0.134\n",
      "Top 7 matches: 0.076\n",
      "Top 7 matches (any order): 0.102\n",
      "Top 8 matches: 0.058\n",
      "Top 8 matches (any order): 0.086\n",
      "Top 9 matches: 0.054\n",
      "Top 9 matches (any order): 0.062\n",
      "Top 10 matches: 0.046\n",
      "Top 10 matches (any order): 0.040\n"
     ]
    }
   ],
   "source": [
    "block_idx = 5\n",
    "ffwd5_freqs = analyze_dataset(\n",
    "    matching_indices=filter_on_prefiltered_results(\n",
    "        load_prefiltered=lambda q_idx: torch.load(prefiltered_filename(q_idx, block_idx)),\n",
    "        q_idx_start=q_idx_start,\n",
    "        q_idx_end=q_idx_end,\n",
    "        filter_fn=lambda values: values > 0.89,\n",
    "    ),\n",
    "    n_queries=n_queries_sample,\n",
    "    all_strings=strings10,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 61657, 'mean': 3283.636, 'std': 9950.066907488814}\n",
      "Top 1 matches: 0.790\n",
      "Top 1 matches (any order): 0.790\n",
      "Top 2 matches: 0.450\n",
      "Top 2 matches (any order): 0.518\n",
      "Top 3 matches: 0.270\n",
      "Top 3 matches (any order): 0.318\n",
      "Top 4 matches: 0.202\n",
      "Top 4 matches (any order): 0.232\n",
      "Top 5 matches: 0.170\n",
      "Top 5 matches (any order): 0.176\n",
      "Top 6 matches: 0.106\n",
      "Top 6 matches (any order): 0.142\n",
      "Top 7 matches: 0.096\n",
      "Top 7 matches (any order): 0.108\n",
      "Top 8 matches: 0.072\n",
      "Top 8 matches (any order): 0.080\n",
      "Top 9 matches: 0.048\n",
      "Top 9 matches (any order): 0.056\n",
      "Top 10 matches: 0.036\n",
      "Top 10 matches (any order): 0.032\n"
     ]
    }
   ],
   "source": [
    "block_idx = 4\n",
    "ffwd4_freqs = analyze_dataset(\n",
    "    matching_indices=filter_on_prefiltered_results(\n",
    "        load_prefiltered=lambda q_idx: torch.load(prefiltered_filename(q_idx, block_idx)),\n",
    "        q_idx_start=q_idx_start,\n",
    "        q_idx_end=q_idx_end,\n",
    "        filter_fn=lambda values: values > 0.81,\n",
    "    ),\n",
    "    n_queries=n_queries_sample,\n",
    "    all_strings=strings10,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 9100, 'mean': 624.342, 'std': 1387.415385901425}\n",
      "Top 1 matches: 0.804\n",
      "Top 1 matches (any order): 0.804\n",
      "Top 2 matches: 0.478\n",
      "Top 2 matches (any order): 0.542\n",
      "Top 3 matches: 0.304\n",
      "Top 3 matches (any order): 0.380\n",
      "Top 4 matches: 0.234\n",
      "Top 4 matches (any order): 0.274\n",
      "Top 5 matches: 0.192\n",
      "Top 5 matches (any order): 0.228\n",
      "Top 6 matches: 0.134\n",
      "Top 6 matches (any order): 0.184\n",
      "Top 7 matches: 0.112\n",
      "Top 7 matches (any order): 0.114\n",
      "Top 8 matches: 0.084\n",
      "Top 8 matches (any order): 0.104\n",
      "Top 9 matches: 0.066\n",
      "Top 9 matches (any order): 0.082\n",
      "Top 10 matches: 0.050\n",
      "Top 10 matches (any order): 0.060\n"
     ]
    }
   ],
   "source": [
    "block_idx = 3\n",
    "ffwd3_freqs = analyze_dataset(\n",
    "    matching_indices=filter_on_prefiltered_results(\n",
    "        load_prefiltered=lambda q_idx: torch.load(prefiltered_filename(q_idx, block_idx)),\n",
    "        q_idx_start=q_idx_start,\n",
    "        q_idx_end=q_idx_end,\n",
    "        filter_fn=lambda values: values > 0.76,\n",
    "    ),\n",
    "    n_queries=n_queries_sample,\n",
    "    all_strings=strings10,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 7457, 'mean': 446.792, 'std': 995.0116103523616}\n",
      "Top 1 matches: 0.808\n",
      "Top 1 matches (any order): 0.808\n",
      "Top 2 matches: 0.458\n",
      "Top 2 matches (any order): 0.496\n",
      "Top 3 matches: 0.298\n",
      "Top 3 matches (any order): 0.376\n",
      "Top 4 matches: 0.222\n",
      "Top 4 matches (any order): 0.256\n",
      "Top 5 matches: 0.182\n",
      "Top 5 matches (any order): 0.196\n",
      "Top 6 matches: 0.102\n",
      "Top 6 matches (any order): 0.158\n",
      "Top 7 matches: 0.112\n",
      "Top 7 matches (any order): 0.132\n",
      "Top 8 matches: 0.090\n",
      "Top 8 matches (any order): 0.096\n",
      "Top 9 matches: 0.074\n",
      "Top 9 matches (any order): 0.070\n",
      "Top 10 matches: 0.042\n",
      "Top 10 matches (any order): 0.056\n"
     ]
    }
   ],
   "source": [
    "block_idx = 2\n",
    "ffwd2_freqs = analyze_dataset(\n",
    "    matching_indices=filter_on_prefiltered_results(\n",
    "        load_prefiltered=lambda q_idx: torch.load(prefiltered_filename(q_idx, block_idx)),\n",
    "        q_idx_start=q_idx_start,\n",
    "        q_idx_end=q_idx_end,\n",
    "        filter_fn=lambda values: values > 0.85,\n",
    "    ),\n",
    "    n_queries=n_queries_sample,\n",
    "    all_strings=strings10,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 5070, 'mean': 369.31, 'std': 755.4999099271952}\n",
      "Top 1 matches: 0.750\n",
      "Top 1 matches (any order): 0.750\n",
      "Top 2 matches: 0.416\n",
      "Top 2 matches (any order): 0.470\n",
      "Top 3 matches: 0.236\n",
      "Top 3 matches (any order): 0.312\n",
      "Top 4 matches: 0.192\n",
      "Top 4 matches (any order): 0.218\n",
      "Top 5 matches: 0.172\n",
      "Top 5 matches (any order): 0.172\n",
      "Top 6 matches: 0.102\n",
      "Top 6 matches (any order): 0.126\n",
      "Top 7 matches: 0.086\n",
      "Top 7 matches (any order): 0.102\n",
      "Top 8 matches: 0.068\n",
      "Top 8 matches (any order): 0.078\n",
      "Top 9 matches: 0.060\n",
      "Top 9 matches (any order): 0.076\n",
      "Top 10 matches: 0.050\n",
      "Top 10 matches (any order): 0.060\n"
     ]
    }
   ],
   "source": [
    "block_idx = 1\n",
    "ffwd1_freqs = analyze_dataset(\n",
    "    matching_indices=filter_on_prefiltered_results(\n",
    "        load_prefiltered=lambda q_idx: torch.load(prefiltered_filename(q_idx, block_idx)),\n",
    "        q_idx_start=q_idx_start,\n",
    "        q_idx_end=q_idx_end,\n",
    "        filter_fn=lambda values: values > 0.94,\n",
    "    ),\n",
    "    n_queries=n_queries_sample,\n",
    "    all_strings=strings10,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min': 1, 'max': 5078, 'mean': 333.072, 'std': 663.3523097238751}\n",
      "Top 1 matches: 0.754\n",
      "Top 1 matches (any order): 0.754\n",
      "Top 2 matches: 0.410\n",
      "Top 2 matches (any order): 0.472\n",
      "Top 3 matches: 0.252\n",
      "Top 3 matches (any order): 0.316\n",
      "Top 4 matches: 0.192\n",
      "Top 4 matches (any order): 0.216\n",
      "Top 5 matches: 0.146\n",
      "Top 5 matches (any order): 0.170\n",
      "Top 6 matches: 0.108\n",
      "Top 6 matches (any order): 0.128\n",
      "Top 7 matches: 0.092\n",
      "Top 7 matches (any order): 0.100\n",
      "Top 8 matches: 0.072\n",
      "Top 8 matches (any order): 0.072\n",
      "Top 9 matches: 0.068\n",
      "Top 9 matches (any order): 0.072\n",
      "Top 10 matches: 0.046\n",
      "Top 10 matches (any order): 0.056\n"
     ]
    }
   ],
   "source": [
    "block_idx = 0\n",
    "ffwd0_freqs = analyze_dataset(\n",
    "    matching_indices=filter_on_prefiltered_results(\n",
    "        load_prefiltered=lambda q_idx: torch.load(prefiltered_filename(q_idx, block_idx)),\n",
    "        q_idx_start=q_idx_start,\n",
    "        q_idx_end=q_idx_end,\n",
    "        filter_fn=lambda values: values > 0.95,\n",
    "    ),\n",
    "    n_queries=n_queries_sample,\n",
    "    all_strings=strings10,\n",
    "    next_token_map=next_token_map10,\n",
    "    model_outputs=model_outputs_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.796\n",
      "Top 1 matches (any order): 0.796\n",
      "Top 2 matches: 0.500\n",
      "Top 2 matches (any order): 0.572\n",
      "Top 3 matches: 0.326\n",
      "Top 3 matches (any order): 0.382\n",
      "Top 4 matches: 0.262\n",
      "Top 4 matches (any order): 0.308\n",
      "Top 5 matches: 0.192\n",
      "Top 5 matches (any order): 0.226\n",
      "Top 6 matches: 0.144\n",
      "Top 6 matches (any order): 0.186\n",
      "Top 7 matches: 0.122\n",
      "Top 7 matches (any order): 0.144\n",
      "Top 8 matches: 0.092\n",
      "Top 8 matches (any order): 0.104\n",
      "Top 9 matches: 0.076\n",
      "Top 9 matches (any order): 0.084\n",
      "Top 10 matches: 0.048\n",
      "Top 10 matches (any order): 0.054\n"
     ]
    }
   ],
   "source": [
    "total_freqs = [\n",
    "    (\n",
    "        0.01*ffwd0_freqs[i] +\n",
    "        0.01*ffwd1_freqs[i] +\n",
    "        0.1*ffwd2_freqs[i] +\n",
    "        1.5*ffwd3_freqs[i] +\n",
    "        4*ffwd4_freqs[i] +\n",
    "        0.01*ffwd5_freq\n",
    "    )\n",
    "    for i, ffwd5_freq in enumerate(ffwd5_freqs)\n",
    "]\n",
    "total_probs = [\n",
    "    freqs / freqs.sum()\n",
    "    for freqs in total_freqs\n",
    "]\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs_sample)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / n_queries_sample:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_queries_sample:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporate data from the rest of the strings (everything above just looked at first 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = get_model_outputs(strings20k, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = environment.data_root / 'cosine_sim_results/large_files/slen10/'\n",
    "n_batches = 8590\n",
    "n_queries = 20000\n",
    "\n",
    "next_token_map = next_token_map10\n",
    "all_strings = strings10\n",
    "\n",
    "ffwd_thresholds = [0.95, 0.94, 0.85, 0.76, 0.81, 0.89]\n",
    "ffwd_freqs = [[] for _ in range(n_layer)]\n",
    "\n",
    "for block_idx in tqdm(range(n_layer)):\n",
    "    get_batch = lambda batch_idx: torch.load(\n",
    "        str(results_folder / f'cosine_sim_ffwd_out_{batch_idx:05d}.pt'),\n",
    "        mmap=True,\n",
    "    )[block_idx, :, :n_queries]\n",
    "\n",
    "    filter_results = filter_across_batches(\n",
    "        get_batch=get_batch,\n",
    "        n_batches=n_batches,\n",
    "        filter_fn=lambda batch: batch > ffwd_thresholds[block_idx],\n",
    "        n_queries=n_queries,\n",
    "    )\n",
    "    filter_results_strings = get_matching_strings(filter_results, all_strings)\n",
    "    ffwd_freqs[block_idx] = [\n",
    "        torch.stack(\n",
    "            [\n",
    "                next_token_map[matching_string]\n",
    "                for matching_string in matching_strings\n",
    "            ]\n",
    "        ).sum(dim=0)\n",
    "        for matching_strings in filter_results_strings\n",
    "    ]\n",
    "\n",
    "ffwd_freqs = torch.stack(\n",
    "    [torch.stack(ffwd_freqs[block_idx]) for block_idx in range(n_layer)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 20000, 65]), 20000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffwd_freqs.shape, len(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results_folder / 'learn_coefficients').mkdir(exist_ok=True)\n",
    "torch.save(ffwd_freqs, str(results_folder / 'learn_coefficients/ffwd_freqs.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ffwd_freqs from disk\n",
    "ffwd_freqs = torch.load(results_folder / 'learn_coefficients/ffwd_freqs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.796\n",
      "Top 1 matches (any order): 0.796\n",
      "Top 2 matches: 0.500\n",
      "Top 2 matches (any order): 0.572\n",
      "Top 3 matches: 0.326\n",
      "Top 3 matches (any order): 0.382\n",
      "Top 4 matches: 0.262\n",
      "Top 4 matches (any order): 0.308\n",
      "Top 5 matches: 0.192\n",
      "Top 5 matches (any order): 0.226\n",
      "Top 6 matches: 0.144\n",
      "Top 6 matches (any order): 0.186\n",
      "Top 7 matches: 0.122\n",
      "Top 7 matches (any order): 0.144\n",
      "Top 8 matches: 0.092\n",
      "Top 8 matches (any order): 0.104\n",
      "Top 9 matches: 0.076\n",
      "Top 9 matches (any order): 0.084\n",
      "Top 10 matches: 0.048\n",
      "Top 10 matches (any order): 0.054\n"
     ]
    }
   ],
   "source": [
    "# Check that we still get the same results for the first 500\n",
    "hand_rolled_coeffs = torch.tensor([0.01, 0.01, 0.1, 1.5, 4, 0.01]).unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs[:, :500, :] * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs[:500])\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / n_queries_sample:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_queries_sample:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.806\n",
      "Top 1 matches (any order): 0.806\n",
      "Top 2 matches: 0.501\n",
      "Top 2 matches (any order): 0.568\n",
      "Top 3 matches: 0.342\n",
      "Top 3 matches (any order): 0.405\n",
      "Top 4 matches: 0.273\n",
      "Top 4 matches (any order): 0.337\n",
      "Top 5 matches: 0.209\n",
      "Top 5 matches (any order): 0.250\n",
      "Top 6 matches: 0.168\n",
      "Top 6 matches (any order): 0.197\n",
      "Top 7 matches: 0.129\n",
      "Top 7 matches (any order): 0.153\n",
      "Top 8 matches: 0.105\n",
      "Top 8 matches (any order): 0.124\n",
      "Top 9 matches: 0.086\n",
      "Top 9 matches (any order): 0.091\n",
      "Top 10 matches: 0.055\n",
      "Top 10 matches (any order): 0.057\n"
     ]
    }
   ],
   "source": [
    "# Look at it for all samples\n",
    "hand_rolled_coeffs = torch.tensor([0.01, 0.01, 0.1, 1.5, 4, 0.01]).unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can we tweak these hand-rolled coefficients for the full data set and get better results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.806\n",
      "Top 1 matches (any order): 0.806\n",
      "Top 2 matches: 0.502\n",
      "Top 2 matches (any order): 0.568\n",
      "Top 3 matches: 0.342\n",
      "Top 3 matches (any order): 0.405\n",
      "Top 4 matches: 0.273\n",
      "Top 4 matches (any order): 0.336\n",
      "Top 5 matches: 0.209\n",
      "Top 5 matches (any order): 0.248\n",
      "Top 6 matches: 0.167\n",
      "Top 6 matches (any order): 0.196\n",
      "Top 7 matches: 0.127\n",
      "Top 7 matches (any order): 0.152\n",
      "Top 8 matches: 0.105\n",
      "Top 8 matches (any order): 0.124\n",
      "Top 9 matches: 0.086\n",
      "Top 9 matches (any order): 0.090\n",
      "Top 10 matches: 0.054\n",
      "Top 10 matches (any order): 0.057\n"
     ]
    }
   ],
   "source": [
    "hand_rolled_coeffs = torch.tensor([0.01, 0.01, 0.1, 1.5, 6, 0.01]).unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "total_freqs = (ffwd_freqs * hand_rolled_coeffs).sum(dim=0)\n",
    "total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best yet for the full data set, with hand-rolled coefficients. Let's see if we can learn better values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below has not yet been re-run with the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSim(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.coeffs = torch.nn.Parameter(\n",
    "            torch.randn(n_layer, 1, 1, dtype=torch.float32, requires_grad=True)\n",
    "        )\n",
    "        torch.nn.init.normal_(self.coeffs.data, mean=0.0, std=0.2)\n",
    "\n",
    "    def forward(self, freqs: torch.Tensor, model_output: Optional[torch.Tensor]=None):\n",
    "        total_freqs = (freqs * self.coeffs).sum(dim=0)\n",
    "        total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "        if model_output is not None:\n",
    "            loss = torch.norm(total_probs - model_output, dim=-1).sum()\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "\n",
    "        return total_probs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(\n",
    "    model: ModelSim, get_batch_func: GetBatchFunction, eval_iters: int=100\n",
    "):\n",
    "    out = {}\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch_func(split=split)\n",
    "\n",
    "            _, loss = model(X, Y)\n",
    "\n",
    "            losses[k] = loss.item()\n",
    "\n",
    "        out[split] = losses.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size: int, freqs: torch.Tensor, split: str='train', train_pct: float=0.9):\n",
    "    n = freqs.shape[1]\n",
    "    assert split in ['train', 'val']\n",
    "    n_train = int(n * train_pct)\n",
    "    low = 0 if split == 'train' else n_train\n",
    "    high = n_train if split == 'train' else n\n",
    "\n",
    "    batch_indices = torch.randint(low=low, high=high, size=(batch_size,), dtype=torch.long)\n",
    "    batch_strings = [strings20k[i.item()] for i in batch_indices]\n",
    "\n",
    "    tokens = encoding_helpers.tokenize_strings(batch_strings)\n",
    "    logits, _ = m(tokens)\n",
    "    model_output = F.softmax(logits[:, -1, :], dim=-1)\n",
    "\n",
    "    return freqs[:, batch_indices, :].clone(), model_output.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=500\n",
    "eval_iters = 100\n",
    "\n",
    "get_batch_func = partial(get_batch, batch_size=batch_size, freqs=ffwd_freqs, train_pct=0.9)\n",
    "estimate_loss_func = partial(estimate_loss, get_batch_func=get_batch_func, eval_iters=eval_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(1337) # Ensure stable random values\n",
    "m2 = ModelSim()\n",
    "_ = m2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = results_folder / 'learn_coefficients'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "checkpointer = CheckPointer(output_dir, 'coeff_model_checkpoint', start_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=m2,\n",
    "    checkpointer=checkpointer,\n",
    "    get_batch_func=get_batch_func,\n",
    "    estimate_loss_func=estimate_loss_func,\n",
    "    iters_trained=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(355.8277), 'val': tensor(390.0248)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a starting point for the loss\n",
    "estimate_loss_func(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56229a8f8f3b4439be223b41f16c3a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 92.6609, val loss 94.5815\n",
      "step 999: train loss 98.4017, val loss 101.1536\n"
     ]
    }
   ],
   "source": [
    "# Start with a pretty high learning rate and go for 1000 iterations\n",
    "learning_rate = 3e-2\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer.train(1000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it got to a good place and then quickly overshot. But we don't know if it would have recovered because we stopped after that. Let's keep going and see what happens. We can always backtrack if it keeps getting worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9058ef56c0d1498fb4fcc6b83b87e94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 98.9964, val loss 99.9345\n",
      "step 999: train loss 96.9539, val loss 97.9114\n",
      "step 1499: train loss 90.8162, val loss 92.1447\n",
      "step 1999: train loss 101.1968, val loss 103.3944\n",
      "step 2499: train loss 101.8853, val loss 104.0021\n",
      "step 2999: train loss 100.8928, val loss 104.1331\n",
      "step 3499: train loss 101.3843, val loss 103.6743\n",
      "step 3999: train loss 101.1491, val loss 104.2174\n",
      "step 4499: train loss 101.8255, val loss 103.3381\n",
      "step 4999: train loss 100.8471, val loss 103.2514\n"
     ]
    }
   ],
   "source": [
    "trainer.train(5000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that got better but then overshot. Let's go back to the good point and try a smaller learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, tensor(90.8162), tensor(92.1447))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpointer.output_dir / 'coeff_model_checkpoint_000004.pt')\n",
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are back at a good state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0998]],\n",
       "\n",
       "        [[0.0701]],\n",
       "\n",
       "        [[0.1811]],\n",
       "\n",
       "        [[0.1651]],\n",
       "\n",
       "        [[0.3011]],\n",
       "\n",
       "        [[0.3028]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.781\n",
      "Top 1 matches (any order): 0.781\n",
      "Top 2 matches: 0.474\n",
      "Top 2 matches (any order): 0.549\n",
      "Top 3 matches: 0.331\n",
      "Top 3 matches (any order): 0.393\n",
      "Top 4 matches: 0.266\n",
      "Top 4 matches (any order): 0.334\n",
      "Top 5 matches: 0.206\n",
      "Top 5 matches (any order): 0.245\n",
      "Top 6 matches: 0.163\n",
      "Top 6 matches (any order): 0.197\n",
      "Top 7 matches: 0.129\n",
      "Top 7 matches (any order): 0.153\n",
      "Top 8 matches: 0.104\n",
      "Top 8 matches (any order): 0.124\n",
      "Top 9 matches: 0.087\n",
      "Top 9 matches (any order): 0.092\n",
      "Top 10 matches: 0.057\n",
      "Top 10 matches (any order): 0.059\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad but we know we can do better. Let's reduce the learning rate and keep going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95e52ccd54843f9936156885abc9a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 86.7844, val loss 85.1847\n",
      "step 999: train loss 89.7584, val loss 85.5004\n",
      "step 1499: train loss 86.8556, val loss 85.5568\n",
      "step 1999: train loss 87.6787, val loss 85.1027\n"
     ]
    }
   ],
   "source": [
    "# Reduce the learning rate by one order of magnitude\n",
    "learning_rate = 3e-3\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "trainer.train(2000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0063]],\n",
       "\n",
       "        [[-0.0217]],\n",
       "\n",
       "        [[ 0.1207]],\n",
       "\n",
       "        [[ 0.2180]],\n",
       "\n",
       "        [[ 0.3632]],\n",
       "\n",
       "        [[ 0.3682]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.795\n",
      "Top 1 matches (any order): 0.795\n",
      "Top 2 matches: 0.486\n",
      "Top 2 matches (any order): 0.558\n",
      "Top 3 matches: 0.333\n",
      "Top 3 matches (any order): 0.397\n",
      "Top 4 matches: 0.268\n",
      "Top 4 matches (any order): 0.338\n",
      "Top 5 matches: 0.206\n",
      "Top 5 matches (any order): 0.250\n",
      "Top 6 matches: 0.166\n",
      "Top 6 matches (any order): 0.199\n",
      "Top 7 matches: 0.127\n",
      "Top 7 matches (any order): 0.151\n",
      "Top 8 matches: 0.104\n",
      "Top 8 matches (any order): 0.124\n",
      "Top 9 matches: 0.085\n",
      "Top 9 matches (any order): 0.090\n",
      "Top 10 matches: 0.052\n",
      "Top 10 matches (any order): 0.058\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing well. Let's try a few more rounds at the same rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3902c4b2ea4a5ba64ce490b5edfeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 88.2698, val loss 85.8976\n",
      "step 999: train loss 111.8359, val loss 105.2479\n",
      "step 1499: train loss 84.7038, val loss 85.9471\n",
      "step 1999: train loss 84.9063, val loss 85.6737\n"
     ]
    }
   ],
   "source": [
    "trainer.train(2000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It got lost but came back to a good spot. It hasn't made a ton of progress, though, so may be stuck. Let's try an even smaller learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5883fb58a404984807fbb402c8702c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 80.4703, val loss 81.8304\n",
      "step 999: train loss 80.1729, val loss 80.9812\n",
      "step 1499: train loss 79.5038, val loss 81.0121\n",
      "step 1999: train loss 79.6113, val loss 81.1012\n"
     ]
    }
   ],
   "source": [
    "# Go down one more order of magnitude\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "trainer.train(2000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going well. Let's let it run a bit more to see if there is more to be gained at this learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b033abf8b84109bd355f8213e8b018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 79.9726, val loss 80.9605\n",
      "step 999: train loss 79.8885, val loss 80.7976\n",
      "step 1499: train loss 79.4328, val loss 80.5349\n",
      "step 1999: train loss 79.6406, val loss 80.7106\n",
      "step 2499: train loss 78.8512, val loss 79.3027\n",
      "step 2999: train loss 92.4660, val loss 84.4240\n",
      "step 3499: train loss 88.8365, val loss 85.2693\n",
      "step 3999: train loss 89.9178, val loss 84.7041\n",
      "step 4499: train loss 89.9341, val loss 85.5066\n",
      "step 4999: train loss 90.7773, val loss 84.8867\n"
     ]
    }
   ],
   "source": [
    "# Train some more\n",
    "trainer.train(5000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That got better but then went off the rails. Let's go back to the best checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14500, tensor(78.8512), tensor(79.3027))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpointer.output_dir / 'coeff_model_checkpoint_000028.pt')\n",
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.8330e-03]],\n",
       "\n",
       "        [[-1.5296e-03]],\n",
       "\n",
       "        [[-2.2343e-04]],\n",
       "\n",
       "        [[ 9.7601e-02]],\n",
       "\n",
       "        [[ 7.6696e-01]],\n",
       "\n",
       "        [[ 1.0677e-01]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.802\n",
      "Top 1 matches (any order): 0.802\n",
      "Top 2 matches: 0.497\n",
      "Top 2 matches (any order): 0.566\n",
      "Top 3 matches: 0.344\n",
      "Top 3 matches (any order): 0.405\n",
      "Top 4 matches: 0.275\n",
      "Top 4 matches (any order): 0.335\n",
      "Top 5 matches: 0.207\n",
      "Top 5 matches (any order): 0.246\n",
      "Top 6 matches: 0.166\n",
      "Top 6 matches (any order): 0.196\n",
      "Top 7 matches: 0.127\n",
      "Top 7 matches (any order): 0.148\n",
      "Top 8 matches: 0.106\n",
      "Top 8 matches (any order): 0.123\n",
      "Top 9 matches: 0.085\n",
      "Top 9 matches (any order): 0.086\n",
      "Top 10 matches: 0.052\n",
      "Top 10 matches (any order): 0.055\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's nearly as good as the hand-rolled coefficients. Let's try a few more rounds at a smaller learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef7b322868940a5b1f6eadbd9012726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 79.0625, val loss 79.1941\n",
      "step 999: train loss 78.2563, val loss 79.1195\n",
      "step 1499: train loss 78.3124, val loss 78.8700\n",
      "step 1999: train loss 78.4172, val loss 79.0324\n",
      "step 2499: train loss 77.7076, val loss 78.5610\n",
      "step 2999: train loss 78.0883, val loss 77.9647\n",
      "step 3499: train loss 76.2281, val loss 76.7733\n",
      "step 3999: train loss 76.0516, val loss 77.5841\n",
      "step 4499: train loss 76.8096, val loss 77.2572\n",
      "step 4999: train loss 76.8454, val loss 77.1808\n"
     ]
    }
   ],
   "source": [
    "# Go down one more order of magnitude\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(m2.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train some more\n",
    "trainer.train(5000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvement! Not clear if it's stabilized or not, so let's keep going. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0715f6372e24d249e0515b2b1f53a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 76.4978, val loss 77.1828\n",
      "step 999: train loss 77.1313, val loss 77.3532\n",
      "step 1499: train loss 76.6558, val loss 77.2998\n",
      "step 1999: train loss 76.8978, val loss 77.4199\n",
      "step 2499: train loss 76.5466, val loss 77.0944\n",
      "step 2999: train loss 76.1288, val loss 76.6329\n",
      "step 3499: train loss 76.5751, val loss 77.8199\n",
      "step 3999: train loss 76.8902, val loss 77.1575\n",
      "step 4499: train loss 76.8581, val loss 77.5016\n",
      "step 4999: train loss 76.1585, val loss 77.7288\n"
     ]
    }
   ],
   "source": [
    "trainer.train(5000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, doesn't seem to be going anywhere. Let's go back to the best checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, tensor(76.0516), tensor(77.5841))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpointer.output_dir / 'coeff_model_checkpoint_000041.pt')\n",
    "checkpoint['iters'], checkpoint['train_loss'], checkpoint['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.6905e-03]],\n",
       "\n",
       "        [[-1.5016e-03]],\n",
       "\n",
       "        [[ 2.6866e-04]],\n",
       "\n",
       "        [[ 1.2218e-01]],\n",
       "\n",
       "        [[ 8.1634e-01]],\n",
       "\n",
       "        [[ 7.6261e-05]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.806\n",
      "Top 1 matches (any order): 0.806\n",
      "Top 2 matches: 0.501\n",
      "Top 2 matches (any order): 0.566\n",
      "Top 3 matches: 0.341\n",
      "Top 3 matches (any order): 0.402\n",
      "Top 4 matches: 0.270\n",
      "Top 4 matches (any order): 0.334\n",
      "Top 5 matches: 0.205\n",
      "Top 5 matches (any order): 0.244\n",
      "Top 6 matches: 0.163\n",
      "Top 6 matches (any order): 0.193\n",
      "Top 7 matches: 0.123\n",
      "Top 7 matches (any order): 0.148\n",
      "Top 8 matches: 0.103\n",
      "Top 8 matches (any order): 0.122\n",
      "Top 9 matches: 0.085\n",
      "Top 9 matches (any order): 0.088\n",
      "Top 10 matches: 0.053\n",
      "Top 10 matches (any order): 0.056\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m2(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really, really close to the best hand-rolled coefficients. It doesn't seem to be getting better so let's stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we initialize with the hand-rolled weights and see if it can improve that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = ModelSim()\n",
    "m3.coeffs = torch.nn.Parameter(torch.tensor([0.01, 0.01, 0.1, 1.5, 6, 0.01]).unsqueeze(dim=1).unsqueeze(dim=2))\n",
    "m3.coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = results_folder / 'learn_coefficients'\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "checkpointer = CheckPointer(output_dir, 'coeff_model_hand_rolled_checkpoint', start_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=m3,\n",
    "    checkpointer=checkpointer,\n",
    "    get_batch_func=get_batch_func,\n",
    "    estimate_loss_func=estimate_loss_func,\n",
    "    iters_trained=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': tensor(77.4965), 'val': tensor(78.0544)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a starting point for the loss\n",
    "estimate_loss_func(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3548daae1b49b39364d83e75c1451d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 76.9864, val loss 77.7938\n",
      "step 999: train loss 76.9611, val loss 77.3218\n"
     ]
    }
   ],
   "source": [
    "# Begin with a moderate learning rate\n",
    "learning_rate = 3e-4\n",
    "optimizer = torch.optim.AdamW(m3.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer.train(1000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very slightly better, but doesn't seem to be going anywhere. Let's reduce the learning rate and run for longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46080e55ab48467d8e18ecb56f7ed2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 499: train loss 76.7579, val loss 77.3010\n",
      "step 999: train loss 76.2980, val loss 77.7475\n",
      "step 1499: train loss 76.2058, val loss 77.4439\n",
      "step 1999: train loss 76.5784, val loss 76.7124\n",
      "step 2499: train loss 76.6791, val loss 77.5712\n",
      "step 2999: train loss 76.7577, val loss 77.4296\n",
      "step 3499: train loss 76.3487, val loss 77.2223\n",
      "step 3999: train loss 76.9857, val loss 77.4700\n",
      "step 4499: train loss 77.6480, val loss 77.1776\n",
      "step 4999: train loss 76.2195, val loss 76.9608\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(m3.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer.train(5000, optimizer, eval_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better but does not seem to be improving. This is probably about as good as it gets. Let's see where we ended up. | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.4375e-02]],\n",
       "\n",
       "        [[-1.1588e-02]],\n",
       "\n",
       "        [[-6.7676e-04]],\n",
       "\n",
       "        [[ 1.2653e+00]],\n",
       "\n",
       "        [[ 6.1962e+00]],\n",
       "\n",
       "        [[ 4.2160e-04]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.coeffs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.806\n",
      "Top 1 matches (any order): 0.806\n",
      "Top 2 matches: 0.501\n",
      "Top 2 matches (any order): 0.566\n",
      "Top 3 matches: 0.340\n",
      "Top 3 matches (any order): 0.402\n",
      "Top 4 matches: 0.271\n",
      "Top 4 matches (any order): 0.335\n",
      "Top 5 matches: 0.206\n",
      "Top 5 matches (any order): 0.245\n",
      "Top 6 matches: 0.163\n",
      "Top 6 matches (any order): 0.193\n",
      "Top 7 matches: 0.123\n",
      "Top 7 matches (any order): 0.147\n",
      "Top 8 matches: 0.104\n",
      "Top 8 matches (any order): 0.121\n",
      "Top 9 matches: 0.084\n",
      "Top 9 matches (any order): 0.087\n",
      "Top 10 matches: 0.053\n",
      "Top 10 matches (any order): 0.055\n"
     ]
    }
   ],
   "source": [
    "total_probs, _ = m3(ffwd_freqs)\n",
    "topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / ffwd_freqs.shape[1]:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / ffwd_freqs.shape[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar to what the model got to from random initialization. And also just a hair worse than the hand-rolled coefficients. There's probably not much more juice to squeeze out of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Results for Strings Used in Training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_histories_dir = environment.data_root / 'model-training/20231112-training/batch_histories'\n",
    "test_eq(batch_histories_dir.exists(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the training log, the final model we ended up using is from the checkpoint file `shakespeare_checkpoint_000008.pt`. And it was a straight succession of training runs to get to that point (no backtracking to intermediate checkpoints). So the relevant history is just all the batch histories up to the final checkpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_history_files = [\n",
    "    'batch_history_0000.pt',\n",
    "    'batch_history_0001.pt',\n",
    "    'batch_history_0002.pt',\n",
    "    'batch_history_0003.pt',\n",
    "    'batch_history_0004.pt',\n",
    "    'batch_history_0005.pt',\n",
    "    'batch_history_0006.pt',\n",
    "    'batch_history_0007.pt',\n",
    "    'batch_history_0008.pt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4500, 64, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_history = torch.cat([\n",
    "    torch.load(batch_histories_dir / batch_history_file)['batch_history']\n",
    "    for batch_history_file in batch_history_files\n",
    "], dim=0)\n",
    "full_history.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process used a batch size of 64. So the shape above indicates we did 4500 iterations with 64 strings per iteration. The grouping into batches isn't meaningful, so we can just combine the first two dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([288000, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert full_history.shape[-1] == block_size\n",
    "full_history = full_history.reshape(-1, block_size)\n",
    "full_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The history data consists of tokens. Now  we turn those into strings.\n",
    "# We'll create a map of unique strings to the count of times they were\n",
    "# trained on.\n",
    "\n",
    "strings_trained_on = defaultdict(int)\n",
    "n_strings, _ = full_history.shape\n",
    "for i in range(n_strings):\n",
    "    string = encoding_helpers.stringify_tokens(full_history[i, :])\n",
    "    strings_trained_on[string] += 1\n",
    "strings_trained_on.default_factory = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250403"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(strings_trained_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(221305, 221236, 780165)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-compute some things that will make later lookups faster\n",
    "\n",
    "# All the evaluation in this notebook is done on length 10 strings\n",
    "slen = 10\n",
    "\n",
    "# All length 10 strings that appeared at the start of any training string\n",
    "prefixes_trained_on = defaultdict(int)\n",
    "for string, count in strings_trained_on.items():\n",
    "    prefixes_trained_on[string[:slen]] += count\n",
    "prefixes_trained_on.default_factory = None\n",
    "\n",
    "# All length 10 strings that appeared at the end of any training string\n",
    "suffixes_trained_on = defaultdict(int)\n",
    "for string, count in strings_trained_on.items():\n",
    "    suffixes_trained_on[string[-slen:]] += count\n",
    "suffixes_trained_on.default_factory = None\n",
    "\n",
    "# All length 10 strings that appeared anywhere in any training string\n",
    "substrings_trained_on = defaultdict(int)\n",
    "for string, count in strings_trained_on.items():\n",
    "    for substring in all_unique_substrings(string, 10):\n",
    "        substrings_trained_on[substring] += count\n",
    "substrings_trained_on.default_factory = None\n",
    "\n",
    "len(prefixes_trained_on), len(suffixes_trained_on), len(substrings_trained_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_trained_on(\n",
    "    strings: Sequence[str],\n",
    "    trained_on: Dict[str, int],\n",
    ") -> Tuple[List[str], torch.Tensor]:\n",
    "    strings_used_in_training = []\n",
    "    indicies_used_in_training = []\n",
    "\n",
    "    for i, string in enumerate(strings):\n",
    "        if string in trained_on:\n",
    "            strings_used_in_training.append(string)\n",
    "            indicies_used_in_training.append(i)\n",
    "\n",
    "    return strings_used_in_training, torch.tensor(\n",
    "        indicies_used_in_training, dtype=torch.long\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_subset(\n",
    "    indices_to_consider: torch.Tensor,\n",
    "    model_outputs: Sequence[Sequence[Tuple[str, float]]],\n",
    "    ffwd_freqs: torch.Tensor,\n",
    "    coeffs: torch.Tensor,\n",
    "):\n",
    "    model_outputs_subset = []\n",
    "    for i in indices_to_consider:\n",
    "        model_outputs_subset.append(model_outputs[i.item()])\n",
    "\n",
    "    n_items = len(indices_to_consider)\n",
    "    total_freqs = (ffwd_freqs[:, indices_to_consider, :] * coeffs).sum(dim=0)\n",
    "    total_probs = total_freqs / total_freqs.sum(dim=-1, keepdim=True)\n",
    "    topn_matches, topn_matches_any_order = analyze_simulate_results(total_probs, model_outputs_subset)\n",
    "    for i in range(10):\n",
    "        print(f\"Top {i+1} matches: {topn_matches[i] / n_items:.3f}\")\n",
    "        print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / n_items:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_rolled_coeffs = torch.tensor([0.01, 0.01, 0.1, 1.5, 4, 0.01]).unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5132 of 20000 strings used in training\n",
      "Top 1 matches: 0.809\n",
      "Top 1 matches (any order): 0.809\n",
      "Top 2 matches: 0.499\n",
      "Top 2 matches (any order): 0.569\n",
      "Top 3 matches: 0.337\n",
      "Top 3 matches (any order): 0.403\n",
      "Top 4 matches: 0.272\n",
      "Top 4 matches (any order): 0.334\n",
      "Top 5 matches: 0.208\n",
      "Top 5 matches (any order): 0.256\n",
      "Top 6 matches: 0.171\n",
      "Top 6 matches (any order): 0.204\n",
      "Top 7 matches: 0.130\n",
      "Top 7 matches (any order): 0.157\n",
      "Top 8 matches: 0.105\n",
      "Top 8 matches (any order): 0.128\n",
      "Top 9 matches: 0.088\n",
      "Top 9 matches (any order): 0.090\n",
      "Top 10 matches: 0.056\n",
      "Top 10 matches (any order): 0.059\n"
     ]
    }
   ],
   "source": [
    "# Prefixes\n",
    "strings_used_in_training, indices_used_in_training = filter_by_trained_on(\n",
    "    strings20k,\n",
    "    prefixes_trained_on,\n",
    ")\n",
    "print(f\"{len(strings_used_in_training)} of {len(strings20k)} strings used in training\")\n",
    "\n",
    "eval_on_subset(indices_used_in_training, model_outputs, ffwd_freqs, hand_rolled_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5132 of 20000 strings used in training\n",
      "Top 1 matches: 0.810\n",
      "Top 1 matches (any order): 0.810\n",
      "Top 2 matches: 0.498\n",
      "Top 2 matches (any order): 0.568\n",
      "Top 3 matches: 0.345\n",
      "Top 3 matches (any order): 0.402\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.329\n",
      "Top 5 matches: 0.207\n",
      "Top 5 matches (any order): 0.246\n",
      "Top 6 matches: 0.170\n",
      "Top 6 matches (any order): 0.194\n",
      "Top 7 matches: 0.131\n",
      "Top 7 matches (any order): 0.157\n",
      "Top 8 matches: 0.108\n",
      "Top 8 matches (any order): 0.129\n",
      "Top 9 matches: 0.087\n",
      "Top 9 matches (any order): 0.090\n",
      "Top 10 matches: 0.061\n",
      "Top 10 matches (any order): 0.062\n"
     ]
    }
   ],
   "source": [
    "# Suffixes\n",
    "strings_used_in_training, indices_used_in_training = filter_by_trained_on(\n",
    "    strings20k,\n",
    "    suffixes_trained_on,\n",
    ")\n",
    "print(f\"{len(strings_used_in_training)} of {len(strings20k)} strings used in training\")\n",
    "\n",
    "eval_on_subset(indices_used_in_training, model_outputs, ffwd_freqs, hand_rolled_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a huge coincidence that the number of the 20,000 eval strings that appeared as prefixes and the number that appeared as suffixes is 5132. Let's double check that these aren't exactly the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "strings_used_in_training_prefix, indices_used_in_training_prefix = filter_by_trained_on(\n",
    "    strings20k,\n",
    "    prefixes_trained_on,\n",
    ")\n",
    "strings_used_in_training_suffix, indices_used_in_training_suffix = filter_by_trained_on(\n",
    "    strings20k,\n",
    "    suffixes_trained_on,\n",
    ")\n",
    "\n",
    "test_eq(all(indices_used_in_training_prefix == indices_used_in_training_suffix), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These aren't the same 5132 strings, so maybe it is just a coincidence. Carrying on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18171 of 20000 strings used in training\n",
      "Top 1 matches: 0.809\n",
      "Top 1 matches (any order): 0.809\n",
      "Top 2 matches: 0.502\n",
      "Top 2 matches (any order): 0.570\n",
      "Top 3 matches: 0.344\n",
      "Top 3 matches (any order): 0.407\n",
      "Top 4 matches: 0.274\n",
      "Top 4 matches (any order): 0.338\n",
      "Top 5 matches: 0.210\n",
      "Top 5 matches (any order): 0.251\n",
      "Top 6 matches: 0.169\n",
      "Top 6 matches (any order): 0.198\n",
      "Top 7 matches: 0.129\n",
      "Top 7 matches (any order): 0.154\n",
      "Top 8 matches: 0.106\n",
      "Top 8 matches (any order): 0.125\n",
      "Top 9 matches: 0.087\n",
      "Top 9 matches (any order): 0.091\n",
      "Top 10 matches: 0.056\n",
      "Top 10 matches (any order): 0.058\n"
     ]
    }
   ],
   "source": [
    "# Substrings anywhere\n",
    "strings_used_in_training, indices_used_in_training = filter_by_trained_on(\n",
    "    strings20k,\n",
    "    substrings_trained_on,\n",
    ")\n",
    "print(f\"{len(strings_used_in_training)} of {len(strings20k)} strings used in training\")\n",
    "\n",
    "eval_on_subset(indices_used_in_training, model_outputs, ffwd_freqs, hand_rolled_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "\n",
    "1. Most of the eval strings appeared somewhere in the training strings. \n",
    "2. Filtering down to eval strings that were just prefixes or suffixes of training strings greatly reduces the number of strings in the sample, and while this does give a small lift to the top 1 accuracy, it slightly reduces everything else. \n",
    "3. Considering the strings that appeared anywhere in the training strings very slightly lifts accuracy.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Characteristics of the Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 0.5250111222267151),\n",
       " (' ', 0.46654149889945984),\n",
       " ('-', 0.007815942168235779),\n",
       " (\"'\", 0.00047109558363445103),\n",
       " ('.', 2.7687412512023002e-05),\n",
       " (',', 1.7208614735864103e-05),\n",
       " (':', 1.5419789633597247e-05),\n",
       " ('?', 1.3534416211768985e-05),\n",
       " (';', 9.159703949990217e-06),\n",
       " ('l', 8.144122148223687e-06)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What do the model outputs look like?\n",
    "model_outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_model_outputs(\n",
    "    model_outputs: Sequence[Sequence[Tuple[str, float]]],\n",
    "    filter_fn: Callable[[Sequence[Tuple[str, float]]], bool],\n",
    ") -> torch.Tensor:\n",
    "    matching_indices = []\n",
    "    for i, model_output in enumerate(model_outputs):\n",
    "        if filter_fn(model_output):\n",
    "            matching_indices.append(i)\n",
    "    return torch.tensor(matching_indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3057 of 20000 string\n",
      "Top 1 matches: 0.998\n",
      "Top 1 matches (any order): 0.998\n",
      "Top 2 matches: 0.349\n",
      "Top 2 matches (any order): 0.351\n",
      "Top 3 matches: 0.137\n",
      "Top 3 matches (any order): 0.149\n",
      "Top 4 matches: 0.060\n",
      "Top 4 matches (any order): 0.062\n",
      "Top 5 matches: 0.028\n",
      "Top 5 matches (any order): 0.026\n",
      "Top 6 matches: 0.020\n",
      "Top 6 matches (any order): 0.022\n",
      "Top 7 matches: 0.013\n",
      "Top 7 matches (any order): 0.012\n",
      "Top 8 matches: 0.011\n",
      "Top 8 matches (any order): 0.010\n",
      "Top 9 matches: 0.010\n",
      "Top 9 matches (any order): 0.008\n",
      "Top 10 matches: 0.005\n",
      "Top 10 matches (any order): 0.004\n"
     ]
    }
   ],
   "source": [
    "matching_indices = filter_model_outputs(\n",
    "    model_outputs,\n",
    "    lambda model_output: model_output[0][1] > 0.99,\n",
    ")\n",
    "print(f\"{len(matching_indices)} of {len(model_outputs)} string\")\n",
    "eval_on_subset(matching_indices, model_outputs, ffwd_freqs, hand_rolled_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10710 of 20000 string\n",
      "Top 1 matches: 0.936\n",
      "Top 1 matches (any order): 0.936\n",
      "Top 2 matches: 0.601\n",
      "Top 2 matches (any order): 0.652\n",
      "Top 3 matches: 0.367\n",
      "Top 3 matches (any order): 0.421\n",
      "Top 4 matches: 0.256\n",
      "Top 4 matches (any order): 0.318\n",
      "Top 5 matches: 0.148\n",
      "Top 5 matches (any order): 0.182\n",
      "Top 6 matches: 0.110\n",
      "Top 6 matches (any order): 0.136\n",
      "Top 7 matches: 0.082\n",
      "Top 7 matches (any order): 0.098\n",
      "Top 8 matches: 0.069\n",
      "Top 8 matches (any order): 0.087\n",
      "Top 9 matches: 0.061\n",
      "Top 9 matches (any order): 0.069\n",
      "Top 10 matches: 0.023\n",
      "Top 10 matches (any order): 0.022\n"
     ]
    }
   ],
   "source": [
    "matching_indices = filter_model_outputs(\n",
    "    model_outputs,\n",
    "    lambda model_output: sum([model_output[i][1] for i in range(2)]) > 0.85,\n",
    ")\n",
    "print(f\"{len(matching_indices)} of {len(model_outputs)} string\")\n",
    "eval_on_subset(matching_indices, model_outputs, ffwd_freqs, hand_rolled_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10710 of 20000 string\n",
      "Top 1 matches: 0.939\n",
      "Top 1 matches (any order): 0.939\n",
      "Top 2 matches: 0.603\n",
      "Top 2 matches (any order): 0.652\n",
      "Top 3 matches: 0.366\n",
      "Top 3 matches (any order): 0.414\n",
      "Top 4 matches: 0.252\n",
      "Top 4 matches (any order): 0.315\n",
      "Top 5 matches: 0.145\n",
      "Top 5 matches (any order): 0.178\n",
      "Top 6 matches: 0.106\n",
      "Top 6 matches (any order): 0.133\n",
      "Top 7 matches: 0.077\n",
      "Top 7 matches (any order): 0.095\n",
      "Top 8 matches: 0.066\n",
      "Top 8 matches (any order): 0.085\n",
      "Top 9 matches: 0.061\n",
      "Top 9 matches (any order): 0.068\n",
      "Top 10 matches: 0.023\n",
      "Top 10 matches (any order): 0.022\n"
     ]
    }
   ],
   "source": [
    "custom_coeffs = torch.tensor([0.1, 0.1, 15, 10, 1000, 0.1]).unsqueeze(dim=1).unsqueeze(dim=2) # (n_layer, 1, 1)\n",
    "matching_indices = filter_model_outputs(\n",
    "    model_outputs,\n",
    "    lambda model_output: sum([model_output[i][1] for i in range(2)]) > 0.85,\n",
    ")\n",
    "print(f\"{len(matching_indices)} of {len(model_outputs)} string\")\n",
    "eval_on_subset(matching_indices, model_outputs, ffwd_freqs, custom_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Sims for Length 256 Strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings256 = all_unique_substrings(ts.text, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "sample_size = 500\n",
    "indices256 = torch.randperm(len(strings256))[:sample_size]\n",
    "strings256_sample = [strings256[i.item()] for i in indices256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs_sample256 = get_model_outputs(strings256_sample, encoding_helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_exp256 = BlockInternalsExperiment(encoding_helpers, accessors, strings256_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilaritiesForFinalFFWDExperiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        exp: FinalFFWDExperiment,\n",
    "        output_folder: Path,\n",
    "    ):\n",
    "        self.exp = exp\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        self.n_batches = exp.n_batches\n",
    "\n",
    "    def ffwd_out_sims_filename(self, batch_idx: int, block_idx: int):\n",
    "        return self.output_folder / f'ffwds_out_sims_{batch_idx:04d}_{block_idx:02d}.pt'\n",
    "\n",
    "    def generate_ffwd_out_sims(self, get_queries: Callable[[int], torch.Tensor], disable_progress_bar=False):\n",
    "        block_idx = n_layer - 1\n",
    "        for batch_idx in tqdm(range(self.exp.n_batches), disable=disable_progress_bar):\n",
    "            queries = get_queries(block_idx)\n",
    "            assert queries.dim() == 2\n",
    "            n_queries = queries.shape[0]\n",
    "\n",
    "            ffwd_out_batch = torch.load(str(self.exp._ffwd_output_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True)\n",
    "            batch_size = ffwd_out_batch.shape[0]\n",
    "            sims = F.cosine_similarity(\n",
    "                ffwd_out_batch.reshape(batch_size, 1, -1).expand(-1, n_queries, -1),\n",
    "                queries,\n",
    "                dim=-1\n",
    "            )\n",
    "            torch.save(sims, str(self.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd_exp256 = FinalFFWDExperiment(\n",
    "    eh=encoding_helpers,\n",
    "    accessors=accessors,\n",
    "    strings=strings256,\n",
    "    output_dir=environment.data_root / 'block_internals_results/large_files/slen256',\n",
    "    batch_size=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ffwd_exp256.output_dir / 'cosine_sims'\n",
    "output_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_exp256 = CosineSimilaritiesForFinalFFWDExperiment(ffwd_exp256, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa11ce5d335947219d9e20bb0294dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2788 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos_exp256.generate_ffwd_out_sims(get_queries=lambda block_idx: prompts_exp256.ffwd_output(block_idx=block_idx)[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_map256 = build_next_token_map(ts.text, 256, tokenizer.vocab_size, tokenizer.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min': 1, 'max': 38780, 'mean': 1561.9, 'std': 4162.8430373964375}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_idx = n_layer - 1\n",
    "ffwd256 = filter_across_batches(\n",
    "    get_batch=lambda batch_idx: torch.load(str(cos_exp256.ffwd_out_sims_filename(batch_idx=batch_idx, block_idx=block_idx)), mmap=True),\n",
    "    n_batches=cos_exp256.n_batches,\n",
    "    filter_fn=lambda batch: batch > 0.91,\n",
    "    n_queries=sample_size,\n",
    ")\n",
    "filter_result_stats(ffwd256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd256_strings = get_matching_strings(ffwd256, strings256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffwd256_freqs = [\n",
    "    torch.stack([\n",
    "        next_token_map256[matching_string]\n",
    "        for matching_string in matching_strings\n",
    "    ]).sum(dim=0)\n",
    "    for matching_strings in ffwd256_strings\n",
    "]\n",
    "ffwd256_probs = [\n",
    "    freqs / freqs.sum()\n",
    "    for freqs in ffwd256_freqs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 matches: 0.802\n",
      "Top 1 matches (any order): 0.802\n",
      "Top 2 matches: 0.362\n",
      "Top 2 matches (any order): 0.412\n",
      "Top 3 matches: 0.246\n",
      "Top 3 matches (any order): 0.298\n",
      "Top 4 matches: 0.200\n",
      "Top 4 matches (any order): 0.250\n",
      "Top 5 matches: 0.156\n",
      "Top 5 matches (any order): 0.154\n",
      "Top 6 matches: 0.128\n",
      "Top 6 matches (any order): 0.148\n",
      "Top 7 matches: 0.070\n",
      "Top 7 matches (any order): 0.086\n",
      "Top 8 matches: 0.044\n",
      "Top 8 matches (any order): 0.068\n",
      "Top 9 matches: 0.032\n",
      "Top 9 matches (any order): 0.038\n",
      "Top 10 matches: 0.030\n",
      "Top 10 matches (any order): 0.016\n"
     ]
    }
   ],
   "source": [
    "topn_matches, topn_matches_any_order = analyze_simulate_results(ffwd256_probs, model_outputs_sample256)\n",
    "for i in range(10):\n",
    "    print(f\"Top {i+1} matches: {topn_matches[i] / sample_size:.3f}\")\n",
    "    print(f\"Top {i+1} matches (any order): {topn_matches_any_order[i] / sample_size:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0 (\" see my shame in him.\\nThou art a widow; yet thou art a mother,\\nAnd hast the comfort of thy children left thee:\\nBut death hath snatch'd my husband from mine arms,\\nAnd pluck'd two crutches from my feeble limbs,\\nEdward and Clarence. O, what cause have I,\\nThin\"): \n",
      "  \" so.\\n\\nSICINIUS:\\nLet them assemble,\\nAnd on a safer judgment all revoke\\nYour ignorant election; enforce his pride,\\nAnd his old hate unto you; besides, forget not\\nWith what contempt he wore the humble weed,\\nHow in his suit he scorn'd you; but your loves,\\nThin\"\n",
      "  \"I'ld have beaten him like a dog, but for\\ndisturbing the lords within.\\n\\nAUFIDIUS:\\nWhence comest thou? what wouldst thou? thy name?\\nWhy speak'st not? speak, man: what's thy name?\\n\\nCORIOLANUS:\\nIf, Tullus,\\nNot yet thou knowest me, and, seeing me, dost not\\nThin\"\n",
      "  \"e not--to save my life, for if\\nI had fear'd death, of all the men i' the world\\nI would have 'voided thee, but in mere spite,\\nTo be full quit of those my banishers,\\nStand I before thee here. Then if thou hast\\nA heart of wreak in thee, that wilt revenge\\nThin\"\n",
      "  \"t,\\nwhich should\\nMake our eyes flow with joy, hearts dance\\nwith comforts,\\nConstrains them weep and shake with fear and sorrow;\\nMaking the mother, wife and child to see\\nThe son, the husband and the father tearing\\nHis country's bowels out. And to poor we\\nThin\"\n",
      "  \" abhorr'd.' Speak to me, son:\\nThou hast affected the fine strains of honour,\\nTo imitate the graces of the gods;\\nTo tear with thunder the wide cheeks o' the air,\\nAnd yet to charge thy sulphur with a bolt\\nThat should but rive an oak. Why dost not speak?\\nThin\"\n",
      "  \"d me, in the field by Tewksbury\\nWhen Oxford had me down, he rescued me,\\nAnd said, 'Dear brother, live, and be a king'?\\nWho told me, when we both lay in the field\\nFrozen almost to death, how he did lap me\\nEven in his own garments, and gave himself,\\nAll thin\"\n",
      "  \" see my shame in him.\\nThou art a widow; yet thou art a mother,\\nAnd hast the comfort of thy children left thee:\\nBut death hath snatch'd my husband from mine arms,\\nAnd pluck'd two crutches from my feeble limbs,\\nEdward and Clarence. O, what cause have I,\\nThin\"\n",
      "  \" uncle Clarence' angry ghost:\\nMy grandam told me he was murdered there.\\n\\nPRINCE EDWARD:\\nI fear no uncles dead.\\n\\nGLOUCESTER:\\nNor none that live, I hope.\\n\\nPRINCE EDWARD:\\nAn if they live, I hope I need not fear.\\nBut come, my lord; and with a heavy heart,\\nThin\"\n",
      "  \"ard, capable\\nHe is all the mother's, from the top to toe.\\n\\nBUCKINGHAM:\\nWell, let them rest. Come hither, Catesby.\\nThou art sworn as deeply to effect what we intend\\nAs closely to conceal what we impart:\\nThou know'st our reasons urged upon the way;\\nWhat thin\"\n",
      "  \"ng that yet think not on it.\\n\\nCATESBY:\\n'Tis a vile thing to die, my gracious lord,\\nWhen men are unprepared and look not for it.\\n\\nHASTINGS:\\nO monstrous, monstrous! and so falls it out\\nWith Rivers, Vaughan, Grey: and so 'twill do\\nWith some men else, who thin\"\n",
      "  \"od morrow; good morrow, Catesby:\\nYou may jest on, but, by the holy rood,\\nI do not like these several councils, I.\\n\\nHASTINGS:\\nMy lord,\\nI hold my life as dear as you do yours;\\nAnd never in my life, I do protest,\\nWas it more precious to me than 'tis now:\\nThin\"\n",
      "  \"fitting for that royal time?\\n\\nDERBY:\\nIt is, and wants but nomination.\\n\\nBISHOP OF ELY:\\nTo-morrow, then, I judge a happy day.\\n\\nBUCKINGHAM:\\nWho knows the lord protector's mind herein?\\nWho is most inward with the royal duke?\\n\\nBISHOP OF ELY:\\nYour grace, we thin\"\n",
      "  \"e English woes will make me smile in France.\\n\\nQUEEN ELIZABETH:\\nO thou well skill'd in curses, stay awhile,\\nAnd teach me how to curse mine enemies!\\n\\nQUEEN MARGARET:\\nForbear to sleep the nights, and fast the days;\\nCompare dead happiness with living woe;\\nThin\"\n",
      "  'thy daughter,\\nAnd mean to make her queen of England.\\n\\nQUEEN ELIZABETH:\\nSay then, who dost thou mean shall be her king?\\n\\nKING RICHARD III:\\nEven he that makes her queen who should be else?\\n\\nQUEEN ELIZABETH:\\nWhat, thou?\\n\\nKING RICHARD III:\\nI, even I: what thin'\n",
      "  \"w near,\\nAnd list what with our council we have done.\\nFor that our kingdom's earth should not be soil'd\\nWith that dear blood which it hath fostered;\\nAnd for our eyes do hate the dire aspect\\nOf civil wounds plough'd up with neighbours' sword;\\nAnd for we thin\"\n",
      "  'd,\\nHaving my freedom, boast of nothing else\\nBut that I was a journeyman to grief?\\n\\nJOHN OF GAUNT:\\nAll places that the eye of heaven visits\\nAre to a wise man ports and happy havens.\\nTeach thy necessity to reason thus;\\nThere is no virtue like necessity.\\nThin'\n",
      "  \"eys-general to sue\\nHis livery, and deny his offer'd homage,\\nYou pluck a thousand dangers on your head,\\nYou lose a thousand well-disposed hearts\\nAnd prick my tender patience, to those thoughts\\nWhich honour and allegiance cannot think.\\n\\nKING RICHARD II:\\nThin\"\n",
      "  \"their complices,\\nThe caterpillars of the commonwealth,\\nWhich I have sworn to weed and pluck away.\\n\\nDUKE OF YORK:\\nIt may be I will go with you: but yet I'll pause;\\nFor I am loath to break our country's laws.\\nNor friends nor foes, to me welcome you are:\\nThin\"\n",
      "  \"ee to France\\nAnd cloister thee in some religious house:\\nOur holy lives must win a new world's crown,\\nWhich our profane hours here have stricken down.\\n\\nQUEEN:\\nWhat, is my Richard both in shape and mind\\nTransform'd and weaken'd? hath Bolingbroke deposed\\nThin\"\n",
      "  'ildly, kiss the rod,\\nAnd fawn on rage with base humility,\\nWhich art a lion and a king of beasts?\\n\\nKING RICHARD II:\\nA king of beasts, indeed; if aught but beasts,\\nI had been still a happy king of men.\\nGood sometime queen, prepare thee hence for France:\\nThin'\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(f\"Query {idx} ({repr(strings256_sample[idx])}): \")\n",
    "result = ffwd256[idx]\n",
    "for j in result[:20]:\n",
    "    print(f\"  {repr(strings256[j])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorBatchIterator:\n",
    "    def __init__(self, n_batches: int, get_batch: Callable[[int], torch.Tensor]):\n",
    "        self.n_batches = n_batches\n",
    "        self.get_batch = get_batch\n",
    "\n",
    "        self.next_batch_idx = 0\n",
    "        self.current_batch: Optional[torch.Tensor] = None\n",
    "        self.idx_within_batch = 0\n",
    "\n",
    "        self._load_next_batch()\n",
    "\n",
    "    def _load_next_batch(self):\n",
    "        if self.next_batch_idx >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "\n",
    "        self.current_batch = self.get_batch(self.next_batch_idx)\n",
    "        self.idx_within_batch = 0\n",
    "        self.next_batch_idx += 1\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch is None:\n",
    "            raise StopIteration()\n",
    "\n",
    "        if self.idx_within_batch >= self.current_batch.shape[0]:\n",
    "            self._load_next_batch()\n",
    "            if self.current_batch is None:\n",
    "                raise StopIteration()\n",
    "\n",
    "        result = self.current_batch[self.idx_within_batch, :]\n",
    "        self.idx_within_batch += 1\n",
    "        return result\n",
    "\n",
    "class EmbeddingCosineSims:\n",
    "    def __init__(self, exp: CosineSimilaritiesExperiment):\n",
    "        self.exp = exp\n",
    "\n",
    "    def __iter__(self):\n",
    "        return TensorBatchIterator(\n",
    "            n_batches=self.exp.n_batches,\n",
    "            get_batch=lambda batch_idx: torch.load(str(self.exp.embedding_sims_filename(batch_idx=batch_idx)), mmap=True)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sims = EmbeddingCosineSims(cos_exp)\n",
    "for i, sim in enumerate(emb_sims):\n",
    "    print(i, sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = next(iter(emb_sims))\n",
    "sims.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
