{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text-analysis\n",
    "\n",
    "> Useful code for analyzing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp common.text_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Dict, Iterable, Sequence, Tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def top_nonzero_tokens(freqs: torch.Tensor, itos: Dict[int, str]) -> Iterable[Tuple[str, float]]:\n",
    "    k = torch.count_nonzero(freqs).item()\n",
    "    assert isinstance(k, int) # keep mypy happy\n",
    "    topk = torch.topk(freqs, k=k)\n",
    "    return [(itos[i], freqs[i].item()) for i in topk.indices.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for top_nonzero_tokens\n",
    "itos = {0: 'a', 1: 'b', 2: 'c', 3: 'd'}\n",
    "\n",
    "# All zeros\n",
    "freqs = torch.tensor([0, 0, 0, 0])\n",
    "test_eq(top_nonzero_tokens(freqs, itos), [])\n",
    "\n",
    "# All non-zeros\n",
    "freqs = torch.tensor([1, 2, 3, 4])\n",
    "test_eq(top_nonzero_tokens(freqs, itos), [('d', 4), ('c', 3), ('b', 2), ('a', 1)])\n",
    "\n",
    "# Some zeros\n",
    "freqs = torch.tensor([0, 2, 0, 4])\n",
    "test_eq(top_nonzero_tokens(freqs, itos), [('d', 4), ('b', 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SubstringFrequencyAnalysis:\n",
    "    \"\"\"Class that performs frequency analysis on a body of text for a set of substrings.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        substrs: Sequence[str],\n",
    "        text: str,\n",
    "        vocab_size: int,\n",
    "        itos: Dict[int, str],\n",
    "        stoi: Dict[str, int],\n",
    "    ):\n",
    "        self.substrs = substrs\n",
    "        self.text = text\n",
    "        self.vocab_size = vocab_size\n",
    "        self.itos = itos\n",
    "        self.stoi = stoi\n",
    "\n",
    "        # Need at least one string to determine the length\n",
    "        # and for this to be useful.\n",
    "        assert len(substrs) > 0\n",
    "        self.s_len = len(substrs[0])\n",
    "\n",
    "        # Build frequency map of next characters\n",
    "        self.freq_map = {\n",
    "            s: torch.zeros(self.vocab_size, dtype=torch.long) for s in self.substrs\n",
    "        }\n",
    "\n",
    "        for i in range(len(self.text) - self.s_len):\n",
    "            s = self.text[i : i + self.s_len]\n",
    "            if s in self.freq_map:\n",
    "                next_char = text[i + self.s_len]\n",
    "                self.freq_map[s][self.stoi[next_char]] += 1\n",
    "\n",
    "        # Compute the normalized cumulative frequencies\n",
    "        self.cumulative_freqs = torch.zeros(self.vocab_size, dtype=torch.float32)\n",
    "        for freqs in self.freq_map.values():\n",
    "            self.cumulative_freqs += freqs.float()\n",
    "        self.cumulative_freqs /= self.cumulative_freqs.sum()\n",
    "\n",
    "        # Figure out the top tokens for each substring\n",
    "        self.top_tokens = {\n",
    "            s: top_nonzero_tokens(freqs, self.itos)\n",
    "            for s, freqs in self.freq_map.items()\n",
    "        }\n",
    "        self.top_tokens_cumulative = top_nonzero_tokens(\n",
    "            self.cumulative_freqs, self.itos\n",
    "        )\n",
    "\n",
    "    def print_summary(self):\n",
    "        print(f\"Substrings: {', '.join([repr(substr) for substr in self.substrs])}\")\n",
    "\n",
    "        print(\"Top Tokens for each substring:\")\n",
    "        for s, tokens in self.top_tokens.items():\n",
    "            print(\n",
    "                f\"{repr(s):>{2*self.s_len+2}}: {', '.join([f'{repr(token):>4} ({freq:>4})' for token, freq in tokens])}\"\n",
    "            )\n",
    "\n",
    "        print(\"Cumulative Top Tokens:\")\n",
    "        print(\n",
    "            ', '.join(\n",
    "                [\n",
    "                    f'{repr(token):>4} ({freq:.2f})'\n",
    "                    for token, freq in self.top_tokens_cumulative\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for SubstringFrequencyAnalysis\n",
    "itos = {0: 'a', 1: 'b', 2: 'c', 3: 'd'}\n",
    "stoi = {v: k for k, v in itos.items()}\n",
    "text = 'aaabbbcccddd'\n",
    "substrs = ['aaa', 'bbb', 'ccc', 'ddd']\n",
    "sfa = SubstringFrequencyAnalysis(\n",
    "    substrs=substrs, text=text, vocab_size=len(itos), itos=itos, stoi=stoi\n",
    ")\n",
    "test_eq(sfa.freq_map['aaa'].tolist(), [0, 1, 0, 0])\n",
    "test_eq(sfa.freq_map['bbb'].tolist(), [0, 0, 1, 0])\n",
    "test_eq(sfa.freq_map['ccc'].tolist(), [0, 0, 0, 1])\n",
    "test_eq(sfa.freq_map['ddd'].tolist(), [0, 0, 0, 0])\n",
    "\n",
    "test_close(sfa.cumulative_freqs.tolist(), [0, 1/3, 1/3, 1/3])\n",
    "\n",
    "test_eq(sfa.top_tokens['aaa'], [('b', 1)])\n",
    "test_eq(sfa.top_tokens['bbb'], [('c', 1)])\n",
    "test_eq(sfa.top_tokens['ccc'], [('d', 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
