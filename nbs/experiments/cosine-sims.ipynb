{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine-sims\n",
    "\n",
    "> Experiment to generate the cosine similarity between a set of queries and specific block internals outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiments.cosine_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import click\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from transformer_experiments.environments import get_environment\n",
    "from transformer_experiments.common.substring_generator import all_unique_substrings\n",
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import (\n",
    "    block_size,\n",
    "    n_embed,\n",
    "    n_layer,\n",
    "    TransformerLanguageModel\n",
    ")\n",
    "from transformer_experiments.models.transformer_helpers import (\n",
    "    EncodingHelpers,\n",
    "    LogitsWrapper,\n",
    "    TransformerAccessors\n",
    ")\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class CosineSimilaritiesExperiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        strings: Sequence[str],\n",
    "        batch_size: int,\n",
    "        output_folder: Path,\n",
    "        encoding_helpers: EncodingHelpers,\n",
    "        accessors: TransformerAccessors,\n",
    "    ):\n",
    "        self.strings = strings\n",
    "        self.batch_size = batch_size\n",
    "        self.output_folder = output_folder\n",
    "        self.encoding_helpers = encoding_helpers\n",
    "        self.accessors = accessors\n",
    "\n",
    "        self.n_batches = math.ceil(len(self.strings) / self.batch_size)\n",
    "\n",
    "    def cosine_sim_ffwd_out_filename(self, batch_idx: int) -> Path:\n",
    "        return self.output_folder / f\"cosine_sim_ffwd_out_{batch_idx:05d}.pt\"\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        queries: torch.Tensor,\n",
    "        start_batch_idx: int = 0,\n",
    "        disable_progress_bar: bool = False,\n",
    "    ):\n",
    "        assert queries.dim() == 3\n",
    "        assert queries.shape[0] == n_layer\n",
    "        assert queries.shape[2] == n_embed\n",
    "        n_queries = queries.shape[1]\n",
    "\n",
    "        for batch_idx in tqdm(\n",
    "            range(start_batch_idx, self.n_batches), disable=disable_progress_bar\n",
    "        ):\n",
    "            start_idx = batch_idx * self.batch_size\n",
    "            end_idx = start_idx + self.batch_size\n",
    "            batch_strings = self.strings[start_idx:end_idx]\n",
    "\n",
    "            batch_size = len(\n",
    "                batch_strings\n",
    "            )  # Might be smaller than configured batch size\n",
    "            assert batch_size <= self.batch_size\n",
    "\n",
    "            ffwd_outs = self._get_ffwd_outs(\n",
    "                batch_strings\n",
    "            )  # (n_layer, batch_size, n_embed)\n",
    "\n",
    "            sims = F.cosine_similarity(\n",
    "                ffwd_outs.reshape(n_layer, batch_size, 1, n_embed).expand(\n",
    "                    -1, -1, n_queries, -1\n",
    "                ),\n",
    "                queries.reshape(n_layer, 1, n_queries, n_embed).expand(\n",
    "                    -1, batch_size, -1, -1\n",
    "                ),\n",
    "                dim=-1,\n",
    "            )\n",
    "\n",
    "            torch.save(sims, self.cosine_sim_ffwd_out_filename(batch_idx))\n",
    "            del ffwd_outs\n",
    "            del sims\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    def _get_ffwd_outs(self, batch_strings: Sequence[str]) -> torch.Tensor:\n",
    "        tokens = self.encoding_helpers.tokenize_strings(batch_strings)\n",
    "        embeddings = self.accessors.embed_tokens(tokens)\n",
    "\n",
    "        _, io_accessors = self.accessors.run_model(embeddings)\n",
    "\n",
    "        ffwd_outs = torch.stack(\n",
    "            [\n",
    "                io_accessors[block_idx].output(\"ffwd\")[:, -1, :].clone()\n",
    "                for block_idx in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "        return ffwd_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def get_ffwd_queries(\n",
    "    strings: Sequence[str],\n",
    "    encoding_helpers: EncodingHelpers,\n",
    "    accessors: TransformerAccessors,\n",
    ") -> torch.Tensor:\n",
    "    tokens = encoding_helpers.tokenize_strings(strings)\n",
    "    embeddings = accessors.embed_tokens(tokens)\n",
    "\n",
    "    _, io_accessors = accessors.run_model(embeddings)\n",
    "\n",
    "    return torch.stack(\n",
    "        [\n",
    "            io_accessors[block_idx].output(\"ffwd\")[:, -1, :]\n",
    "            for block_idx in range(n_layer)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment is paperspace\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "environment = get_environment()\n",
    "print(f\"environment is {environment.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TinyShakespeareDataSet(cache_file=environment.code_root / 'nbs/artifacts/input.txt')\n",
    "m, tokenizer = create_model_and_tokenizer(\n",
    "    saved_model_filename=environment.code_root / 'nbs/artifacts/shakespeare-20231112.pt',\n",
    "    dataset=ts,\n",
    "    device=device,\n",
    ")\n",
    "encoding_helpers = EncodingHelpers(tokenizer, device)\n",
    "accessors = TransformerAccessors(m, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings10 = all_unique_substrings(ts.text, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for CosineSimilaritiesExperiment\n",
    "s_len = 3\n",
    "strings3 = all_unique_substrings(ts.text[:100], s_len)\n",
    "batch_size = 17\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    output_folder = Path(tmpdirname)\n",
    "    experiment = CosineSimilaritiesExperiment(\n",
    "        strings=strings3,\n",
    "        batch_size=batch_size,\n",
    "        output_folder=output_folder,\n",
    "        encoding_helpers=encoding_helpers,\n",
    "        accessors=accessors,\n",
    "    )\n",
    "    query_strings = [strings3[i] for i in [10, 75, 3]] # indices are arbitrary\n",
    "    queries = get_ffwd_queries(query_strings, encoding_helpers, accessors)\n",
    "    experiment.run(queries=queries, disable_progress_bar=True)\n",
    "\n",
    "    n_expected_batches = math.ceil(len(strings3) / batch_size)\n",
    "    for batch_idx in range(n_expected_batches):\n",
    "        test_eq(experiment.cosine_sim_ffwd_out_filename(batch_idx).exists(), True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@click.command()\n",
    "@click.argument(\"model_weights_filename\", type=click.Path(exists=True))\n",
    "@click.argument(\"dataset_cache_filename\", type=click.Path(exists=True))\n",
    "@click.argument(\"output_folder\", type=click.Path(exists=True))\n",
    "@click.option(\n",
    "    \"-s\",\n",
    "    \"--string_len\",\n",
    "    required=True,\n",
    "    type=click.IntRange(min=1, max=block_size),\n",
    ")\n",
    "@click.option(\n",
    "    \"-m\",\n",
    "    \"--max_batch_size\",\n",
    "    required=True,\n",
    "    type=click.IntRange(min=1),\n",
    ")\n",
    "@click.option(\n",
    "    \"-n\",\n",
    "    \"--num_queries\",\n",
    "    required=True,\n",
    "    type=click.IntRange(min=1),\n",
    ")\n",
    "@click.option(\n",
    "    \"-r\",\n",
    "    \"--random_seed\",\n",
    "    required=True,\n",
    "    type=click.INT,\n",
    ")\n",
    "@click.option(\n",
    "    \"-b\",\n",
    "    \"--start_batch_idx\",\n",
    "    required=False,\n",
    "    type=click.INT,\n",
    "    default=0,\n",
    ")\n",
    "def run(\n",
    "    model_weights_filename: str,\n",
    "    dataset_cache_filename: str,\n",
    "    output_folder: str,\n",
    "    string_len: int,\n",
    "    max_batch_size: int,\n",
    "    num_queries: int,\n",
    "    random_seed: int,\n",
    "    start_batch_idx: int,\n",
    "):\n",
    "    click.echo(\"CosineSimilaritiesExperiment CLI\")\n",
    "    click.echo()\n",
    "    click.echo(f\"  model weights: {model_weights_filename}\")\n",
    "    click.echo(f\"  dataset cache: {dataset_cache_filename}\")\n",
    "    click.echo(f\"  output folder: {output_folder}\")\n",
    "\n",
    "    click.echo()\n",
    "    click.echo(f\"  string length: {string_len}\")\n",
    "    click.echo(f\"  max batch size: {max_batch_size}\")\n",
    "    click.echo(f\"  num queries: {num_queries}\")\n",
    "    click.echo(f\"  random seed: {random_seed}\")\n",
    "    click.echo(f\"  start batch idx: {start_batch_idx}\")\n",
    "\n",
    "    click.echo()\n",
    "\n",
    "    click.echo(f\"pid is {os.getpid()}\")\n",
    "    click.echo()\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    click.echo(f\"device is {device}\")\n",
    "\n",
    "    ts = TinyShakespeareDataSet(cache_file=dataset_cache_filename)\n",
    "    m, tokenizer = create_model_and_tokenizer(\n",
    "        saved_model_filename=model_weights_filename,\n",
    "        dataset=ts,\n",
    "        device=device,\n",
    "    )\n",
    "    _ = m.to(device)\n",
    "\n",
    "    encoding_helpers = EncodingHelpers(tokenizer, device)\n",
    "    accessors = TransformerAccessors(m, device)\n",
    "\n",
    "    all_strings = all_unique_substrings(ts.text, string_len)\n",
    "\n",
    "    experiment = CosineSimilaritiesExperiment(\n",
    "        strings=all_strings,\n",
    "        batch_size=max_batch_size,\n",
    "        output_folder=Path(output_folder),\n",
    "        encoding_helpers=encoding_helpers,\n",
    "        accessors=accessors,\n",
    "    )\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    indices = torch.randperm(len(all_strings))[:num_queries]\n",
    "    query_strings = [all_strings[i.item()] for i in indices]\n",
    "\n",
    "    queries = get_ffwd_queries(query_strings, encoding_helpers, accessors)\n",
    "    experiment.run(queries=queries, start_batch_idx=start_batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-experiments",
   "language": "python",
   "name": "transformer-experiments"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
