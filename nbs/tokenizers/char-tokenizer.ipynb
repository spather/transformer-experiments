{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# char-tokenizer.ipynb\n",
    "\n",
    "> Implementation of a character-level tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tokenizers.char_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from typing import Callable, Dict, Iterable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "SToI = Dict[str, int]\n",
    "IToS = Dict[int, str]\n",
    "EncodeFn = Callable[[str], Iterable[int]]\n",
    "DecodeFn = Callable[[Iterable[int]], str]\n",
    "\n",
    "\n",
    "def create_character_tokenizer(\n",
    "    text: str,\n",
    ") -> Tuple[Iterable[str], int, SToI, IToS, EncodeFn, DecodeFn]:\n",
    "    \"\"\"Create a character tokenizer from text.\"\"\"\n",
    "    chars = sorted(list(set(text)))\n",
    "    vocab_size = len(chars)\n",
    "    stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "    itos = {i: ch for i, ch in enumerate(chars)}\n",
    "    encode = lambda s: [stoi[c] for c in s]\n",
    "    decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "    return chars, vocab_size, stoi, itos, encode, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for create_character_tokenizer\n",
    "chars, vocab_size, stoi, itos, encode, decode = create_character_tokenizer('abcabc')\n",
    "test_eq(chars, ['a', 'b', 'c'])\n",
    "test_eq(vocab_size, 3)\n",
    "test_eq(stoi, {'a': 0, 'b': 1, 'c': 2})\n",
    "test_eq(itos, {0: 'a', 1: 'b', 2: 'c'})\n",
    "test_eq(encode('cab'), [2, 0, 1])\n",
    "test_eq(decode([2, 1, 0]), 'cba')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
