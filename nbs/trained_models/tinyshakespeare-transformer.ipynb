{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tinyshakespeare-transformer\n",
    "\n",
    "> Code for instantiating a pre-trained TinyShakespeare transformer model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp trained_models.tinyshakespeare_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from typing import Callable, Dict, Iterable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import device, TransformerLanguageModel\n",
    "from transformer_experiments.tokenizers.char_tokenizer import (\n",
    "    create_character_tokenizer,\n",
    "    SToI,\n",
    "    IToS,\n",
    "    DecodeFn,\n",
    "    EncodeFn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_model_and_tokenizer(\n",
    "    saved_model_filename: str, dataset: TinyShakespeareDataSet\n",
    ") -> Tuple[\n",
    "    TransformerLanguageModel, str, Iterable[str], int, SToI, IToS, EncodeFn, DecodeFn\n",
    "]:\n",
    "    \"\"\"Instantiates a pre-trained TinyShakespeare model: creates transformer model,\n",
    "    loads the model params from a saved file, and creates a tokenizer from the dataset's text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a tokenizer from the dataset's text\n",
    "    chars, vocab_size, stoi, itos, encode, decode = create_character_tokenizer(\n",
    "        dataset.text\n",
    "    )\n",
    "\n",
    "    # Create the model\n",
    "    m = TransformerLanguageModel(vocab_size=vocab_size)\n",
    "    m.to(device)\n",
    "\n",
    "    # Load the model params from a saved file\n",
    "    m.load_state_dict(\n",
    "        torch.load(saved_model_filename, map_location=torch.device(device))\n",
    "    )\n",
    "    m.eval()\n",
    "\n",
    "    return m, device, chars, vocab_size, stoi, itos, encode, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
