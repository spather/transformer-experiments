{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "> An introduction to the TinyShakespeare transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a manual seed so output is deterministic (used same value as @karpathy)\n",
    "_ = torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_experiments.datasets.tinyshakespeare import (\n",
    "    TinyShakespeareDataSet,\n",
    ")\n",
    "from transformer_experiments.models.transformer import TransformerLanguageModel\n",
    "from transformer_experiments.trained_models.tinyshakespeare_transformer import (\n",
    "    create_model_and_tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TinyShakespeareDataSet(cache_file='../artifacts/input.txt')\n",
    "m, device, chars, vocab_size, stoi, itos, encode, decode = create_model_and_tokenizer(\n",
    "    saved_model_filename='../artifacts/shakespeare.pt',\n",
    "    dataset=ts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device is {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788929"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at the model size\n",
    "trainable_params = [p for p in m.parameters() if p.requires_grad]\n",
    "nparams = sum([np.prod(p.size()) for p in trainable_params])\n",
    "nparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate text\n",
    "\n",
    "def str_to_tensor(s: str):\n",
    "    return torch.tensor([encode(s)], dtype=torch.long, device=device)\n",
    "\n",
    "def generate(m: TransformerLanguageModel, initial_text: str, max_new_tokens=100):\n",
    "    input = str_to_tensor(initial_text)\n",
    "    return decode(m.generate(input, max_new_tokens=max_new_tokens)[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellowful provide the instrument to use.\n",
      "\n",
      "CORIOLANUS:\n",
      "Great of this desperate lies! Dost most war;\n",
      "This m\n"
     ]
    }
   ],
   "source": [
    "print(generate(m, 'Hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ANGELO:\n",
      "From Relandful grace!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Bid heaven, to see you hear.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Back hame heard gone alas! would hear your honours\n",
      "Where you hear you pray? Or if my brother's love!\n",
      "\n",
      "LUCIO:\n",
      "I have as a well-manded general seem,\n",
      "Pray you for the pricked handing bears\n",
      "To send a spoil membranch with our face.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "How is it to save the sweet discoversaried!\n",
      "Thou must not meed to do against him,\n",
      "Very expers to them report; now that she is not half\n",
      "His absence afed, whose hands the morning tomb,\n",
      "Imptition him in the crown'd and power hour\n",
      "As happy that lost upon his feet and gentleman.\n",
      "\n",
      "Shepherd:\n",
      "His regord, he, I thank you.\n",
      "\n",
      "PAULINA:\n",
      "As my lady\n",
      "Unto the case.\n",
      "\n",
      "DERSE:\n",
      "Clarence me too,\n",
      "And in this vengeance corn: these part they should pay\n",
      "The day and day inhish the light.\n",
      "\n",
      "PARIS:\n",
      "Why, I am sure.\n",
      "\n",
      "LEONTES:\n",
      "So, if you had content to re't:\n",
      "She is true, may be guilty and calm\n",
      "Of that your honour daughter's hands you all.\n",
      "Where is claim? and why 'twere it? who, lords?\n",
      "\n",
      "L\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Generate some longer text\n",
    "print(generate(m, '\\n', max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There once was a man from Nantucket,\n",
      "Unrichly man in that head; thou, they the fearful head.\n",
      "\n",
      "BRUTUS:\n",
      "After all of much in this eyes.\n",
      "\n",
      "Citizens:\n",
      "Well all met, sir: to prisoner you, let's God!\n",
      "\n",
      "BAGOT:\n",
      "O God save the better wondrous says\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "print(generate(m, 'There once was a man from Nantucket', max_new_tokens=200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
