# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/trained_models/tinyshakespeare-transformer.ipynb.

# %% auto 0
__all__ = ['create_model_and_tokenizer']

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 4
from typing import Callable, Dict, Iterable, Tuple

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 5
import torch

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 6
from transformer_experiments.datasets.tinyshakespeare import (
    TinyShakespeareDataSet,
)
from ..models.transformer import device, TransformerLanguageModel
from transformer_experiments.tokenizers.char_tokenizer import (
    create_character_tokenizer,
    SToI,
    IToS,
    DecodeFn,
    EncodeFn,
)

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 7
def create_model_and_tokenizer(
    saved_model_filename: str, dataset: TinyShakespeareDataSet
) -> Tuple[
    TransformerLanguageModel, str, Iterable[str], int, SToI, IToS, EncodeFn, DecodeFn
]:
    """Instantiates a pre-trained TinyShakespeare model: creates transformer model,
    loads the model params from a saved file, and creates a tokenizer from the dataset's text.
    """

    # Create a tokenizer from the dataset's text
    chars, vocab_size, stoi, itos, encode, decode = create_character_tokenizer(
        dataset.text
    )

    # Create the model
    m = TransformerLanguageModel(vocab_size=vocab_size)
    m.to(device)

    # Load the model params from a saved file
    m.load_state_dict(
        torch.load(saved_model_filename, map_location=torch.device(device))
    )
    m.eval()

    return m, device, chars, vocab_size, stoi, itos, encode, decode
