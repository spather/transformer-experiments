# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/trained_models/tinyshakespeare-transformer.ipynb.

# %% auto 0
__all__ = ['create_model_and_tokenizer']

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 4
from typing import Callable, Dict, Iterable, Tuple

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 5
import torch

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 6
from transformer_experiments.datasets.tinyshakespeare import (
    TinyShakespeareDataSet,
)
from ..models.transformer import TransformerLanguageModel
from transformer_experiments.tokenizers.char_tokenizer import (
    CharacterTokenizer,
)

# %% ../../nbs/trained_models/tinyshakespeare-transformer.ipynb 7
def create_model_and_tokenizer(
    saved_model_filename: str, dataset: TinyShakespeareDataSet, device: str
) -> Tuple[TransformerLanguageModel, CharacterTokenizer]:
    """Instantiates a pre-trained TinyShakespeare model: creates transformer model,
    loads the model params from a saved file, and creates a tokenizer from the dataset's text.
    """

    # Create a tokenizer from the dataset's text
    tokenizer = CharacterTokenizer(dataset.text)

    # Create the model
    m = TransformerLanguageModel(vocab_size=tokenizer.vocab_size, device=device)
    m.to(device)

    # Load the model params from a saved file
    m.load_state_dict(
        torch.load(saved_model_filename, map_location=torch.device(device))
    )
    m.eval()

    return m, tokenizer
